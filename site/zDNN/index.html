
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
        <meta name="author" content="IBM Developer">
      
      
        <link rel="canonical" href="https://ibm.github.io/ai-on-z-101/zDNN/">
      
      <link rel="icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.3.0, mkdocs-material-8.2.15">
    
    
      
        <title>zDNN API Reference - AI on IBM Z 101</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.c382b1dc.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.cc9b2e1e.min.css">
        
          
          
          <meta name="theme-color" content="#2094f3">
        
      
    
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=IBM+Plex+Sans:300,300i,400,400i,700,700i%7CIBM+Plex+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"IBM Plex Sans";--md-code-font:"IBM Plex Mono"}</style>
      
    
    
    <script>__md_scope=new URL("..",location),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="blue" data-md-color-accent="blue">
  
    
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#zdnn-api-reference" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="AI on IBM Z 101" class="md-header__button md-logo" aria-label="AI on IBM Z 101" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            AI on IBM Z 101
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              zDNN API Reference
            
          </span>
        </div>
      </div>
    </div>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" aria-label="Clear" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/IBM/ai-on-z-101" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.1.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    ai-on-z-101
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="AI on IBM Z 101" class="md-nav__button md-logo" aria-label="AI on IBM Z 101" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    AI on IBM Z 101
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/IBM/ai-on-z-101" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.1.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    ai-on-z-101
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        Overview
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../z16Accel/" class="md-nav__link">
        Leveraging the IBM z16 Integrated Accelerator for AI
      </a>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3" type="checkbox" id="__nav_3" >
      
      
      
      
        <label class="md-nav__link" for="__nav_3">
          Featured Frameworks and Technologies
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Featured Frameworks and Technologies" data-md-level="1">
        <label class="md-nav__title" for="__nav_3">
          <span class="md-nav__icon md-icon"></span>
          Featured Frameworks and Technologies
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../onnxdlc/" class="md-nav__link">
        ONNX and the IBM Deep Learning Compiler
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../snapml/" class="md-nav__link">
        IBM Snap Machine Learning (Snap ML)
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../tensorflow/" class="md-nav__link">
        TensorFlow
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="https://www.ibm.com/common/ssi/ShowDoc.wss?docURL=/common/ssi/rep_ca/1/897/ENUS222-061/index.html" class="md-nav__link">
        Db2 13 SQL Data Insights
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../opensource/" class="md-nav__link">
        Obtaining open-source packages
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../infusing/" class="md-nav__link">
        Infusing AI into your IBM zSystem business applications
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../help/" class="md-nav__link">
        Getting help
      </a>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_7" type="checkbox" id="__nav_7" >
      
      
      
      
        <label class="md-nav__link" for="__nav_7">
          Reference Models
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Reference Models" data-md-level="1">
        <label class="md-nav__title" for="__nav_7">
          <span class="md-nav__icon md-icon"></span>
          Reference Models
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="https://github.com/IBM/ai-on-z-fraud-detection/" class="md-nav__link">
        Fraud Detection
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../codingAIU/" class="md-nav__link">
        Compiler and AI framework developer resources
      </a>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_9" type="checkbox" id="__nav_9" >
      
      
      
      
        <label class="md-nav__link" for="__nav_9">
          Resources
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Resources" data-md-level="1">
        <label class="md-nav__title" for="__nav_9">
          <span class="md-nav__icon md-icon"></span>
          Resources
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="https://github.com/IBM/ai-on-z-samples" class="md-nav__link">
        Samples
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="https://github.com/IBM/ai-on-z-containers" class="md-nav__link">
        Additional container build files
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="https://github.com/IBM/zDNN" class="md-nav__link">
        zDNN
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_10" type="checkbox" id="__nav_10" >
      
      
      
      
        <label class="md-nav__link" for="__nav_10">
          External Content
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="External Content" data-md-level="1">
        <label class="md-nav__title" for="__nav_10">
          <span class="md-nav__icon md-icon"></span>
          External Content
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="https://www.ibm.com/support/z-content-solutions/journey-to-ai-on-z/" class="md-nav__link">
        IBM Z and LinuxOne Content Solutions
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="https://ibmzxplore.influitive.com" class="md-nav__link">
        IBM Z Xplore
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="https://community.ibm.com/community/user/ibmz-and-linuxone/groups/topic-home?CommunityKey=038560b2-e962-4500-b0b5-e3745175a065" class="md-nav__link">
        AI on IBM Z and LinuxONE Community
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="https://ibm.github.io/ibm-z-oss-hub/main/main.html" class="md-nav__link">
        IBM Z and LinuxONE Container Registry
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#contacts" class="md-nav__link">
    Contacts
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#version" class="md-nav__link">
    Version
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#table-of-contents" class="md-nav__link">
    Table of Contents 
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#overview" class="md-nav__link">
    Overview
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#environment" class="md-nav__link">
    Environment
  </a>
  
    <nav class="md-nav" aria-label="Environment">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#alignment-requirements" class="md-nav__link">
    Alignment requirements
  </a>
  
    <nav class="md-nav" aria-label="Alignment requirements">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#aiu-op-limits" class="md-nav__link">
    AIU Op Limits
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#application-interfaces-for-zaiu-enterprise-neural-network-inference" class="md-nav__link">
    Application interfaces for zAIU Enterprise Neural Network Inference
  </a>
  
    <nav class="md-nav" aria-label="Application interfaces for zAIU Enterprise Neural Network Inference">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#zdnn-general" class="md-nav__link">
    zDNN General
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#using-zdnn" class="md-nav__link">
    Using zDNN
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#common-types-and-structs" class="md-nav__link">
    Common Types and Structs
  </a>
  
    <nav class="md-nav" aria-label="Common Types and Structs">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#version-information" class="md-nav__link">
    Version Information 
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zdnn-ztensor" class="md-nav__link">
    zDNN zTensor 
  </a>
  
    <nav class="md-nav" aria-label="zDNN zTensor ">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#general-ztensor-requirements" class="md-nav__link">
    General zTensor Requirements 
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#concatenated-ztensor-requirements" class="md-nav__link">
    Concatenated zTensor Requirements 
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zdnn-tensor-descriptors" class="md-nav__link">
    zDNN Tensor Descriptors 
  </a>
  
    <nav class="md-nav" aria-label="zDNN Tensor Descriptors ">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#programming-notes" class="md-nav__link">
    Programming Notes
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zdnn-data-layouts" class="md-nav__link">
    zDNN Data Layouts 
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zdnn-data-formats" class="md-nav__link">
    zDNN Data Formats 
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zdnn-data-types" class="md-nav__link">
    zDNN Data Types 
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zdnn-statuses" class="md-nav__link">
    zDNN Statuses 
  </a>
  
    <nav class="md-nav" aria-label="zDNN Statuses ">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#warning-statuses" class="md-nav__link">
    Warning Statuses 
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#general-failing-statuses" class="md-nav__link">
    General Failing Statuses 
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#hardware-statuses" class="md-nav__link">
    Hardware Statuses 
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#runtime-environment-variables" class="md-nav__link">
    Runtime Environment Variables 
  </a>
  
    <nav class="md-nav" aria-label="Runtime Environment Variables ">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#programming-notes_1" class="md-nav__link">
    Programming Notes
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#api-reference" class="md-nav__link">
    API Reference
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#support-functions" class="md-nav__link">
    Support Functions
  </a>
  
    <nav class="md-nav" aria-label="Support Functions">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#zdnn_init" class="md-nav__link">
    zdnn_init
  </a>
  
    <nav class="md-nav" aria-label="zdnn_init">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#description" class="md-nav__link">
    Description
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#format" class="md-nav__link">
    Format
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#parameters" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zdnn_get_nnpa_max_dim_idx_size" class="md-nav__link">
    zdnn_get_nnpa_max_dim_idx_size
  </a>
  
    <nav class="md-nav" aria-label="zdnn_get_nnpa_max_dim_idx_size">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#description_1" class="md-nav__link">
    Description
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#format_1" class="md-nav__link">
    Format
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#parameters_1" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_1" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zdnn_get_nnpa_max_tensor_size" class="md-nav__link">
    zdnn_get_nnpa_max_tensor_size
  </a>
  
    <nav class="md-nav" aria-label="zdnn_get_nnpa_max_tensor_size">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#description_2" class="md-nav__link">
    Description
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#format_2" class="md-nav__link">
    Format
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#parameters_2" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_2" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zdnn_is_nnpa_installed" class="md-nav__link">
    zdnn_is_nnpa_installed
  </a>
  
    <nav class="md-nav" aria-label="zdnn_is_nnpa_installed">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#description_3" class="md-nav__link">
    Description
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#format_3" class="md-nav__link">
    Format
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#parameters_3" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_3" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zdnn_is_nnpa_function_installed" class="md-nav__link">
    zdnn_is_nnpa_function_installed
  </a>
  
    <nav class="md-nav" aria-label="zdnn_is_nnpa_function_installed">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#description_4" class="md-nav__link">
    Description
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#format_4" class="md-nav__link">
    Format
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#parameters_4" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_4" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zdnn_is_nnpa_parmblk_fmt_installed" class="md-nav__link">
    zdnn_is_nnpa_parmblk_fmt_installed
  </a>
  
    <nav class="md-nav" aria-label="zdnn_is_nnpa_parmblk_fmt_installed">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#description_5" class="md-nav__link">
    Description
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#format_5" class="md-nav__link">
    Format
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#parameters_5" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_5" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zdnn_is_nnpa_datatype_installed" class="md-nav__link">
    zdnn_is_nnpa_datatype_installed
  </a>
  
    <nav class="md-nav" aria-label="zdnn_is_nnpa_datatype_installed">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#description_6" class="md-nav__link">
    Description
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#format_6" class="md-nav__link">
    Format
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#parameters_6" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_6" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zdnn_is_nnpa_layout_fmt_installed" class="md-nav__link">
    zdnn_is_nnpa_layout_fmt_installed
  </a>
  
    <nav class="md-nav" aria-label="zdnn_is_nnpa_layout_fmt_installed">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#description_7" class="md-nav__link">
    Description
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#format_7" class="md-nav__link">
    Format
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#parameters_7" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_7" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zdnn_is_nnpa_conversion_installed" class="md-nav__link">
    zdnn_is_nnpa_conversion_installed
  </a>
  
    <nav class="md-nav" aria-label="zdnn_is_nnpa_conversion_installed">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#description_8" class="md-nav__link">
    Description
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#format_8" class="md-nav__link">
    Format
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#parameters_8" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_8" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zdnn_get_library_version" class="md-nav__link">
    zdnn_get_library_version
  </a>
  
    <nav class="md-nav" aria-label="zdnn_get_library_version">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#description_9" class="md-nav__link">
    Description
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#format_9" class="md-nav__link">
    Format
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_9" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zdnn_get_library_version_str" class="md-nav__link">
    zdnn_get_library_version_str
  </a>
  
    <nav class="md-nav" aria-label="zdnn_get_library_version_str">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#description_10" class="md-nav__link">
    Description
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#format_10" class="md-nav__link">
    Format
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_10" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zdnn_refresh_nnpa_query_result" class="md-nav__link">
    zdnn_refresh_nnpa_query_result
  </a>
  
    <nav class="md-nav" aria-label="zdnn_refresh_nnpa_query_result">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#description_11" class="md-nav__link">
    Description
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#format_11" class="md-nav__link">
    Format
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#parameters_9" class="md-nav__link">
    Parameters
  </a>
  
    <nav class="md-nav" aria-label="Parameters">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#programming-notes_2" class="md-nav__link">
    Programming Notes
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns-zdnn_status-indications" class="md-nav__link">
    Returns zdnn_status indications
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zdnn_getsize_ztensor" class="md-nav__link">
    zdnn_getsize_ztensor
  </a>
  
    <nav class="md-nav" aria-label="zdnn_getsize_ztensor">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#description_12" class="md-nav__link">
    Description
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#format_12" class="md-nav__link">
    Format
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#parameters_10" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns-zdnn_status-indications_1" class="md-nav__link">
    Returns zdnn_status indications
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zdnn_init_pre_transformed_desc" class="md-nav__link">
    zdnn_init_pre_transformed_desc
  </a>
  
    <nav class="md-nav" aria-label="zdnn_init_pre_transformed_desc">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#description_13" class="md-nav__link">
    Description
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#format_13" class="md-nav__link">
    Format
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#parameters_11" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_11" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zdnn_generate_transformed_desc" class="md-nav__link">
    zdnn_generate_transformed_desc
  </a>
  
    <nav class="md-nav" aria-label="zdnn_generate_transformed_desc">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#description_14" class="md-nav__link">
    Description
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#format_14" class="md-nav__link">
    Format
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#parameters_12" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zdnn_status-indications" class="md-nav__link">
    zdnn_status indications
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zdnn_generate_transformed_desc_concatenated" class="md-nav__link">
    zdnn_generate_transformed_desc_concatenated
  </a>
  
    <nav class="md-nav" aria-label="zdnn_generate_transformed_desc_concatenated">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#description_15" class="md-nav__link">
    Description
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#format_15" class="md-nav__link">
    Format
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#parameters_13" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zdnn_status-indications_1" class="md-nav__link">
    zdnn_status indications
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zdnn_init_ztensor" class="md-nav__link">
    zdnn_init_ztensor
  </a>
  
    <nav class="md-nav" aria-label="zdnn_init_ztensor">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#description_16" class="md-nav__link">
    Description
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#format_16" class="md-nav__link">
    Format
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#parameters_14" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_12" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zdnn_init_ztensor_with_malloc" class="md-nav__link">
    zdnn_init_ztensor_with_malloc
  </a>
  
    <nav class="md-nav" aria-label="zdnn_init_ztensor_with_malloc">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#description_17" class="md-nav__link">
    Description
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#format_17" class="md-nav__link">
    Format
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#parameters_15" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns-zdnn_status-indications_2" class="md-nav__link">
    Returns zdnn_status indications
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zdnn_reset_ztensor" class="md-nav__link">
    zdnn_reset_ztensor
  </a>
  
    <nav class="md-nav" aria-label="zdnn_reset_ztensor">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#description_18" class="md-nav__link">
    Description
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#format_18" class="md-nav__link">
    Format
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#parameters_16" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_13" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zdnn_allochelper_ztensor" class="md-nav__link">
    zdnn_allochelper_ztensor
  </a>
  
    <nav class="md-nav" aria-label="zdnn_allochelper_ztensor">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#description_19" class="md-nav__link">
    Description
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#format_19" class="md-nav__link">
    Format
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#parameters_17" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns-zdnn_status-indications_3" class="md-nav__link">
    Returns zdnn_status indications
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zdnn_free_ztensor_buffer" class="md-nav__link">
    zdnn_free_ztensor_buffer
  </a>
  
    <nav class="md-nav" aria-label="zdnn_free_ztensor_buffer">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#description_20" class="md-nav__link">
    Description
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#format_20" class="md-nav__link">
    Format
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#parameters_18" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns-zdnn_status-indications_4" class="md-nav__link">
    Returns zdnn_status indications
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zdnn_get_status_message" class="md-nav__link">
    zdnn_get_status_message
  </a>
  
    <nav class="md-nav" aria-label="zdnn_get_status_message">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#description_21" class="md-nav__link">
    Description
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#format_21" class="md-nav__link">
    Format
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#parameters_19" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_14" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zdnn_reshape_ztensor" class="md-nav__link">
    zdnn_reshape_ztensor
  </a>
  
    <nav class="md-nav" aria-label="zdnn_reshape_ztensor">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#description_22" class="md-nav__link">
    Description
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#format_22" class="md-nav__link">
    Format
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#parameters_20" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#programming-notes_3" class="md-nav__link">
    Programming Notes
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_15" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zdnn_is_version_runnable" class="md-nav__link">
    zdnn_is_version_runnable
  </a>
  
    <nav class="md-nav" aria-label="zdnn_is_version_runnable">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#description_23" class="md-nav__link">
    Description
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#format_23" class="md-nav__link">
    Format
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#parameters_21" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_16" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zdnn_get_max_runnable_version" class="md-nav__link">
    zdnn_get_max_runnable_version
  </a>
  
    <nav class="md-nav" aria-label="zdnn_get_max_runnable_version">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#description_24" class="md-nav__link">
    Description
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#format_24" class="md-nav__link">
    Format
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#parameters_22" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns_17" class="md-nav__link">
    Returns
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#data-transformation" class="md-nav__link">
    Data Transformation
  </a>
  
    <nav class="md-nav" aria-label="Data Transformation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#zdnn_transform_ztensor" class="md-nav__link">
    zdnn_transform_ztensor
  </a>
  
    <nav class="md-nav" aria-label="zdnn_transform_ztensor">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#description_25" class="md-nav__link">
    Description
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#format_25" class="md-nav__link">
    Format
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#parameters_23" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#programming-notes_4" class="md-nav__link">
    Programming Notes
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns-zdnn_status-indications_5" class="md-nav__link">
    Returns zdnn_status indications
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zdnn_transform_origtensor" class="md-nav__link">
    zdnn_transform_origtensor
  </a>
  
    <nav class="md-nav" aria-label="zdnn_transform_origtensor">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#description_26" class="md-nav__link">
    Description
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#format_26" class="md-nav__link">
    Format
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#parameters_24" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#programming-notes_5" class="md-nav__link">
    Programming Notes
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns-zdnn_status-indications_6" class="md-nav__link">
    Returns zdnn_status indications
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#operations" class="md-nav__link">
    Operations
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#element-wise-operations" class="md-nav__link">
    Element-wise Operations 
  </a>
  
    <nav class="md-nav" aria-label="Element-wise Operations ">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#zdnn_add" class="md-nav__link">
    zdnn_add
  </a>
  
    <nav class="md-nav" aria-label="zdnn_add">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#description_27" class="md-nav__link">
    Description
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#format_27" class="md-nav__link">
    Format
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#parameters_25" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns-see-zdnn-statuses-for-descriptions" class="md-nav__link">
    Returns (see zDNN Statuses for descriptions)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#framework-examples" class="md-nav__link">
    Framework Examples
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zdnn_sub" class="md-nav__link">
    zdnn_sub
  </a>
  
    <nav class="md-nav" aria-label="zdnn_sub">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#description_28" class="md-nav__link">
    Description
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#format_28" class="md-nav__link">
    Format
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#parameters_26" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns-see-zdnn-statuses-for-descriptions_1" class="md-nav__link">
    Returns (see zDNN Statuses for descriptions)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#framework-examples_1" class="md-nav__link">
    Framework Examples
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zdnn_mul" class="md-nav__link">
    zdnn_mul
  </a>
  
    <nav class="md-nav" aria-label="zdnn_mul">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#description_29" class="md-nav__link">
    Description
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#format_29" class="md-nav__link">
    Format
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#parameters_27" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns-see-zdnn-statuses-for-descriptions_2" class="md-nav__link">
    Returns (see zDNN Statuses for descriptions)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#framework-examples_2" class="md-nav__link">
    Framework Examples
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zdnn_div" class="md-nav__link">
    zdnn_div
  </a>
  
    <nav class="md-nav" aria-label="zdnn_div">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#description_30" class="md-nav__link">
    Description
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#format_30" class="md-nav__link">
    Format
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#parameters_28" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns-see-zdnn-statuses-for-descriptions_3" class="md-nav__link">
    Returns (see zDNN Statuses for descriptions)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#framework-examples_3" class="md-nav__link">
    Framework Examples
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zdnn_min" class="md-nav__link">
    zdnn_min
  </a>
  
    <nav class="md-nav" aria-label="zdnn_min">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#description_31" class="md-nav__link">
    Description
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#format_31" class="md-nav__link">
    Format
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#parameters_29" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns-see-zdnn-statuses-for-descriptions_4" class="md-nav__link">
    Returns (see zDNN Statuses for descriptions)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#framework-examples_4" class="md-nav__link">
    Framework Examples
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zdnn_max" class="md-nav__link">
    zdnn_max
  </a>
  
    <nav class="md-nav" aria-label="zdnn_max">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#description_32" class="md-nav__link">
    Description
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#format_32" class="md-nav__link">
    Format
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#parameters_30" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns-see-zdnn-statuses-for-descriptionss" class="md-nav__link">
    Returns (see zDNN Statuses for descriptions)s
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#framework-examples_5" class="md-nav__link">
    Framework Examples
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zdnn_log" class="md-nav__link">
    zdnn_log
  </a>
  
    <nav class="md-nav" aria-label="zdnn_log">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#description_33" class="md-nav__link">
    Description
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#format_33" class="md-nav__link">
    Format
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#parameters_31" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns-see-zdnn-statuses-for-descriptions_5" class="md-nav__link">
    Returns (see zDNN Statuses for descriptions)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#framework-examples_6" class="md-nav__link">
    Framework Examples
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zdnn_exp" class="md-nav__link">
    zdnn_exp
  </a>
  
    <nav class="md-nav" aria-label="zdnn_exp">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#description_34" class="md-nav__link">
    Description
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#format_34" class="md-nav__link">
    Format
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#parameters_32" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns-see-zdnn-statuses-for-descriptions_6" class="md-nav__link">
    Returns (see zDNN Statuses for descriptions)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#framework-examples_7" class="md-nav__link">
    Framework Examples
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#activation-operations" class="md-nav__link">
    Activation Operations 
  </a>
  
    <nav class="md-nav" aria-label="Activation Operations ">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#zdnn_relu" class="md-nav__link">
    zdnn_relu
  </a>
  
    <nav class="md-nav" aria-label="zdnn_relu">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#description_35" class="md-nav__link">
    Description
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#format_35" class="md-nav__link">
    Format
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#parameters_33" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns-see-zdnn-statuses-for-descriptions_7" class="md-nav__link">
    Returns (see zDNN Statuses for descriptions)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#framework-examples_8" class="md-nav__link">
    Framework Examples
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zdnn_tanh" class="md-nav__link">
    zdnn_tanh
  </a>
  
    <nav class="md-nav" aria-label="zdnn_tanh">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#description_36" class="md-nav__link">
    Description
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#format_36" class="md-nav__link">
    Format
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#parameters_34" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns-see-zdnn-statuses-for-descriptions_8" class="md-nav__link">
    Returns (see zDNN Statuses for descriptions)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#framework-examples_9" class="md-nav__link">
    Framework Examples
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zdnn_sigmoid" class="md-nav__link">
    zdnn_sigmoid
  </a>
  
    <nav class="md-nav" aria-label="zdnn_sigmoid">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#description_37" class="md-nav__link">
    Description
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#format_37" class="md-nav__link">
    Format
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#parameters_35" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns-see-zdnn-statuses-for-descriptions_9" class="md-nav__link">
    Returns (see zDNN Statuses for descriptions)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#framework-examples_10" class="md-nav__link">
    Framework Examples
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zdnn_softmax" class="md-nav__link">
    zdnn_softmax
  </a>
  
    <nav class="md-nav" aria-label="zdnn_softmax">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#description_38" class="md-nav__link">
    Description
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#format_38" class="md-nav__link">
    Format
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#parameters_36" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#programming-notes_6" class="md-nav__link">
    Programming Notes
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns-see-zdnn-statuses-for-descriptions_10" class="md-nav__link">
    Returns (see zDNN Statuses for descriptions)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#framework-examples_11" class="md-nav__link">
    Framework Examples
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#normalization-operations" class="md-nav__link">
    Normalization Operations 
  </a>
  
    <nav class="md-nav" aria-label="Normalization Operations ">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#zdnn_meanreduce2d" class="md-nav__link">
    zdnn_meanreduce2d
  </a>
  
    <nav class="md-nav" aria-label="zdnn_meanreduce2d">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#description_39" class="md-nav__link">
    Description
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#format_39" class="md-nav__link">
    Format
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#parameters_37" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns-see-zdnn-statuses-for-descriptions_11" class="md-nav__link">
    Returns (see zDNN Statuses for descriptions)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#framework-examples_12" class="md-nav__link">
    Framework Examples
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zdnn_batchnorm" class="md-nav__link">
    zdnn_batchnorm
  </a>
  
    <nav class="md-nav" aria-label="zdnn_batchnorm">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#description_40" class="md-nav__link">
    Description
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#format_40" class="md-nav__link">
    Format
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#parameters_38" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns-see-zdnn-statuses-for-descriptions_12" class="md-nav__link">
    Returns (see zDNN Statuses for descriptions)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#framework-examples_13" class="md-nav__link">
    Framework Examples
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zdnn_matmul_op" class="md-nav__link">
    zdnn_matmul_op
  </a>
  
    <nav class="md-nav" aria-label="zdnn_matmul_op">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#description_41" class="md-nav__link">
    Description
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#format_41" class="md-nav__link">
    Format
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#input-output-matmul-tensor-requirements" class="md-nav__link">
    Input / Output matmul tensor requirements 
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#parameters_39" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#programming-notes_7" class="md-nav__link">
    Programming Notes
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns-see-zdnn-statuses-for-descriptions_13" class="md-nav__link">
    Returns (see zDNN Statuses for descriptions)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#framework-examples_14" class="md-nav__link">
    Framework Examples
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zdnn_matmul_bcast_op" class="md-nav__link">
    zdnn_matmul_bcast_op
  </a>
  
    <nav class="md-nav" aria-label="zdnn_matmul_bcast_op">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#description_42" class="md-nav__link">
    Description
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#format_42" class="md-nav__link">
    Format
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#input-output-matmul-broadcast-tensor-requirements" class="md-nav__link">
    Input / Output matmul broadcast tensor requirements 
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#parameters_40" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#programming-notes_8" class="md-nav__link">
    Programming Notes
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns-see-zdnn-statuses-for-descriptions_14" class="md-nav__link">
    Returns (see zDNN Statuses for descriptions)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#framework-examples_15" class="md-nav__link">
    Framework Examples
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zdnn_lstm" class="md-nav__link">
    zdnn_lstm
  </a>
  
    <nav class="md-nav" aria-label="zdnn_lstm">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#description_43" class="md-nav__link">
    Description
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#format_43" class="md-nav__link">
    Format
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lstm-input-output-requirements" class="md-nav__link">
    LSTM Input / Output requirements
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#parameters_41" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#summary" class="md-nav__link">
    Summary
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns-see-zdnn-statuses-for-descriptions_15" class="md-nav__link">
    Returns (see zDNN Statuses for descriptions)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#framework-examples_16" class="md-nav__link">
    Framework Examples
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zdnn_gru" class="md-nav__link">
    zdnn_gru
  </a>
  
    <nav class="md-nav" aria-label="zdnn_gru">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#description_44" class="md-nav__link">
    Description
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#format_44" class="md-nav__link">
    Format
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gru-input-output-requirements" class="md-nav__link">
    GRU Input / Output requirements
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#parameters_42" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#summary_1" class="md-nav__link">
    Summary
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns-see-zdnn-statuses-for-descriptions_16" class="md-nav__link">
    Returns (see zDNN Statuses for descriptions)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#framework-examples_17" class="md-nav__link">
    Framework Examples
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zdnn_avgpool2d" class="md-nav__link">
    zdnn_avgpool2d
  </a>
  
    <nav class="md-nav" aria-label="zdnn_avgpool2d">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#description_45" class="md-nav__link">
    Description
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#format_45" class="md-nav__link">
    Format
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#parameters_43" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#avgpool2d-parameter-restrictions" class="md-nav__link">
    AvgPool2D Parameter Restrictions 
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#programming-notes_9" class="md-nav__link">
    Programming Notes
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns-see-zdnn-statuses-for-descriptions_17" class="md-nav__link">
    Returns (see zDNN Statuses for descriptions)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#framework-examples_18" class="md-nav__link">
    Framework Examples
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zdnn_maxpool2d" class="md-nav__link">
    zdnn_maxpool2d
  </a>
  
    <nav class="md-nav" aria-label="zdnn_maxpool2d">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#description_46" class="md-nav__link">
    Description
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#format_46" class="md-nav__link">
    Format
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#parameters_44" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#maxpool2d-parameter-restrictions" class="md-nav__link">
    MaxPool2D Parameter Restrictions 
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#programming-notes_10" class="md-nav__link">
    Programming Notes
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns-see-zdnn-statuses-for-descriptions_18" class="md-nav__link">
    Returns (see zDNN Statuses for descriptions)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#framework-examples_19" class="md-nav__link">
    Framework Examples
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zdnn_conv2d" class="md-nav__link">
    zdnn_conv2d
  </a>
  
    <nav class="md-nav" aria-label="zdnn_conv2d">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#description_47" class="md-nav__link">
    Description
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#format_47" class="md-nav__link">
    Format
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#parameters_45" class="md-nav__link">
    Parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#convolution-2d-requirements" class="md-nav__link">
    Convolution 2D Requirements
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#returns-see-zdnn-statuses-for-descriptions_19" class="md-nav__link">
    Returns (see zDNN Statuses for descriptions)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#framework-examples_20" class="md-nav__link">
    Framework Examples
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#convenience-functions" class="md-nav__link">
    Convenience Functions
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#usage-examples" class="md-nav__link">
    Usage Examples
  </a>
  
    <nav class="md-nav" aria-label="Usage Examples">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#example-flow-of-an-application-calling-the-zdnn-apis" class="md-nav__link">
    Example flow of an application calling the zDNN APIs
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#example-of-an-application-calling-the-zdnn_lstm-api-forward" class="md-nav__link">
    Example of an application calling the zdnn_lstm API (forward)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#example-of-an-application-calling-the-zdnn_lstm-api-bi-directional" class="md-nav__link">
    Example of an application calling the zdnn_lstm API (bi-directional)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#example-of-an-application-calling-the-zdnn_lstm-api-multi-layer-bi-directional" class="md-nav__link">
    Example of an application calling the zdnn_lstm API (multi-layer bi-directional)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#example-of-an-application-calling-the-zdnn_gru-api-forward" class="md-nav__link">
    Example of an application calling the zdnn_gru API (forward)
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content" data-md-component="content">
            <article class="md-content__inner md-typeset">
              
                
  <a href="https://github.com/IBM/ai-on-z-101/edit/master/docs/zDNN/README.md" title="Edit this page" class="md-content__button md-icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25Z"/></svg>
  </a>



<h1 id="zdnn-api-reference">zDNN API Reference<a class="headerlink" href="#zdnn-api-reference" title="Permanent link">&para;</a></h1>
<h2 id="contacts">Contacts<a class="headerlink" href="#contacts" title="Permanent link">&para;</a></h2>
<ul>
<li>Nicholas Marion (nmarion@us.ibm.com)</li>
<li>Andreas Krebbel (krebbel@linux.ibm.com)</li>
</ul>
<h2 id="version">Version<a class="headerlink" href="#version" title="Permanent link">&para;</a></h2>
<p>0.4.0</p>
<h2 id="table-of-contents">Table of Contents <a id="TOC"></a><a class="headerlink" href="#table-of-contents" title="Permanent link">&para;</a></h2>
<ol>
<li><a href="#overview">Overview</a></li>
<li><a href="#environment">Environment</a></li>
<li>
<p><a href="#common-types-and-structs">Common Data Types and Structs</a></p>
</li>
<li>
<p><a href="#common-version-info">Version Information</a></p>
</li>
<li><a href="#common-ztensor">zDNN zTensor</a><ul>
<li><a href="#gen-zten-reqs">General zTensor Requirements</a></li>
<li><a href="#concat-zten-reqs">Concatenated zTensor Requirements</a></li>
</ul>
</li>
<li><a href="#common-descriptors">zDNN Tensor Descriptors</a></li>
<li><a href="#common-layouts">zDNN Data Layouts</a></li>
<li><a href="#common-formats">zDNN Data Formats</a></li>
<li><a href="#common-types">zDNN Data Types</a></li>
<li>
<p><a href="#common-statuses">zDNN Statuses</a></p>
</li>
<li>
<p><a href="#env-vars">Runtime Environment Variables</a></p>
</li>
<li>
<p><a href="#api-reference">API Reference</a></p>
</li>
<li>
<p><a href="#support-functions">Support Functions</a></p>
</li>
<li><a href="#data-transformation">Data Transformation</a></li>
<li>
<p><a href="#operations">Operations</a></p>
<ul>
<li><a href="#elwise-ops">Element-wise</a></li>
<li><a href="#act-ops">Activation</a></li>
<li><a href="#norm-ops">Normalization</a></li>
<li><a href="#zdnn_matmul_op">Matmul with Operation</a></li>
<li><a href="#zdnn_matmul_bcast_op">Matmul Broadcast with Operation</a></li>
<li><a href="#zdnn_lstm">LSTM</a></li>
<li><a href="#zdnn_gru">GRU</a></li>
<li><a href="#zdnn_avgpool2d">Average Pool 2D</a></li>
<li><a href="#zdnn_maxpool2d">Max Pool 2D</a></li>
<li><a href="#zdnn_conv2d">Convolution 2D</a></li>
</ul>
</li>
<li>
<p><a href="#convenience-functions">Convenience Functions</a></p>
</li>
<li>
<p><a href="#usage-examples">Usage Examples</a></p>
</li>
</ol>
<h2 id="overview">Overview<a class="headerlink" href="#overview" title="Permanent link">&para;</a></h2>
<p><strong>Deep Learning Library</strong> - the deep learning library support (zDNN) is the SW
enablement technology provided by IBM to meet the following requirements:</p>
<ul>
<li>Specialized-function-assist instructions are intended to provide performance
  improvements for specific operations used in software libraries, utilities,
  and operating system (OS) services. The facilities and instructions described
  as specialized-function-assist instructions may be replaced or removed in the
  future. As such, the IBM recommendation for these instructions is that a
  software library or operating system function be used instead of directly
  accessing the instructions. This is the function provided by zDNN.</li>
<li>zAIU has very complex data layout requirements; these requirements arrange the
  tensor to enhance the performance characteristics of the operations. zDNN will
  format the tensor appropriately on behalf of the caller, and it will do so
  using an optimized approach.</li>
<li>For deep learning operations, zAIU requires the use of an internal data type
  (DLFLOAT16). This is a 2-byte data type, similar in concept to Brain
  float (BFLOAT); that is, it is an AI optimized format that is used to speed up
  training and inference (from 4-byte formats) while minimizing the loss of
  accuracy at inference time.</li>
</ul>
<p>The zDNN library will provide a set of APIs that an exploiter will utilize to
drive the desired request. zDNN will be available on both z/OS and Linux on Z;
the inclusion of Linux on Z provides particular benefit, as it will allow us to
enable acceleration in frameworks for z/OS via z/OS Container Extensions (zCX).</p>
<hr />
<h2 id="environment">Environment<a class="headerlink" href="#environment" title="Permanent link">&para;</a></h2>
<p>z/OS:</p>
<ul>
<li>Problem state</li>
<li>AMODE64</li>
<li>XPLINK</li>
</ul>
<h3 id="alignment-requirements">Alignment requirements<a class="headerlink" href="#alignment-requirements" title="Permanent link">&para;</a></h3>
<h4 id="aiu-op-limits">AIU Op Limits<a class="headerlink" href="#aiu-op-limits" title="Permanent link">&para;</a></h4>
<p><em>This implies a zDNN limitation as well at this point.</em></p>
<ul>
<li>
<p>For all ops:</p>
</li>
<li>
<p>Number of elements in any dimension must not exceed the value returned by
    <code>zdnn_get_nnpa_max_dim_idx_size()</code></p>
</li>
<li>Total number of bytes required for storing a transformed tensor must not
    exceed the value returned by <code>zdnn_get_nnpa_max_tensor_size()</code></li>
</ul>
<h3 id="application-interfaces-for-zaiu-enterprise-neural-network-inference">Application interfaces for zAIU Enterprise Neural Network Inference<a class="headerlink" href="#application-interfaces-for-zaiu-enterprise-neural-network-inference" title="Permanent link">&para;</a></h3>
<h4 id="zdnn-general">zDNN General<a class="headerlink" href="#zdnn-general" title="Permanent link">&para;</a></h4>
<p>The zDNN deep learning library provides the standard IBM Z software interface to
the zAIU. This IBM-provided C library provides a set of functions that handle
the data transformation requirements of the AIU and provide wrapper functions
for the NNPA instruction primitives.</p>
<p>The zDNN functions use the following criteria to determine if zAIU can be used
to accelerate a deep learning primitive:</p>
<ul>
<li>Neural Network Processing Assist (NNPA) facility indicator in the system STFLE
  output.</li>
<li>Output of the NNPA-QAF (Query Available Functions) request.</li>
</ul>
<h4 id="using-zdnn">Using zDNN<a class="headerlink" href="#using-zdnn" title="Permanent link">&para;</a></h4>
<p>To use the IBM-provided zDNN C library for the NNPA instruction, follow these
steps:</p>
<ol>
<li>Link or re-link applications to use the IBM-provided zDNN. The IBM-provided
   zDNN is a library file in the z/OS UNIX System Services file system and can
   be statically or dynamically linked into your applications. The paths for the
   zDNN archive file and the zDNN header files are:</li>
</ol>
<p><strong>z/OS (LE required):</strong> Path for 64-bit dynamic library files:</p>
<ul>
<li><code>/lib/libzdnn.so</code></li>
<li><code>/lib/libzdnn.x</code></li>
</ul>
<p>Path for the zDNN header files:</p>
<ul>
<li><code>/usr/include/</code></li>
</ul>
<p>The XL C/C++ compiler and the z/OS Language Environment provide various
environment variables to control processing, in addition to the variables
provided by the zDNN library itself.</p>
<ol>
<li>
<p>Use the environment variable <code>_CEE_RUNOPTS</code> to specify invocation Language
   Environment runtime options. For more information about using the environment
   variable <code>_CEE_RUNOPTS</code> and other C and LE variables, see z/OS XL C/C++
   Programming Guide.</p>
</li>
<li>
<p>For environment variables accepted by the zDNN library, see
   <a href="#env-vars">Runtime Environment Variables</a>.</p>
</li>
</ol>
<p><strong>Linux on Z:</strong></p>
<p>On Linux on Z we expect to ship source as well a package-installable
library and header. The library installation will conform to the standards of
the packaging method chosen.</p>
<hr />
<h2 id="common-types-and-structs">Common Types and Structs<a class="headerlink" href="#common-types-and-structs" title="Permanent link">&para;</a></h2>
<p>Include Files: <code>zdnn.h</code></p>
<h3 id="version-information">Version Information <a id="common-version-info"></a><a class="headerlink" href="#version-information" title="Permanent link">&para;</a></h3>
<p><a href="#TOC">Back to Table of Contents</a></p>
<div class="highlight"><pre><span></span><code>#define ZDNN_VERSION &quot;0.4.0&quot;
#define ZDNN_VERNUM 0x000400 // 0x[major][minor][patch]
#define ZDNN_VER_MAJOR 0
#define ZDNN_VER_MINOR 4
#define ZDNN_VER_PATCH 0
</code></pre></div>
<ol>
<li>zDNN major version (<em>ZDNN_VER_MAJOR</em>) will be incremented if any backwards
   incompatible changes are introduced to the API. It may also include minor and
   patch level changes. Patch and minor version will be reset to 0 when major
   version is incremented.</li>
<li>zDNN minor version (<em>ZDNN_VER_MINOR</em>) will be incremented if new, backwards
   compatible functionalities are introduced to the API or if any API
   functionalities are marked as deprecated. It may also include patch level
   changes. Patch version will be reset to 0 when minor version is incremented.</li>
<li>zDNN patch version (<em>ZDNN_VER_PATCH</em>) will be incremented if only backwards
   compatible bug fixes are introduced. A bug fix being defined as an internal
   change that fixes incorrect behavior.</li>
</ol>
<p>Functions for checking version incompatibility with the zDNN load library are
provided and described in the <a href="#support-functions">Support Functions</a> section.</p>
<h3 id="zdnn-ztensor">zDNN zTensor <a id="common-ztensor"></a><a class="headerlink" href="#zdnn-ztensor" title="Permanent link">&para;</a></h3>
<p><a href="#TOC">Back to Table of Contents</a></p>
<div class="highlight"><pre><span></span><code>typedef struct zdnn_ztensor {
  zdnn_tensor_desc
      *pre_transformed_desc; // tensor&#39;s shape information before transformation
  zdnn_tensor_desc *transformed_desc; // transformed tensor&#39;s shape information
  uint64_t buffer_size;               // tensor size in bytes
  void *buffer;                       // pointer to the tensor in memory
  bool is_transformed; // indicator if data in buffer has been transformed
  char reserved[31];   // not currently used, should contain zeros.
} zdnn_ztensor;
</code></pre></div>
<h4 id="general-ztensor-requirements">General zTensor Requirements <a id="gen-zten-reqs"></a><a class="headerlink" href="#general-ztensor-requirements" title="Permanent link">&para;</a></h4>
<p><a href="#TOC">Back to Table of Contents</a></p>
<ul>
<li><code>buffer</code> requirements:</li>
<li>Calling <a href="#zdnn_init_ztensor_with_malloc">zdnn_init_ztensor_with_malloc</a>
    automatically allocates and sets a valid <code>buffer</code> for a tensor.</li>
<li><code>buffer</code> field must point to storage allocated of sufficient size to contain
    the transformed tensor data described by the its <code>transformed_desc</code> field.<ul>
<li>Calling <a href="#zdnn_getsize_ztensor">zdnn_getsize_ztensor</a> with the tensor's
  <code>transformed_desc</code> returns the required size.</li>
</ul>
</li>
<li>Start of <code>buffer</code> field must be 4k aligned.</li>
<li><code>reserved</code> should contain zeros, otherwise the program may not operate
  compatibly in the future.</li>
<li>Calling <a href="#zdnn_init_ztensor">zdnn_init_ztensor</a> or
    <a href="#zdnn_init_ztensor_with_malloc">zdnn_init_ztensor_with_malloc</a> will set
    <code>reserved</code> to zeros.</li>
</ul>
<h4 id="concatenated-ztensor-requirements">Concatenated zTensor Requirements <a id="concat-zten-reqs"></a><a class="headerlink" href="#concatenated-ztensor-requirements" title="Permanent link">&para;</a></h4>
<p><a href="#TOC">Back to Table of Contents</a></p>
<ul>
<li>For use with weights/biases/hidden-weights/hidden-biases RNN-gates tensors.</li>
<li>You must use
  <a href="#zdnn_generate_transformed_desc_concatenated">zdnn_generate_transformed_desc_concatenated</a>
  with the appropriate concatenation info</li>
<li>Do not use <code>zdnn_generate_transformed_desc</code> with concatenated tensors</li>
<li>The pre-transformed shape dimensions should not include the concatenation.</li>
<li>Thus, the pre-transformed shape should be that of a single gate, not the
    shape of the combined gates</li>
<li>Afterward transform with <a href="#zdnn_transform_ztensor">zdnn_transform_ztensor</a> as
  normal</li>
<li>Must follow <a href="#gen-zten-reqs">general tensor requirements</a></li>
</ul>
<h3 id="zdnn-tensor-descriptors">zDNN Tensor Descriptors <a id="common-descriptors"></a><a class="headerlink" href="#zdnn-tensor-descriptors" title="Permanent link">&para;</a></h3>
<p><a href="#TOC">Back to Table of Contents</a></p>
<div class="highlight"><pre><span></span><code>typedef struct zdnn_tensor_desc {
  zdnn_data_layouts layout; // data layout
  zdnn_data_formats format; // internal use only
  zdnn_data_types type;     // data type
  uint32_t dim4;            // number of elements in outermost dimension
  uint32_t dim3;            // ... outer dimension
  uint32_t dim2;            // ... inner dimension
  uint32_t dim1;            // number of elements in innermost dimension
} zdnn_tensor_desc;
</code></pre></div>
<h4 id="programming-notes">Programming Notes<a class="headerlink" href="#programming-notes" title="Permanent link">&para;</a></h4>
<ul>
<li>Helper methods
  <a href="#zdnn_init_pre_transformed_desc">zdnn_init_pre_transformed_desc</a> and
  <a href="#zdnn_generate_transformed_desc">zdnn_generate_transformed_desc</a> or
  <a href="#zdnn_generate_transformed_desc_concatenated">zdnn_generate_transformed_desc_concatenated</a>
  will set the correct dims based on the layout and format.</li>
<li>The <a href="#common-layouts">layout</a> of the tensor descriptor affects the expected
  order of the dims. For example:</li>
<li>For tensors with less than 4 dimensions, unspecified dims:<ul>
<li>In the <a href="#common-ztensor">pre_transformed_desc</a> are ignored. For example a
  <a href="#common-layouts">ZDNN_3D</a> expects values in dim4, dim3, and dim2.</li>
<li>In the <a href="#common-ztensor">transformed_desc</a> "unused" dims must be 1.</li>
</ul>
</li>
<li>A <a href="#common-layouts">ZDNN_NCHW</a> expects dims such that dim4 = N, dim3 = H,
    dim2 = W, dim1 = C</li>
<li>A <a href="#common-layouts">ZDNN_HWCK</a> expects dims such that dim4 = W, dim3 = W,
    dim2 = C, dim1 = K</li>
<li>The <a href="#common-formats">format</a> changes the expected dims order for
  <a href="#common-layouts">ZDNN_4D</a> tensors layouts</li>
<li><a href="#common-formats">ZDNN_FORMAT_4DFEATURE</a> expects dims such that dim4 = N,
    dim3 = H, dim2 = W, dim1 = C</li>
<li><a href="#common-formats">ZDNN_FORMAT_4DKERNEL</a> expects dims such that dim4 = H,
    dim3 = W, dim2 = C, dim1 = K</li>
</ul>
<h3 id="zdnn-data-layouts">zDNN Data Layouts <a id="common-layouts"></a><a class="headerlink" href="#zdnn-data-layouts" title="Permanent link">&para;</a></h3>
<p><a href="#TOC">Back to Table of Contents</a></p>
<p>The following are layouts for zDNN ztensor descriptors. These indicate the
number and order of dimensions to expect for the ztensor data.</p>
<div class="highlight"><pre><span></span><code>typedef enum zdnn_data_layouts {
  ZDNN_1D,          // 1d tensor
  ZDNN_2D,          // 2d tensor
  ZDNN_2DS,         // represents special 2D tensors required by LSTM/GRU
  ZDNN_3D,          // 3d tensor
  ZDNN_3DS,         // represents special 3D tensors required by
                    // LSTM/GRU/Softmax/Matmul
  ZDNN_ZRH,         // represents (update, reset, hidden) used by GRU
  ZDNN_4D,          // 4d tensor
  ZDNN_4DS,         // represents special 4D tensors required by LSTM/GRU output
  ZDNN_NHWC,        // 4d feature tensor in NHWC
  ZDNN_NCHW,        // 4d feature tensor in NCHW
  ZDNN_FICO,        // represents (forget, input, cell, output) used by LSTM
  ZDNN_HWCK,        // 4d kernel CNN tensor
  ZDNN_BIDIR_ZRH,   // ZRH variant to work with bidirectional LSTM/GRU output
  ZDNN_BIDIR_FICO  // FICO variant to work with bidirectional LSTM/GRU output
} zdnn_data_layouts;
</code></pre></div>
<p>Some layouts also indicate special re-arrangement of the data during ztensor
transformation.</p>
<ul>
<li><code>ZDNN_2DS</code> - The outermost dimension of the original shape is promoted to dim4
  during transformation. For example, a shape of (a, b) becomes [a, 1, 1, b]
  (dim4, dim3, dim2, dim1) in the <code>transformed_desc</code></li>
<li><code>ZDNN_3DS</code> - The outermost dimension of the original shape is promoted to dim4
  during transformation. For example, a shape of (a, b, c) becomes [a, 1, b, c]
  (dim4, dim3, dim2, dim1) in the <code>transformed_desc</code></li>
<li><code>ZDNN_4DS</code> - Arrangement for RNN output tensor</li>
</ul>
<p>The followings are set automatically in <code>transformed_desc</code> based on <code>info</code> when
calling <code>zdnn_generate_transformed_desc_concatenated()</code>:</p>
<ul>
<li><code>ZDNN_ZRH/FICO</code> - During transformation, the RNN input gates data are
  concatenated on the innermost dimension. Supported with
  <code>pre_transformed_layout</code> of <code>ZDNN_2DS</code> or <code>ZDNN_3DS</code>.</li>
<li><code>ZDNN_BIDIR_ZRH/FICO</code> - Similar to <code>ZDNN_ZRH/FICO</code>, used when:</li>
<li>transforming RNN input weight gate data, and</li>
<li>the input tensor for the current RNN layer is a bidirectional RNN output
     from a previous RNN layer</li>
</ul>
<h3 id="zdnn-data-formats">zDNN Data Formats <a id="common-formats"></a><a class="headerlink" href="#zdnn-data-formats" title="Permanent link">&para;</a></h3>
<p><a href="#TOC">Back to Table of Contents</a></p>
<div class="highlight"><pre><span></span><code>typedef enum zdnn_data_formats {
  ZDNN_FORMAT_4DFEATURE, // tensor in AIU data layout format 0
  ZDNN_FORMAT_4DKERNEL, // tensor in AIU data layout format 1
} zdnn_data_formats;
</code></pre></div>
<h3 id="zdnn-data-types">zDNN Data Types <a id="common-types"></a><a class="headerlink" href="#zdnn-data-types" title="Permanent link">&para;</a></h3>
<p><a href="#TOC">Back to Table of Contents</a></p>
<div class="highlight"><pre><span></span><code>typedef enum zdnn_data_types {
  ZDNN_DLFLOAT16, // 16-bit deep learning format
  BFLOAT, // Brain floating point format
  FP16, // 16-bit IEEE-754 floating point format
  FP32, // 32-bit IEEE-754 floating point format
} zdnn_data_types;
</code></pre></div>
<h3 id="zdnn-statuses">zDNN Statuses <a id="common-statuses"></a><a class="headerlink" href="#zdnn-statuses" title="Permanent link">&para;</a></h3>
<p><a href="#TOC">Back to Table of Contents</a></p>
<!-- prettier-ignore -->
<table>
<thead>
<tr>
<th>Mnemonic Constant</th>
<th>Value</th>
<th>Meaning</th>
</tr>
</thead>
<tbody>
<tr>
<td>ZDNN_OK</td>
<td>0x00000000</td>
<td>Success.</td>
</tr>
</tbody>
</table>
<h4 id="warning-statuses">Warning Statuses <a id="warning-statuses"></a><a class="headerlink" href="#warning-statuses" title="Permanent link">&para;</a></h4>
<!-- prettier-ignore -->
<table>
<thead>
<tr>
<th>Mnemonic Constant</th>
<th>Value</th>
<th>Meaning</th>
</tr>
</thead>
<tbody>
<tr>
<td>ZDNN_ELEMENT_RANGE_VIOLATION</td>
<td>0x00020001</td>
<td>AIU operation resulted in data that was out of the normal range.</td>
</tr>
</tbody>
</table>
<p><em>Note: ZDNN_ELEMENT_RANGE_VIOLATION indicates a <strong>range violation</strong> occurred for
the AIU operation based on the data in the tensors. This usually indicates an
overflow of the NNPA internal data type, but can also be associated with
operation specific errors, such as "divide by zero". See the "z/Architecture
Principles of Operation" for information about range violation on the operation
that encountered the violation.</em></p>
<h4 id="general-failing-statuses">General Failing Statuses <a id="failing-statuses"></a><a class="headerlink" href="#general-failing-statuses" title="Permanent link">&para;</a></h4>
<!-- prettier-ignore -->
<table>
<thead>
<tr>
<th>Mnemonic Constant</th>
<th>Value</th>
<th>Meaning</th>
</tr>
</thead>
<tbody>
<tr>
<td>ZDNN_INVALID_SHAPE*</td>
<td>0x00040001</td>
<td>Invalid shape information in one (or more) of the input/output tensor(s).</td>
</tr>
<tr>
<td>ZDNN_INVALID_LAYOUT</td>
<td>0x00040002</td>
<td>Invalid layout information in one (or more) of the input/output tensor(s).</td>
</tr>
<tr>
<td>ZDNN_INVALID_TYPE*</td>
<td>0x00040003</td>
<td>Invalid type information in one (or more) of the input/output tensor(s).</td>
</tr>
<tr>
<td>ZDNN_INVALID_FORMAT*</td>
<td>0x00040004</td>
<td>Invalid format information in one (or more) of the input/output tensor(s).</td>
</tr>
<tr>
<td>ZDNN_INVALID_DIRECTION</td>
<td>0x00040005</td>
<td>Invalid RNN direction.</td>
</tr>
<tr>
<td>ZDNN_INVALID_CONCAT_INFO</td>
<td>0x00040006</td>
<td>Invalid concatenation info.</td>
</tr>
<tr>
<td>ZDNN_INVALID_STRIDE_PADDING*</td>
<td>0x00040007</td>
<td>Invalid padding type parameter for current strides.</td>
</tr>
<tr>
<td>ZDNN_INVALID_STRIDES*</td>
<td>0x00040008</td>
<td>Invalid stride height or width parameter.</td>
</tr>
<tr>
<td>ZDNN_MISALIGNED_PARMBLOCK*</td>
<td>0x00040009</td>
<td>NNPA parameter block is not on double word boundary.</td>
</tr>
<tr>
<td>ZDNN_INVALID_CLIPPING_VALUE</td>
<td>0x0004000A</td>
<td>Invalid clipping for the specified operation.</td>
</tr>
<tr>
<td>ZDNN_ALLOCATION_FAILURE</td>
<td>0x00100001</td>
<td>Can not allocate storage.</td>
</tr>
<tr>
<td>ZDNN_INVALID_BUFFER</td>
<td>0x00100002</td>
<td>Buffer address is NULL or not on 4K-byte boundary or insufficient buffer size.</td>
</tr>
<tr>
<td>ZDNN_CONVERT_FAILURE</td>
<td>0x00100003</td>
<td>Floating point data conversion failure.</td>
</tr>
<tr>
<td>ZDNN_INVALID_STATE</td>
<td>0x00100004</td>
<td>Invalid zTensor state.</td>
</tr>
<tr>
<td>ZDNN_UNSUPPORTED_AIU_EXCEPTION</td>
<td>0x00100005</td>
<td>AIU operation returned an unexpected exception.</td>
</tr>
</tbody>
</table>
<p><em>Note: *In certain scenarios, these statuses are returned only if
<a href="#env-vars">ZDNN_ENABLE_PRECHECK</a> is enabled. When not enabled, these scenarios
will lead to abnormal program termination.</em></p>
<h4 id="hardware-statuses">Hardware Statuses <a id="hw-statuses"></a><a class="headerlink" href="#hardware-statuses" title="Permanent link">&para;</a></h4>
<p>The following statuses indicate issues returned from the hardware.</p>
<!-- prettier-ignore -->
<table>
<thead>
<tr>
<th>Mnemonic Constant</th>
<th>Value</th>
<th>Meaning</th>
</tr>
</thead>
<tbody>
<tr>
<td>ZDNN_UNSUPPORTED_PARMBLOCK</td>
<td>0x000C0001</td>
<td>NNPA parameter block format is not supported by the model.</td>
</tr>
<tr>
<td>ZDNN_UNAVAILABLE_FUNCTION</td>
<td>0x000C0002</td>
<td>Specified NNPA function is not defined or installed on the machine.</td>
</tr>
<tr>
<td>ZDNN_UNSUPPORTED_FORMAT</td>
<td>0x000C0010</td>
<td>Specified tensor data layout format is not supported.</td>
</tr>
<tr>
<td>ZDNN_UNSUPPORTED_TYPE</td>
<td>0x000C0011</td>
<td>Specified tensor data type is not supported.</td>
</tr>
<tr>
<td>ZDNN_EXCEEDS_MDIS</td>
<td>0x000C0012</td>
<td>Tensor dimension exceeds maximum dimension index size (MDIS).</td>
</tr>
<tr>
<td>ZDNN_EXCEEDS_MTS</td>
<td>0x000C0013</td>
<td>Total number of bytes in tensor exceeds maximum tensor size. (MTS).</td>
</tr>
<tr>
<td>ZDNN_MISALIGNED_TENSOR</td>
<td>0x000C0014</td>
<td>Tensor address is not on 4K-byte boundary.</td>
</tr>
<tr>
<td>ZDNN_MISALIGNED_SAVEAREA</td>
<td>0x000C0015</td>
<td>Function specific save area address is not on 4K-byte boundary.</td>
</tr>
</tbody>
</table>
<p>The meaning of the following hardware statuses vary based on operation. See the
operation that returned the status for the specific meaning.</p>
<!-- prettier-ignore -->
<table>
<thead>
<tr>
<th>Mnemonic Constant</th>
<th>Value</th>
<th>Meaning</th>
</tr>
</thead>
<tbody>
<tr>
<td>ZDNN_FUNC_RC_F000</td>
<td>0x000CF000</td>
<td>Function specific response code (F000).</td>
</tr>
<tr>
<td>ZDNN_FUNC_RC_F001</td>
<td>0x000CF001</td>
<td>Function specific response code (F001).</td>
</tr>
<tr>
<td>ZDNN_FUNC_RC_F002</td>
<td>0x000CF002</td>
<td>Function specific response code (F002).</td>
</tr>
<tr>
<td>ZDNN_FUNC_RC_F003</td>
<td>0x000CF003</td>
<td>Function specific response code (F003).</td>
</tr>
<tr>
<td>ZDNN_FUNC_RC_F004</td>
<td>0x000CF004</td>
<td>Function specific response code (F004).</td>
</tr>
<tr>
<td>ZDNN_FUNC_RC_F005</td>
<td>0x000CF005</td>
<td>Function specific response code (F005).</td>
</tr>
<tr>
<td>ZDNN_FUNC_RC_F006</td>
<td>0x000CF006</td>
<td>Function specific response code (F006).</td>
</tr>
<tr>
<td>ZDNN_FUNC_RC_F007</td>
<td>0x000CF007</td>
<td>Function specific response code (F007).</td>
</tr>
<tr>
<td>ZDNN_FUNC_RC_F008</td>
<td>0x000CF008</td>
<td>Function specific response code (F008).</td>
</tr>
<tr>
<td>ZDNN_FUNC_RC_F009</td>
<td>0x000CF009</td>
<td>Function specific response code (F009).</td>
</tr>
</tbody>
</table>
<hr />
<h2 id="runtime-environment-variables">Runtime Environment Variables <a id="env-vars"></a><a class="headerlink" href="#runtime-environment-variables" title="Permanent link">&para;</a></h2>
<p><a href="#TOC">Back to Table of Contents</a></p>
<ul>
<li><code>ZDNN_ENABLE_PRECHECK</code>: true/false</li>
<li>If set to <code>true</code>, tensor integrity prechecks are run before issuing NNPA
    operations.</li>
<li>Enabling precheck may impact performance.</li>
<li>Enable to debug issues which cause hardware exceptions that otherwise would
    result in abnormal program termination.</li>
<li><code>ZDNN_STATUS_DIAG</code>: nnnnnnnn (decimal) or 0xnnnnnnnn (hexadecimal)</li>
<li>Prints or produces diagnostic information whenever zDNN status code is equal
    to the specified value. Only one status value can be specified.</li>
</ul>
<p><em>The following are only available when the zDNN library was built with
<code>ZDNN_CONFIG_DEBUG</code> enabled.</em></p>
<ul>
<li><code>ZDNN_LOGLEVEL</code>: off/fatal/error/warn/info/debug/trace</li>
<li>Sets logging facility's output level</li>
<li><code>ZDNN_LOGMODULE</code>: module name(s)</li>
<li>Produces log output only when the issuer's module name is in the list. You
    may specify multiple module names by separating them with either commas or
    spaces.</li>
</ul>
<h3 id="programming-notes_1">Programming Notes<a class="headerlink" href="#programming-notes_1" title="Permanent link">&para;</a></h3>
<ul>
<li>Environment variables settings are checked during initial library load by
  <a href="#zdnn_init">zdnn_init</a>.</li>
<li>To change environment variable settings afterward, <a href="#zdnn_init">zdnn_init</a>
  must be called again manually.</li>
</ul>
<hr />
<h2 id="api-reference">API Reference<a class="headerlink" href="#api-reference" title="Permanent link">&para;</a></h2>
<p><a href="#TOC">Back to Table of Contents</a></p>
<ul>
<li><a href="#support-functions">Support Functions</a></li>
<li><a href="#data-transformation">Data Transformation</a></li>
<li><a href="#operations">Operations</a></li>
<li><a href="#convenience-functions">Convenience Functions</a></li>
</ul>
<hr />
<h2 id="support-functions">Support Functions<a class="headerlink" href="#support-functions" title="Permanent link">&para;</a></h2>
<p><a href="#TOC">Back to Table of Contents</a></p>
<ul>
<li><a href="#zdnn_init">Initialization</a></li>
<li><a href="#zdnn_get_nnpa_max_dim_idx_size">Query</a></li>
<li><a href="#zdnn_getsize_ztensor">Get Size</a></li>
<li><a href="#zdnn_init_pre_transformed_desc">Initialize pre-transformed tensor descriptor</a></li>
<li><a href="#zdnn_generate_transformed_desc">Generate transformed tensor descriptor</a></li>
<li><a href="#zdnn_generate_transformed_desc_concatenated">Generate concatenated transformed tensor descriptor</a></li>
<li><a href="#zdnn_init_ztensor">Initialize zTensor</a></li>
<li><a href="#zdnn_init_ztensor_with_malloc">Initialize zTensor with memory allocate</a></li>
<li><a href="#zdnn_reset_ztensor">Reset zTensor</a></li>
<li><a href="#zdnn_allochelper_ztensor">Allocate memory for zTensor</a></li>
<li><a href="#zdnn_free_ztensor_buffer">De-allocate memory for zTensor</a></li>
<li><a href="#zdnn_get_status_message">Retrieve status message of the status code</a></li>
<li><a href="#zdnn_reshape_ztensor">Reshape zTensor</a></li>
<li><a href="#zdnn_is_version_runnable">Check if version is runnable</a></li>
<li><a href="#zdnn_get_max_runnable_version">Get maximum runnable version</a></li>
</ul>
<hr />
<h3 id="zdnn_init">zdnn_init<a class="headerlink" href="#zdnn_init" title="Permanent link">&para;</a></h3>
<h4 id="description">Description<a class="headerlink" href="#description" title="Permanent link">&para;</a></h4>
<p>Initialize the zDNN library. This sends an NNPA_QAF to query the NNPA and loads
the current environment variable settings.</p>
<p>This needs to be invoked at least once if zDNN library is statically-linked. It
is automatically invoked if zDNN library is dynamically loaded.</p>
<h4 id="format">Format<a class="headerlink" href="#format" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code>void zdnn_init();
</code></pre></div>
<h4 id="parameters">Parameters<a class="headerlink" href="#parameters" title="Permanent link">&para;</a></h4>
<p>None</p>
<h4 id="returns">Returns<a class="headerlink" href="#returns" title="Permanent link">&para;</a></h4>
<p>None</p>
<hr />
<h3 id="zdnn_get_nnpa_max_dim_idx_size">zdnn_get_nnpa_max_dim_idx_size<a class="headerlink" href="#zdnn_get_nnpa_max_dim_idx_size" title="Permanent link">&para;</a></h3>
<h4 id="description_1">Description<a class="headerlink" href="#description_1" title="Permanent link">&para;</a></h4>
<p>Retrieve the maximum dimension index size value currently supported by the AIU
from zDNN's internal memory.</p>
<h4 id="format_1">Format<a class="headerlink" href="#format_1" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code>uint32_t zdnn_get_nnpa_max_dim_idx_size();
</code></pre></div>
<h4 id="parameters_1">Parameters<a class="headerlink" href="#parameters_1" title="Permanent link">&para;</a></h4>
<p>None</p>
<h4 id="returns_1">Returns<a class="headerlink" href="#returns_1" title="Permanent link">&para;</a></h4>
<p>Maximum dimension index size supported by the AIU</p>
<hr />
<h3 id="zdnn_get_nnpa_max_tensor_size">zdnn_get_nnpa_max_tensor_size<a class="headerlink" href="#zdnn_get_nnpa_max_tensor_size" title="Permanent link">&para;</a></h3>
<h4 id="description_2">Description<a class="headerlink" href="#description_2" title="Permanent link">&para;</a></h4>
<p>Retrieve the maximum tensor size value (number of bytes required for storing a
transformed tensor) currently supported by the AIU from zDNN's internal memory.</p>
<h4 id="format_2">Format<a class="headerlink" href="#format_2" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code>uint64_t zdnn_get_nnpa_max_tensor_size();
</code></pre></div>
<h4 id="parameters_2">Parameters<a class="headerlink" href="#parameters_2" title="Permanent link">&para;</a></h4>
<p>None</p>
<h4 id="returns_2">Returns<a class="headerlink" href="#returns_2" title="Permanent link">&para;</a></h4>
<p>Maximum tensor size supported by the AIU</p>
<hr />
<h3 id="zdnn_is_nnpa_installed">zdnn_is_nnpa_installed<a class="headerlink" href="#zdnn_is_nnpa_installed" title="Permanent link">&para;</a></h3>
<h4 id="description_3">Description<a class="headerlink" href="#description_3" title="Permanent link">&para;</a></h4>
<p>Interrogates the hardware to determine if the NNPA and NNP-internal data type
(DLFLOAT16) conversion instructions are installed.</p>
<p>Use this function during application initialization to determine whether the AIU
hardware is available.</p>
<h4 id="format_3">Format<a class="headerlink" href="#format_3" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code>bool zdnn_is_nnpa_installed();
</code></pre></div>
<h4 id="parameters_3">Parameters<a class="headerlink" href="#parameters_3" title="Permanent link">&para;</a></h4>
<ul>
<li>None.</li>
</ul>
<h4 id="returns_3">Returns<a class="headerlink" href="#returns_3" title="Permanent link">&para;</a></h4>
<p><code>true</code> if NNPA and zdnn conversion instructions are installed, <code>false</code>
otherwise.</p>
<hr />
<h3 id="zdnn_is_nnpa_function_installed">zdnn_is_nnpa_function_installed<a class="headerlink" href="#zdnn_is_nnpa_function_installed" title="Permanent link">&para;</a></h3>
<h4 id="description_4">Description<a class="headerlink" href="#description_4" title="Permanent link">&para;</a></h4>
<p>Query, from zDNN internal memory, if requested NNPA functions are available.</p>
<h4 id="format_4">Format<a class="headerlink" href="#format_4" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code>bool zdnn_is_nnpa_function_installed(int count, ...);
</code></pre></div>
<h4 id="parameters_4">Parameters<a class="headerlink" href="#parameters_4" title="Permanent link">&para;</a></h4>
<ul>
<li>
<p><code>int count</code></p>
</li>
<li>
<p>number of NNPA functions to check</p>
</li>
<li>
<p><code>... (additional arguments)</code></p>
</li>
<li>
<p>Function names separated by commas, e.g., <em>NNPA_MUL, NNPA_MIN</em></p>
</li>
</ul>
<div class="highlight"><pre><span></span><code>NNPA_QAF
NNPA_ADD
NNPA_SUB
NNPA_MUL
NNPA_DIV
NNPA_MIN
NNPA_MAX
NNPA_LOG
NNPA_EXP
NNPA_RELU
NNPA_TANH
NNPA_SIGMOID
NNPA_SOFTMAX
NNPA_BATCHNORMALIZATION
NNPA_MAXPOOL2D
NNPA_AVGPOOL2D
NNPA_LSTMACT
NNPA_GRUACT
NNPA_CONVOLUTION
NNPA_MATMUL_OP
NNPA_MATMUL_OP_BCAST23
</code></pre></div>
<h4 id="returns_4">Returns<a class="headerlink" href="#returns_4" title="Permanent link">&para;</a></h4>
<p><code>true</code> if all queried formats are installed or if <code>count</code> is zero, <code>false</code>
otherwise.</p>
<hr />
<h3 id="zdnn_is_nnpa_parmblk_fmt_installed">zdnn_is_nnpa_parmblk_fmt_installed<a class="headerlink" href="#zdnn_is_nnpa_parmblk_fmt_installed" title="Permanent link">&para;</a></h3>
<h4 id="description_5">Description<a class="headerlink" href="#description_5" title="Permanent link">&para;</a></h4>
<p>Query, from zDNN internal memory, if requested parameter block formats are
installed.</p>
<h4 id="format_5">Format<a class="headerlink" href="#format_5" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code>bool zdnn_is_nnpa_parmblk_fmt_installed(int count, ...);
</code></pre></div>
<h4 id="parameters_5">Parameters<a class="headerlink" href="#parameters_5" title="Permanent link">&para;</a></h4>
<ul>
<li>
<p><code>int count</code></p>
</li>
<li>
<p>number of NNPA parameter block formats to check</p>
</li>
<li>
<p><code>... (additional arguments)</code></p>
</li>
<li>
<p>NNPA parameter block formats separated by commas</p>
</li>
</ul>
<div class="highlight"><pre><span></span><code>NNPA_PARMBLKFORMAT_0
</code></pre></div>
<h4 id="returns_5">Returns<a class="headerlink" href="#returns_5" title="Permanent link">&para;</a></h4>
<p><code>true</code> if all queried formats are installed or if <code>count</code> is zero, <code>false</code>
otherwise.</p>
<hr />
<h3 id="zdnn_is_nnpa_datatype_installed">zdnn_is_nnpa_datatype_installed<a class="headerlink" href="#zdnn_is_nnpa_datatype_installed" title="Permanent link">&para;</a></h3>
<h4 id="description_6">Description<a class="headerlink" href="#description_6" title="Permanent link">&para;</a></h4>
<p>Query, from zDNN internal memory, if requested NNPA data type are installed.</p>
<h4 id="format_6">Format<a class="headerlink" href="#format_6" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code>bool zdnn_is_nnpa_datatype_installed(uint16_t types_bitmask);
</code></pre></div>
<h4 id="parameters_6">Parameters<a class="headerlink" href="#parameters_6" title="Permanent link">&para;</a></h4>
<ul>
<li>
<p><code>uint16_t types_bitmask</code></p>
</li>
<li>
<p>OR'd type bitmasks as defined in zdnn_query_datatypes enum</p>
</li>
</ul>
<div class="highlight"><pre><span></span><code>QUERY_DATATYPE_INTERNAL1
</code></pre></div>
<h4 id="returns_6">Returns<a class="headerlink" href="#returns_6" title="Permanent link">&para;</a></h4>
<p><code>true</code> if all queried data types are installed, <code>false</code> otherwise.</p>
<hr />
<h3 id="zdnn_is_nnpa_layout_fmt_installed">zdnn_is_nnpa_layout_fmt_installed<a class="headerlink" href="#zdnn_is_nnpa_layout_fmt_installed" title="Permanent link">&para;</a></h3>
<h4 id="description_7">Description<a class="headerlink" href="#description_7" title="Permanent link">&para;</a></h4>
<p>Query, from zDNN internal memory, if requested NNPA data layout format are
installed.</p>
<h4 id="format_7">Format<a class="headerlink" href="#format_7" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code>bool zdnn_is_nnpa_layout_fmt_installed(uint32_t layout_bitmask);
</code></pre></div>
<h4 id="parameters_7">Parameters<a class="headerlink" href="#parameters_7" title="Permanent link">&para;</a></h4>
<ul>
<li>
<p><code>uint32_t layout_bitmask</code></p>
</li>
<li>
<p>OR'd layout bitmasks as defined in zdnn_query_layoutfmts enum</p>
</li>
</ul>
<div class="highlight"><pre><span></span><code>QUERY_LAYOUTFMT_4DFEATURE
QUERY_LAYOUTFMT_4DKERNEL
</code></pre></div>
<h4 id="returns_7">Returns<a class="headerlink" href="#returns_7" title="Permanent link">&para;</a></h4>
<p><code>true</code> if all queried data layouts are installed, <code>false</code> otherwise.</p>
<hr />
<h3 id="zdnn_is_nnpa_conversion_installed">zdnn_is_nnpa_conversion_installed<a class="headerlink" href="#zdnn_is_nnpa_conversion_installed" title="Permanent link">&para;</a></h3>
<h4 id="description_8">Description<a class="headerlink" href="#description_8" title="Permanent link">&para;</a></h4>
<p>Query, from zDNN internal memory, if requested NNPA data-type to/from BFP format
conversions are installed.</p>
<h4 id="format_8">Format<a class="headerlink" href="#format_8" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code>bool zdnn_is_nnpa_conversion_installed(nnpa_data_type type,
                                       uint16_t format_bitmask);
</code></pre></div>
<h4 id="parameters_8">Parameters<a class="headerlink" href="#parameters_8" title="Permanent link">&para;</a></h4>
<ul>
<li>
<p><code>nnpa_data_type type</code></p>
</li>
<li>
<p>NNPA data-type number as defined in nnpa_data_type enum</p>
</li>
</ul>
<div class="highlight"><pre><span></span><code>NNPA_DATATYPE_1
</code></pre></div>
<ul>
<li>
<p><code>uint16_t format_bitmask</code></p>
</li>
<li>
<p>OR'd BFP format bitmasks as defined in zdnn_query_bfpfmts enum</p>
</li>
</ul>
<div class="highlight"><pre><span></span><code>QUERY_BFPFMT_TINY (FP16)
QUERY_BFPFMT_SHORT (FP32/BFLOAT)
</code></pre></div>
<h4 id="returns_8">Returns<a class="headerlink" href="#returns_8" title="Permanent link">&para;</a></h4>
<p><code>true</code> if all queried conversions are installed, <code>false</code> otherwise.</p>
<hr />
<h3 id="zdnn_get_library_version">zdnn_get_library_version<a class="headerlink" href="#zdnn_get_library_version" title="Permanent link">&para;</a></h3>
<h4 id="description_9">Description<a class="headerlink" href="#description_9" title="Permanent link">&para;</a></h4>
<p>Retrieve library version number as a 32-bit hex value
(<code>0x00[major][minor][patch]</code>).</p>
<h4 id="format_9">Format<a class="headerlink" href="#format_9" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code>uint32_t zdnn_get_library_version();
</code></pre></div>
<h4 id="returns_9">Returns<a class="headerlink" href="#returns_9" title="Permanent link">&para;</a></h4>
<p>Library version number in <code>0x00[major][minor][patch]</code> format.</p>
<hr />
<h3 id="zdnn_get_library_version_str">zdnn_get_library_version_str<a class="headerlink" href="#zdnn_get_library_version_str" title="Permanent link">&para;</a></h3>
<h4 id="description_10">Description<a class="headerlink" href="#description_10" title="Permanent link">&para;</a></h4>
<p>Retrieve the library version number and build information as a string.</p>
<h4 id="format_10">Format<a class="headerlink" href="#format_10" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code>char *zdnn_get_library_version_str();
</code></pre></div>
<h4 id="returns_10">Returns<a class="headerlink" href="#returns_10" title="Permanent link">&para;</a></h4>
<p>Library version number and build information as a string.</p>
<hr />
<h3 id="zdnn_refresh_nnpa_query_result">zdnn_refresh_nnpa_query_result<a class="headerlink" href="#zdnn_refresh_nnpa_query_result" title="Permanent link">&para;</a></h3>
<h4 id="description_11">Description<a class="headerlink" href="#description_11" title="Permanent link">&para;</a></h4>
<p>Refresh zDNN in-memory query result from zAIU.</p>
<h4 id="format_11">Format<a class="headerlink" href="#format_11" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code>zdnn_status zdnn_refresh_nnpa_query_result();
</code></pre></div>
<h4 id="parameters_9">Parameters<a class="headerlink" href="#parameters_9" title="Permanent link">&para;</a></h4>
<p>None</p>
<h5 id="programming-notes_2">Programming Notes<a class="headerlink" href="#programming-notes_2" title="Permanent link">&para;</a></h5>
<p>This is called automatically as a part of <code>zdnn_init</code> and should not need to be
called directly. Manually refreshing query results before making other
<code>zdnn_query_*</code> calls may noticeably impact performance.</p>
<h4 id="returns-zdnn_status-indications">Returns zdnn_status indications<a class="headerlink" href="#returns-zdnn_status-indications" title="Permanent link">&para;</a></h4>
<ul>
<li><code>ZDNN_OK</code></li>
<li><code>ZDNN_UNAVAILABLE_FUNCTION</code></li>
</ul>
<hr />
<h3 id="zdnn_getsize_ztensor">zdnn_getsize_ztensor<a class="headerlink" href="#zdnn_getsize_ztensor" title="Permanent link">&para;</a></h3>
<h4 id="description_12">Description<a class="headerlink" href="#description_12" title="Permanent link">&para;</a></h4>
<p>Used to determine the buffer size required for the transformed tensor (including
concatenated) in zDNN transformed format. Requires tensor descriptor
(<code>zdnn_tensor_desc</code>) with transformed shape information.</p>
<h4 id="format_12">Format<a class="headerlink" href="#format_12" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code>uint64_t zdnn_getsize_ztensor(const zdnn_tensor_desc *tfrmd_desc);
</code></pre></div>
<h4 id="parameters_10">Parameters<a class="headerlink" href="#parameters_10" title="Permanent link">&para;</a></h4>
<ul>
<li>
<p><code>zdnn_tensor_desc *tfrmd_desc</code></p>
</li>
<li>
<p>Contains transformed information about the shape, layout and data type.</p>
</li>
</ul>
<h4 id="returns-zdnn_status-indications_1">Returns zdnn_status indications<a class="headerlink" href="#returns-zdnn_status-indications_1" title="Permanent link">&para;</a></h4>
<ul>
<li>required buffer size in bytes</li>
</ul>
<hr />
<h3 id="zdnn_init_pre_transformed_desc">zdnn_init_pre_transformed_desc<a class="headerlink" href="#zdnn_init_pre_transformed_desc" title="Permanent link">&para;</a></h3>
<h4 id="description_13">Description<a class="headerlink" href="#description_13" title="Permanent link">&para;</a></h4>
<p>Initialize tensor descriptor (<code>zdnn_tensor_desc</code>) struct with pre-transformed
(original) shape information.</p>
<h4 id="format_13">Format<a class="headerlink" href="#format_13" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code>void zdnn_init_pre_transformed_desc(zdnn_data_layouts layout,
                                    zdnn_data_types type,
                                    zdnn_tensor_desc *pre_tfrmd_desc, ...);
</code></pre></div>
<h4 id="parameters_11">Parameters<a class="headerlink" href="#parameters_11" title="Permanent link">&para;</a></h4>
<ul>
<li>
<p><code>zdnn_data_layouts layout</code></p>
</li>
<li>
<p>data layout</p>
</li>
<li>
<p><code>zdnn_data_types type</code></p>
</li>
<li>
<p>data type</p>
</li>
<li>
<p><code>zdnn_tensor_desc *pre_tfrmd_desc</code></p>
</li>
<li>
<p>output zdnn_tensor_desc struct</p>
</li>
<li>
<p><code>... (additional arguments)</code></p>
</li>
<li>
<p>Variadic: number of elements in each dimension in accordance to the layout,
    in outermost to innermost order</p>
</li>
</ul>
<h4 id="returns_11">Returns<a class="headerlink" href="#returns_11" title="Permanent link">&para;</a></h4>
<ul>
<li>None</li>
</ul>
<hr />
<h3 id="zdnn_generate_transformed_desc">zdnn_generate_transformed_desc<a class="headerlink" href="#zdnn_generate_transformed_desc" title="Permanent link">&para;</a></h3>
<h4 id="description_14">Description<a class="headerlink" href="#description_14" title="Permanent link">&para;</a></h4>
<p>Generate transformed tensor descriptor information based on supplied
pre-transformed tensor descriptor.</p>
<h4 id="format_14">Format<a class="headerlink" href="#format_14" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code>zdnn_status zdnn_generate_transformed_desc(
    const zdnn_tensor_desc *pre_tfrmd_desc, zdnn_tensor_desc *tfrmd_desc);
</code></pre></div>
<h4 id="parameters_12">Parameters<a class="headerlink" href="#parameters_12" title="Permanent link">&para;</a></h4>
<ul>
<li>
<p><code>zdnn_tensor_desc *pre_tfrmd_desc</code></p>
</li>
<li>
<p>input tensor descriptor with pre-transformed shape information</p>
</li>
<li>
<p><code>zdnn_tensor_desc *tfrmd_desc</code></p>
</li>
<li>
<p>output <code>zdnn_tensor_desc</code> struct</p>
</li>
</ul>
<h4 id="zdnn_status-indications">zdnn_status indications<a class="headerlink" href="#zdnn_status-indications" title="Permanent link">&para;</a></h4>
<ul>
<li><code>ZDNN_OK</code></li>
<li><code>ZDNN_INVALID_LAYOUT</code> - pre-transformed <code>layout</code> is not recognized or is a
  layout only used for concatenated tensors.</li>
</ul>
<hr />
<h3 id="zdnn_generate_transformed_desc_concatenated">zdnn_generate_transformed_desc_concatenated<a class="headerlink" href="#zdnn_generate_transformed_desc_concatenated" title="Permanent link">&para;</a></h3>
<h4 id="description_15">Description<a class="headerlink" href="#description_15" title="Permanent link">&para;</a></h4>
<p>Generate concatenated transformed tensor descriptor information for RNN
input-gates tensors based on a supplied pre-transformed tensor descriptor.</p>
<h4 id="format_15">Format<a class="headerlink" href="#format_15" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code>zdnn_status zdnn_generate_transformed_desc_concatenated(
    const zdnn_tensor_desc *pre_tfrmd_desc,
    zdnn_concat_info info, zdnn_tensor_desc *tfrmd_desc);
</code></pre></div>
<h4 id="parameters_13">Parameters<a class="headerlink" href="#parameters_13" title="Permanent link">&para;</a></h4>
<ul>
<li>
<p><code>zdnn_tensor_desc *pre_tfrmd_desc</code></p>
</li>
<li>
<p>input tensor descriptor with pre-transformed shape information</p>
</li>
<li>
<p><code>zdnn_concat_info info</code></p>
</li>
<li>
<p>Information about how the tensors will be concatenated, consists of the
    RNN_TYPE, PREV_LAYER and USAGE flags OR'd together:</p>
<p>RNN_TYPE flags:</p>
<ul>
<li>RNN_TYPE_LSTM - For LSTM</li>
<li>RNN_TYPE_GRU - For GRU</li>
</ul>
<p>PREV_LAYER flags:</p>
<ul>
<li>PREV_LAYER_UNI - Previous RNN layer is uni-directional</li>
<li>PREV_LAYER_NONE - Previous layer is not a RNN layer</li>
<li>PREV_LAYER_BIDIR - Previous RNN layer is bi-directional</li>
</ul>
<p>USAGE flags:</p>
<ul>
<li>USAGE_WEIGHTS - Concatenate as input weights</li>
<li>USAGE_HIDDEN_WEIGHTS - Concatenate as input hidden-weights</li>
<li>USAGE_BIASES - Concatenate as input biases</li>
<li>USAGE_HIDDEN_BIASES - Concatenate as input hidden-biases</li>
</ul>
</li>
<li>
<p><code>zdnn_tensor_desc *tfrmd_desc</code></p>
</li>
<li>
<p>output <code>zdnn_tensor_desc</code> struct</p>
</li>
</ul>
<h4 id="zdnn_status-indications_1">zdnn_status indications<a class="headerlink" href="#zdnn_status-indications_1" title="Permanent link">&para;</a></h4>
<ul>
<li><code>ZDNN_OK</code></li>
<li><code>ZDNN_INVALID_LAYOUT</code> - pre-transformed <code>layout</code> is not recognized or is not
  supported for concatenated tensors.</li>
<li><code>ZDNN_INVALID_CONCAT_INFO</code> - invalid concatenation information.</li>
</ul>
<hr />
<h3 id="zdnn_init_ztensor">zdnn_init_ztensor<a class="headerlink" href="#zdnn_init_ztensor" title="Permanent link">&para;</a></h3>
<h4 id="description_16">Description<a class="headerlink" href="#description_16" title="Permanent link">&para;</a></h4>
<p>Initialize a <code>zdnn_ztensor</code> struct using the pre-transformed and transformed
tensor shape information</p>
<h4 id="format_16">Format<a class="headerlink" href="#format_16" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code>void zdnn_init_ztensor(zdnn_tensor_desc *pre_tfrmd_desc,
                       zdnn_tensor_desc *tfrmd_desc, zdnn_ztensor *output);
</code></pre></div>
<h4 id="parameters_14">Parameters<a class="headerlink" href="#parameters_14" title="Permanent link">&para;</a></h4>
<ul>
<li>
<p><code>zdnn_tensor_desc *pre_tfrmd_desc</code></p>
</li>
<li>
<p>input tensor descriptor with pre-transformed shape information</p>
</li>
<li>
<p><code>zdnn_tensor_desc *tfrmd_desc</code></p>
</li>
<li>
<p>input tensor descriptor with transformed shape information</p>
</li>
<li>
<p><code>zdnn_ztensor *output</code></p>
</li>
<li>
<p>The <code>zdnn_ztensor</code> struct being initialized.</p>
</li>
</ul>
<h4 id="returns_12">Returns<a class="headerlink" href="#returns_12" title="Permanent link">&para;</a></h4>
<ul>
<li>None</li>
</ul>
<hr />
<h3 id="zdnn_init_ztensor_with_malloc">zdnn_init_ztensor_with_malloc<a class="headerlink" href="#zdnn_init_ztensor_with_malloc" title="Permanent link">&para;</a></h3>
<h4 id="description_17">Description<a class="headerlink" href="#description_17" title="Permanent link">&para;</a></h4>
<p>Same functionality as <code>zdnn_init_ztensor</code>, and computes the size required for
the tensor in the zDNN transformed format and allocates the storage for it. Sets
<code>buffer</code> and <code>buffer_size</code> fields within <code>output</code>.</p>
<h4 id="format_17">Format<a class="headerlink" href="#format_17" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code>zdnn_status zdnn_init_ztensor_with_malloc(zdnn_tensor_desc *pre_tfrmd_desc,
                                          zdnn_tensor_desc *tfrmd_desc,
                                          zdnn_ztensor *output);
</code></pre></div>
<h4 id="parameters_15">Parameters<a class="headerlink" href="#parameters_15" title="Permanent link">&para;</a></h4>
<ul>
<li>
<p><code>zdnn_tensor_desc *pre_tfrmd_desc</code></p>
</li>
<li>
<p>input tensor descriptor with pre-transformed shape information</p>
</li>
<li>
<p><code>zdnn_tensor_desc *tfrmd_desc</code></p>
</li>
<li>
<p>input tensor descriptor with transformed shape information</p>
</li>
<li>
<p><code>zdnn_ztensor *output</code></p>
</li>
<li>
<p>The <code>zdnn_ztensor</code> struct being initialized.</p>
</li>
</ul>
<h4 id="returns-zdnn_status-indications_2">Returns zdnn_status indications<a class="headerlink" href="#returns-zdnn_status-indications_2" title="Permanent link">&para;</a></h4>
<ul>
<li><code>ZDNN_OK</code></li>
<li><code>ZDNN_INVALID_FORMAT</code> - <code>tfrmd_desc-&gt;format</code> is not recognized.</li>
<li><code>ZDNN_INVALID_TYPE</code> - <code>tfrmd_desc-&gt;type</code> is not recognized or is a
  pre_tfrmd_desc type.</li>
<li><code>ZDNN_INVALID_SHAPE</code> - (if any of the following are true)</li>
<li>One of <code>tfrmd_desc-&gt;dim*</code> dimensions is 0.</li>
<li>One of <code>tfrmd_desc-&gt;dim*</code> dimensions is greater than
    <code>zdnn_get_nnpa_max_dim_idx_size</code>.<ul>
<li>Note: concatenation dimensions have a smaller maximum size. See
  <a href="#lstm-hid_sz">LSTM</a> or <a href="#gru-hid_sz">GRU</a>.</li>
</ul>
</li>
<li>The total number of tfrmd_desc elements is larger than
    <code>zdnn_get_nnpa_max_tensor_size</code>.</li>
<li><code>ZDNN_ALLOCATION_FAILURE</code> - Unable to allocate required memory on a 4K
  boundary.</li>
</ul>
<hr />
<h3 id="zdnn_reset_ztensor">zdnn_reset_ztensor<a class="headerlink" href="#zdnn_reset_ztensor" title="Permanent link">&para;</a></h3>
<h4 id="description_18">Description<a class="headerlink" href="#description_18" title="Permanent link">&para;</a></h4>
<p>Reset a <code>zdnn_ztensor</code> struct for reuse.</p>
<p><em>Note this operation does not set or reset the <code>buffer</code> and <code>buffer_size</code> fields
nor free the transformed area storage.</em></p>
<h4 id="format_18">Format<a class="headerlink" href="#format_18" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code>void zdnn_reset_ztensor(zdnn_ztensor *ztensor);
</code></pre></div>
<h4 id="parameters_16">Parameters<a class="headerlink" href="#parameters_16" title="Permanent link">&para;</a></h4>
<ul>
<li>
<p><code>zdnn_ztensor *output</code></p>
</li>
<li>
<p>The <code>zdnn_ztensor</code> struct being reset.</p>
</li>
</ul>
<h4 id="returns_13">Returns<a class="headerlink" href="#returns_13" title="Permanent link">&para;</a></h4>
<ul>
<li>None</li>
</ul>
<hr />
<h3 id="zdnn_allochelper_ztensor">zdnn_allochelper_ztensor<a class="headerlink" href="#zdnn_allochelper_ztensor" title="Permanent link">&para;</a></h3>
<h4 id="description_19">Description<a class="headerlink" href="#description_19" title="Permanent link">&para;</a></h4>
<p>Calculate the size required for the tensor in the zDNN transformed format and
allocate the needed storage, satisfying alignment requirements. Sets <code>buffer</code>
and <code>buffer_size</code> fields within <code>ztensor</code>.</p>
<p><em>Note that the calling application assumes ownership of this storage and is
responsible for freeing it.</em></p>
<h4 id="format_19">Format<a class="headerlink" href="#format_19" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code>zdnn_status zdnn_allochelper_ztensor(zdnn_ztensor *ztensor);
</code></pre></div>
<h4 id="parameters_17">Parameters<a class="headerlink" href="#parameters_17" title="Permanent link">&para;</a></h4>
<ul>
<li>
<p><code>zdnn_ztensor *ztensor</code></p>
</li>
<li>
<p>A <code>zdnn_ztensor</code> struct that contains the transformed shape information in
    the <code>transformed_desc</code> field.</p>
</li>
</ul>
<h4 id="returns-zdnn_status-indications_3">Returns zdnn_status indications<a class="headerlink" href="#returns-zdnn_status-indications_3" title="Permanent link">&para;</a></h4>
<ul>
<li><code>ZDNN_OK</code></li>
<li><code>ZDNN_INVALID_FORMAT</code> - <code>ztensor-&gt;transformed_desc-&gt;format</code> is not recognized.</li>
<li><code>ZDNN_INVALID_TYPE</code> - <code>ztensor-&gt;transformed_desc-&gt;type</code> is not recognized or
  is a pre_transformed_desc type.</li>
<li><code>ZDNN_INVALID_SHAPE</code> - (if any of the following are true)</li>
<li>One of <code>ztensor-&gt;transformed_desc-&gt;dim*</code> dimensions is 0.</li>
<li>One of <code>ztensor-&gt;transformed_desc-&gt;dim*</code> dimensions is greater than
    <code>zdnn_get_nnpa_max_dim_idx_size</code>.<ul>
<li>Note: concatenation dimensions have a smaller maximum size. See
  <a href="#lstm-hid_sz">LSTM</a> or <a href="#gru-hid_sz">GRU</a>.</li>
</ul>
</li>
<li>The total number of transformed_desc elements is larger than
    <code>zdnn_get_nnpa_max_tensor_size</code>.</li>
<li><code>ZDNN_ALLOCATION_FAILURE</code> - Unable to allocate required memory on a 4K
  boundary.</li>
</ul>
<hr />
<h3 id="zdnn_free_ztensor_buffer">zdnn_free_ztensor_buffer<a class="headerlink" href="#zdnn_free_ztensor_buffer" title="Permanent link">&para;</a></h3>
<h4 id="description_20">Description<a class="headerlink" href="#description_20" title="Permanent link">&para;</a></h4>
<p>Given an input zdnn_ztensor, zdnn_free_ztensor_buffer will free the transformed
area storage associated with it.</p>
<p><em>Note that the routine does not free the storage allocated for the zdnn_ztensor
struct itself.</em></p>
<h4 id="format_20">Format<a class="headerlink" href="#format_20" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code>zdnn_status zdnn_free_ztensor_buffer(const zdnn_ztensor *ztensor);
</code></pre></div>
<h4 id="parameters_18">Parameters<a class="headerlink" href="#parameters_18" title="Permanent link">&para;</a></h4>
<ul>
<li>
<p><code>zdnn_ztensor *tensor</code></p>
</li>
<li>
<p>A <code>zdnn_ztensor</code> struct with field buffer pointing to storage allocated.</p>
</li>
</ul>
<h4 id="returns-zdnn_status-indications_4">Returns zdnn_status indications<a class="headerlink" href="#returns-zdnn_status-indications_4" title="Permanent link">&para;</a></h4>
<ul>
<li><code>ZDNN_OK</code></li>
<li><code>ZDNN_INVALID_BUFFER</code> - <code>tensor-&gt;buffer</code> is <code>NULL</code></li>
</ul>
<hr />
<h3 id="zdnn_get_status_message">zdnn_get_status_message<a class="headerlink" href="#zdnn_get_status_message" title="Permanent link">&para;</a></h3>
<h4 id="description_21">Description<a class="headerlink" href="#description_21" title="Permanent link">&para;</a></h4>
<p>Retrieve status message of the status code</p>
<h4 id="format_21">Format<a class="headerlink" href="#format_21" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code>const char *zdnn_get_status_message(zdnn_status status);
</code></pre></div>
<h4 id="parameters_19">Parameters<a class="headerlink" href="#parameters_19" title="Permanent link">&para;</a></h4>
<ul>
<li>
<p><code>zdnn_status status</code></p>
</li>
<li>
<p>Status code</p>
</li>
</ul>
<h4 id="returns_14">Returns<a class="headerlink" href="#returns_14" title="Permanent link">&para;</a></h4>
<p>Pointer to the description string or "(Status string is not defined.)" if
<code>status</code> is not defined.</p>
<hr />
<h3 id="zdnn_reshape_ztensor">zdnn_reshape_ztensor<a class="headerlink" href="#zdnn_reshape_ztensor" title="Permanent link">&para;</a></h3>
<h4 id="description_22">Description<a class="headerlink" href="#description_22" title="Permanent link">&para;</a></h4>
<p>Reshape and copy buffer content from source zTensor's buffer to destination
zTensor's in accordance to destination zTensor's shape.</p>
<p>The following conditions must be satisfied:</p>
<ul>
<li>Both tensor's transformed_desc must be fully initialized</li>
<li><code>dest-&gt;buffer</code> must be pre-allocated</li>
<li><code>src</code> must be transformed</li>
<li><code>dest</code> must be not already transformed</li>
<li>Both <code>transformed_desc-&gt;layout</code> must be the same and either NHWC or HWCK</li>
<li>Both zTensors must contain equal number of elements</li>
</ul>
<h4 id="format_22">Format<a class="headerlink" href="#format_22" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code>zdnn_status zdnn_reshape_ztensor(const zdnn_ztensor *src, zdnn_ztensor *dest);
</code></pre></div>
<h4 id="parameters_20">Parameters<a class="headerlink" href="#parameters_20" title="Permanent link">&para;</a></h4>
<ul>
<li>
<p><code>src</code></p>
</li>
<li>
<p>Source zTensor to copy from</p>
</li>
<li>
<p><code>dest</code></p>
</li>
<li>
<p>Destination zTensor to copy to</p>
</li>
</ul>
<h4 id="programming-notes_3">Programming Notes<a class="headerlink" href="#programming-notes_3" title="Permanent link">&para;</a></h4>
<ul>
<li>
<p>If <code>src</code> and <code>dest</code> have the same <code>transformed_desc-&gt;dim1</code> dimension size, the
  transformed data is directly copied to the destination without
  untransformation.</p>
</li>
<li>
<p>If <code>src</code> and <code>dest</code> have different <code>transformed_desc-&gt;dim1</code> dimension sizes,
  reshaping will internally un-transform the source and then re-transform the
  values into the destination.</p>
</li>
</ul>
<h4 id="returns_15">Returns<a class="headerlink" href="#returns_15" title="Permanent link">&para;</a></h4>
<ul>
<li><code>ZDNN_OK</code></li>
<li><code>ZDNN_INVALID_SHAPE</code> - (if any of the following are true)</li>
<li><code>src</code>'s and <code>dest</code>'s <code>transformed_desc-&gt;dim*</code> total to different numbers of
    elements.</li>
<li>One of <code>dest-&gt;transformed_desc-&gt;dim*</code> dimensions is 0.</li>
<li>One of <code>dest-&gt;transformed_desc-&gt;dim*</code> dimensions is greater than
    <code>zdnn_get_nnpa_max_dim_idx_size</code>.<ul>
<li>Note: concatenation dimensions have a smaller maximum size. See
  <a href="#lstm-hid_sz">LSTM</a> or <a href="#gru-hid_sz">GRU</a>.</li>
</ul>
</li>
<li>The total number of <code>dest-&gt;transformed_desc-dim*</code> elements is larger than
    <code>zdnn_get_nnpa_max_tensor_size</code>.</li>
<li><code>ZDNN_INVALID_LAYOUT</code> - (if any of the following are true)</li>
<li><code>src</code>'s and <code>dest</code>'s <code>transformed_desc-&gt;layout</code> are not the same.</li>
<li><code>transformed_desc-&gt;layout</code> is not <code>ZDNN_NHWC</code> nor <code>ZDNN_HWCK</code>.</li>
<li><code>src-&gt;pre_transformed_desc-&gt;layout</code> is not recognized or is not a valid
    pre_transformed_desc layout.</li>
<li><code>dest-&gt;pre_transformed_desc-&gt;layout</code> is not recognized or is not a valid
    pre_transformed_desc layout.</li>
<li><code>ZDNN_INVALID_STATE</code> - (if any of the following are true)</li>
<li><code>src</code> is not already transformed.</li>
<li><code>dest</code> is already transformed.</li>
<li><code>ZDNN_INVALID_FORMAT</code> - <code>src-&gt;transformed_desc-&gt;format</code> is not
  <code>ZDNN_FORMAT_4DFEATURE</code>.</li>
<li><code>ZDNN_INVALID_TYPE</code> (if any of the following are true)</li>
<li><code>src-&gt;pre_transformed_desc-&gt;type</code> is not recognized or is a transformed_desc
    type.</li>
<li><code>dest-&gt;pre_transformed_desc-&gt;type</code> is not recognized or is a
    transformed_desc type.</li>
<li><code>dest-&gt;transformed_desc-&gt;type</code> is not recognized or is a
    pre_transformed_desc type.</li>
<li><code>ZDNN_INVALID_BUFFER</code> (if any of the following are true)</li>
<li><code>src-&gt;buffer</code> is <code>NULL</code>.</li>
<li><code>src-&gt;buffer</code> is not on a 4K boundary.</li>
<li><code>dest-&gt;buffer</code> is <code>NULL</code>.</li>
<li><code>dest-&gt;buffer</code> is not on a 4K boundary.</li>
<li><code>dest-&gt;buffer_size</code> is too small to hold transformed values.</li>
<li><code>ZDNN_CONVERT_FAILURE</code> - Values failed to un-transform or transform.</li>
</ul>
<hr />
<h3 id="zdnn_is_version_runnable">zdnn_is_version_runnable<a class="headerlink" href="#zdnn_is_version_runnable" title="Permanent link">&para;</a></h3>
<h4 id="description_23">Description<a class="headerlink" href="#description_23" title="Permanent link">&para;</a></h4>
<p>Check if application built for zDNN version <code>ver_num</code> can be run on the current
AIU hardware with the installed zDNN library</p>
<h4 id="format_23">Format<a class="headerlink" href="#format_23" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code>bool zdnn_is_version_runnable(uint32_t ver_num);
</code></pre></div>
<h4 id="parameters_21">Parameters<a class="headerlink" href="#parameters_21" title="Permanent link">&para;</a></h4>
<ul>
<li>
<p><code>ver_num</code></p>
</li>
<li>
<p>zDNN version number from the application in 0x00[major][minor][patch] form.
    Typically this is ZDNN_VERNUM used to compile the application</p>
</li>
</ul>
<h4 id="returns_16">Returns<a class="headerlink" href="#returns_16" title="Permanent link">&para;</a></h4>
<ul>
<li>true/false</li>
</ul>
<hr />
<h3 id="zdnn_get_max_runnable_version">zdnn_get_max_runnable_version<a class="headerlink" href="#zdnn_get_max_runnable_version" title="Permanent link">&para;</a></h3>
<h4 id="description_24">Description<a class="headerlink" href="#description_24" title="Permanent link">&para;</a></h4>
<p>Returns the maximum zDNN version number that the current hardware and installed
zDNN library can run together. The returned value means the current runtime
environment fully supports zDNN APIs set of that <code>major</code>.<code>minor</code> version and
below.</p>
<h4 id="format_24">Format<a class="headerlink" href="#format_24" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code>uint32_t zdnn_get_max_runnable_version();
</code></pre></div>
<h4 id="parameters_22">Parameters<a class="headerlink" href="#parameters_22" title="Permanent link">&para;</a></h4>
<ul>
<li>None</li>
</ul>
<h4 id="returns_17">Returns<a class="headerlink" href="#returns_17" title="Permanent link">&para;</a></h4>
<ul>
<li>A 32-bit zDNN version number in 0x00[major][minor]FF form.</li>
</ul>
<hr />
<h2 id="data-transformation">Data Transformation<a class="headerlink" href="#data-transformation" title="Permanent link">&para;</a></h2>
<p><a href="#TOC">Back to Table of Contents</a></p>
<ul>
<li><a href="#zdnn_transform_ztensor">Transform to zTensor</a></li>
<li><a href="#zdnn_transform_origtensor">Transform to Original</a></li>
</ul>
<hr />
<p>zAIU requires the tensor data to be arranged in a format that enhances the
performance characteristics of the operations. In this documentation, it is
referred to as "transformed format". In addition, data conversions are necessary
from the common formats (FP32, FP16, BFLOAT) to the internal format (DLFLOAT16)
supported by the AIU. Two functions are provided:</p>
<ul>
<li>
<p>'<code>zdnn_transform_ztensor</code></p>
</li>
<li>
<p>zdnn_transform_ztensor will transform the input tensor and convert the input
    data to the format required by the AIU. The resulting transformed ztensor
    can be reused as many times as necessary.</p>
</li>
<li>
<p>See <a href="#zdnn_transform_ztensor">zdnn_transform_ztensor</a> for details on
    transforming an input tensor to the internal format.</p>
</li>
<li>
<p><code>zdnn_transform_origtensor</code></p>
</li>
<li>
<p>zdnn_transform_origtensor transforms a ztensor (usually output from an
    operation or network) to the format and data types that are usable by the
    application.</p>
</li>
<li>
<p>See <a href="#zdnn_transform_origtensor">zdnn_transform_origtensor</a> for details on
    transforming an input tensor to the internal format.</p>
</li>
</ul>
<hr />
<h3 id="zdnn_transform_ztensor">zdnn_transform_ztensor<a class="headerlink" href="#zdnn_transform_ztensor" title="Permanent link">&para;</a></h3>
<h4 id="description_25">Description<a class="headerlink" href="#description_25" title="Permanent link">&para;</a></h4>
<p>Converts the input tensor to the supported transformed format for execution by
zdnn operations. If transformation is successful the <code>is_transformed</code> field
within <code>ztensor</code> will be set to <code>true</code> otherwise it is set to <code>false</code>.
Transformation will fail if <code>is_transformed</code> was already <code>true</code>.</p>
<p><em>Note that the tensor layout in memory, once in transformed format, is dependent
on the content of the input tensor's descriptors (<code>zdnn_tensor_desc</code> fields).
Once converted, a <code>zdnn_ztensor</code> should only be manipulated by zDNN API
functions.</em></p>
<h4 id="format_25">Format<a class="headerlink" href="#format_25" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code>zdnn_status zdnn_transform_ztensor(zdnn_ztensor *ztensor, ...);
</code></pre></div>
<h4 id="parameters_23">Parameters<a class="headerlink" href="#parameters_23" title="Permanent link">&para;</a></h4>
<ul>
<li>
<p><code>zdnn_ztensor *tensor</code></p>
</li>
<li>
<p>The input <code>zdnn_ztensor</code> struct. <code>pre_transformed_desc</code> and
    <code>transformed_desc</code> must be set, <code>is_transformed</code> must be <code>false</code>. A
    4k-aligned tensor storage must be pre-allocated by the caller (directly or
    by calling the zDNN allocation helper function) and field <code>buffer</code> must
    point to the storage.</p>
</li>
<li>
<p><code>... (additional arguments)</code></p>
</li>
<li>
<p>Variadic: list of pointers for input data to be transformed:</p>
<ul>
<li>Non-concatenated: 1 data pointer</li>
<li>LSTM concatenated: 4 data pointers, one for each input gate in Forget,
  Input, Cell, Output (FICO) order</li>
<li>GRU concatenated: 3 data pointers, one for each input gate in (Z)update,
  Reset, Hidden, (ZRH) gate order</li>
</ul>
</li>
</ul>
<h4 id="programming-notes_4">Programming Notes<a class="headerlink" href="#programming-notes_4" title="Permanent link">&para;</a></h4>
<ul>
<li>This function clears the pre-thread floating-point exception flags at entry,
  and may set <code>FE_UNDERFLOW</code> / <code>FE_INVALID</code> / <code>FE_INEXACT</code> / <code>FE_OVERFLOW</code> when
  it encounters errors during data conversion.</li>
</ul>
<h4 id="returns-zdnn_status-indications_5">Returns zdnn_status indications<a class="headerlink" href="#returns-zdnn_status-indications_5" title="Permanent link">&para;</a></h4>
<ul>
<li><code>ZDNN_OK</code></li>
<li><code>ZDNN_INVALID_FORMAT</code> - <code>zdnn_ztensor-&gt;transformed_desc-&gt;format</code> is not
  recognized.</li>
<li><code>ZDNN_INVALID_LAYOUT</code> - (if any of the following are true)</li>
<li><code>zdnn_ztensor-&gt;pre_transformed_desc-&gt;layout</code> is not recognized or is not a
    valid pre_transformed_desc layout.</li>
<li><code>zdnn_ztensor-&gt;transformed_desc-&gt;layout</code> is not recognized or is not a valid
    transformed_desc layout.</li>
<li><code>ZDNN_INVALID_TYPE</code> - (if any of the following are true)</li>
<li><code>zdnn_ztensor-&gt;pre_transformed_desc-&gt;type</code> is not recognized or is a
    transformed_desc type.</li>
<li><code>zdnn_ztensor-&gt;transformed_desc-&gt;type</code> is not recognized or is a
    pre_transformed_desc type.</li>
<li><code>ZDNN_INVALID_BUFFER</code> (if any of the following are true)</li>
<li><code>buffer</code> is <code>NULL</code>.</li>
<li><code>buffer</code> is not on a 4K boundary.</li>
<li><code>buffer_size</code> is too small to hold transformed values.</li>
<li><code>ZDNN_INVALID_SHAPE</code> - (if any of the following are true)</li>
<li>One of <code>zdnn_ztensor-&gt;transformed_desc-&gt;dim*</code> dimensions is 0.</li>
<li>One of <code>zdnn_ztensor-&gt;transformed_desc-&gt;dim*</code> dimensions is greater than
    <code>zdnn_get_nnpa_max_dim_idx_size</code>.<ul>
<li>Note: concatenation dimensions have a smaller maximum size. See
  <a href="#lstm-hid_sz">LSTM</a> or <a href="#gru-hid_sz">GRU</a>.</li>
</ul>
</li>
<li>The total number of transformed_desc elements is larger than
    <code>zdnn_get_nnpa_max_tensor_size</code>.</li>
<li><code>ZDNN_INVALID_STATE</code> - Tensor is already transformed.</li>
<li><code>ZDNN_CONVERT_FAILURE</code> - Values failed to transform.</li>
</ul>
<hr />
<h3 id="zdnn_transform_origtensor">zdnn_transform_origtensor<a class="headerlink" href="#zdnn_transform_origtensor" title="Permanent link">&para;</a></h3>
<h4 id="description_26">Description<a class="headerlink" href="#description_26" title="Permanent link">&para;</a></h4>
<p>Converts the input tensor from the zDNN transformed format back to a standard
non-transformed layout. The <code>is_transformed</code> field within <code>ztensor</code> must be
<code>true</code>.</p>
<p>All stick format tensors are supported, except:</p>
<ul>
<li>Kernel tensors</li>
<li>Concatenated RNN input-gates tensors</li>
</ul>
<h4 id="format_26">Format<a class="headerlink" href="#format_26" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code>zdnn_status zdnn_transform_origtensor(const zdnn_ztensor *ztensor, void *out_buf);
</code></pre></div>
<h4 id="parameters_24">Parameters<a class="headerlink" href="#parameters_24" title="Permanent link">&para;</a></h4>
<ul>
<li>
<p><code>zdnn_ztensor *ztensor</code></p>
</li>
<li>
<p>The input <code>zdnn_ztensor</code> struct. <code>pre_transformed_desc</code>, <code>transformed_desc</code>
    and <code>buffer</code> must be set, <code>is_transformed</code> must be <code>true</code>.</p>
</li>
<li>
<p><code>void *out_buf</code></p>
</li>
<li>
<p>The buffer for storing the standard non-transformed tensor data. Must be
    pre-allocated by the caller.</p>
</li>
</ul>
<h4 id="programming-notes_5">Programming Notes<a class="headerlink" href="#programming-notes_5" title="Permanent link">&para;</a></h4>
<ul>
<li>This function clears the pre-thread floating-point exception flags at entry,
  and may set <code>FE_UNDERFLOW</code> / <code>FE_INVALID</code> / <code>FE_INEXACT</code> / <code>FE_OVERFLOW</code> when
  it encounters errors during data conversion.</li>
</ul>
<h4 id="returns-zdnn_status-indications_6">Returns zdnn_status indications<a class="headerlink" href="#returns-zdnn_status-indications_6" title="Permanent link">&para;</a></h4>
<ul>
<li><code>ZDNN_OK</code></li>
<li><code>ZDNN_INVALID_FORMAT</code> - <code>ztensor-&gt;transformed_desc-&gt;format</code> is not
  <code>ZDNN_FORMAT_4DFEATURE</code>.</li>
<li><code>ZDNN_INVALID_LAYOUT</code> - (if any of the following are true)</li>
<li><code>zdnn_ztensor-&gt;pre_transformed_desc-&gt;layout</code> is not recognized or is not a
    valid pre_transformed_desc layout.</li>
<li><code>zdnn_ztensor-&gt;transformed_desc-&gt;layout</code> is not recognized or is not a valid
    transformed_desc layout required by this function.</li>
<li><code>ZDNN_INVALID_TYPE</code></li>
<li><code>ztensor-&gt;pre_transformed_desc-&gt;type</code> is not recognized or is a
    transformed_desc type.</li>
<li><code>ztensor-&gt;transformed_desc-&gt;type</code> is not recognized or is a
    pre_transformed_desc type.</li>
<li><code>ZDNN_INVALID_BUFFER</code> (if any of the following are true)</li>
<li><code>ztensor-&gt;buffer</code> is <code>NULL</code>.</li>
<li><code>ztensor-&gt;buffer</code> is not on a 4K boundary.</li>
<li><code>ZDNN_INVALID_STATE</code> - <code>ztensor</code> is not transformed.</li>
<li><code>ZDNN_CONVERT_FAILURE</code> - Values failed to un-transform.</li>
</ul>
<hr />
<h2 id="operations">Operations<a class="headerlink" href="#operations" title="Permanent link">&para;</a></h2>
<p>See <a href="#TOC">Table of Contents</a> for operations list</p>
<hr />
<h2 id="element-wise-operations">Element-wise Operations <a id="elwise-ops"></a><a class="headerlink" href="#element-wise-operations" title="Permanent link">&para;</a></h2>
<p><a href="#TOC">Back to Table of Contents</a></p>
<ul>
<li><a href="#zdnn_add">Addition</a></li>
<li><a href="#zdnn_sub">Subtraction</a></li>
<li><a href="#zdnn_mul">Multiplication</a></li>
<li><a href="#zdnn_div">Division</a></li>
<li><a href="#zdnn_min">Minimum</a></li>
<li><a href="#zdnn_max">Maximum</a></li>
<li><a href="#zdnn_log">Natural Logarithm</a></li>
<li><a href="#zdnn_exp">Exponential</a></li>
</ul>
<hr />
<h3 id="zdnn_add">zdnn_add<a class="headerlink" href="#zdnn_add" title="Permanent link">&para;</a></h3>
<ul>
<li><a href="#TOC">Back to Table of Contents</a></li>
<li><a href="#elwise-ops">Back to Element-wise Operations</a></li>
</ul>
<h4 id="description_27">Description<a class="headerlink" href="#description_27" title="Permanent link">&para;</a></h4>
<p>Given two input tensors in zDNN transformed format, performs element-wise
addition and stores the result into the provided output zDNN tensor.</p>
<p><em>Note that for zDNN use, broadcasting of the input tensor(s) must be performed
by the caller. As such, the input tensors must be of the same shape.</em></p>
<h4 id="format_27">Format<a class="headerlink" href="#format_27" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code>zdnn_status zdnn_add(const zdnn_ztensor *input_a, const zdnn_ztensor *input_b,
                     zdnn_ztensor *output);
</code></pre></div>
<h4 id="parameters_25">Parameters<a class="headerlink" href="#parameters_25" title="Permanent link">&para;</a></h4>
<ul>
<li>
<p><code>zdnn_ztensor *input_a</code></p>
</li>
<li>
<p>Tensor with addends to add to <code>input_b</code> tensor</p>
</li>
<li>
<p>Must follow <a href="#gen-zten-reqs">general tensor requirements</a></p>
</li>
<li>
<p><code>zdnn_ztensor *input_b</code></p>
</li>
<li>
<p>Tensor with addends to add to <code>input_a</code> tensor</p>
</li>
<li>
<p>Must follow <a href="#gen-zten-reqs">general tensor requirements</a></p>
</li>
<li>
<p><code>zdnn_ztensor *output</code></p>
</li>
<li>Tensor to hold the result of the addition</li>
<li>Must follow <a href="#gen-zten-reqs">general tensor requirements</a></li>
</ul>
<h4 id="returns-see-zdnn-statuses-for-descriptions">Returns (see <a href="#common-statuses">zDNN Statuses</a> for descriptions)<a class="headerlink" href="#returns-see-zdnn-statuses-for-descriptions" title="Permanent link">&para;</a></h4>
<ul>
<li><code>ZDNN_OK</code></li>
<li><a href="#warning-statuses">warning statuses</a></li>
<li><code>ZDNN_INVALID_SHAPE</code></li>
<li><code>ZDNN_INVALID_TYPE</code></li>
<li><code>ZDNN_INVALID_FORMAT</code></li>
<li><a href="#hw-statuses">hardware statuses</a></li>
</ul>
<h4 id="framework-examples">Framework Examples<a class="headerlink" href="#framework-examples" title="Permanent link">&para;</a></h4>
<p><a href="https://www.tensorflow.org/api_docs/python/tf/math/add">TensorFlow Addition</a></p>
<p><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Add">ONNX Addition</a></p>
<hr />
<h3 id="zdnn_sub">zdnn_sub<a class="headerlink" href="#zdnn_sub" title="Permanent link">&para;</a></h3>
<ul>
<li><a href="#TOC">Back to Table of Contents</a></li>
<li><a href="#elwise-ops">Back to Element-wise Operations</a></li>
</ul>
<h4 id="description_28">Description<a class="headerlink" href="#description_28" title="Permanent link">&para;</a></h4>
<p>Given two input tensors in zDNN transformed format, performs element-wise
subtraction and stores the result into the provided output zDNN tensor.</p>
<p><em>Note that for zDNN use, broadcasting of the input tensor(s) must be performed
by the caller. As such, the input tensors must be of the same shape.</em></p>
<h4 id="format_28">Format<a class="headerlink" href="#format_28" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code>zdnn_status zdnn_sub(const zdnn_ztensor *input_a, const zdnn_ztensor *input_b,
                     zdnn_ztensor *output);
</code></pre></div>
<h4 id="parameters_26">Parameters<a class="headerlink" href="#parameters_26" title="Permanent link">&para;</a></h4>
<ul>
<li>
<p><code>zdnn_ztensor *input_a</code></p>
</li>
<li>
<p>Tensor with minuends that will be subtracted by <code>input_b</code> tensor.</p>
</li>
<li>
<p>Must follow <a href="#gen-zten-reqs">general tensor requirements</a></p>
</li>
<li>
<p><code>zdnn_ztensor *input_b</code></p>
</li>
<li>
<p>Tensor with subtrahends to subtract from <code>input_a</code> tensor.</p>
</li>
<li>
<p>Must follow <a href="#gen-zten-reqs">general tensor requirements</a></p>
</li>
<li>
<p><code>zdnn_ztensor *output</code></p>
</li>
<li>Tensor to hold the result of the subtraction</li>
<li>Must follow <a href="#gen-zten-reqs">general tensor requirements</a></li>
</ul>
<h4 id="returns-see-zdnn-statuses-for-descriptions_1">Returns (see <a href="#common-statuses">zDNN Statuses</a> for descriptions)<a class="headerlink" href="#returns-see-zdnn-statuses-for-descriptions_1" title="Permanent link">&para;</a></h4>
<ul>
<li><code>ZDNN_OK</code></li>
<li><a href="#warning-statuses">warning statuses</a></li>
<li><code>ZDNN_INVALID_SHAPE</code></li>
<li><code>ZDNN_INVALID_TYPE</code></li>
<li><code>ZDNN_INVALID_FORMAT</code></li>
<li><a href="#hw-statuses">hardware statuses</a></li>
</ul>
<h4 id="framework-examples_1">Framework Examples<a class="headerlink" href="#framework-examples_1" title="Permanent link">&para;</a></h4>
<p><a href="https://www.tensorflow.org/api_docs/python/tf/math/subtract">TensorFlow Subtraction</a></p>
<p><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#sub">ONNX Subtraction</a></p>
<hr />
<h3 id="zdnn_mul">zdnn_mul<a class="headerlink" href="#zdnn_mul" title="Permanent link">&para;</a></h3>
<ul>
<li><a href="#TOC">Back to Table of Contents</a></li>
<li><a href="#elwise-ops">Back to Element-wise Operations</a></li>
</ul>
<h4 id="description_29">Description<a class="headerlink" href="#description_29" title="Permanent link">&para;</a></h4>
<p>Given two input tensors in zDNN transformed format, performs element-wise
multiplication and stores the result into the provided output zDNN tensor.</p>
<p><em>Note that for zDNN use, broadcasting of the input tensor(s) must be performed
by the caller. As such, the input tensors must be of the same shape.</em></p>
<h4 id="format_29">Format<a class="headerlink" href="#format_29" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code>zdnn_status zdnn_mul(const zdnn_ztensor *input_a, const zdnn_ztensor *input_b,
                     zdnn_ztensor *output);
</code></pre></div>
<h4 id="parameters_27">Parameters<a class="headerlink" href="#parameters_27" title="Permanent link">&para;</a></h4>
<ul>
<li>
<p><code>zdnn_ztensor *input_a</code></p>
</li>
<li>
<p>Tensor with multiplicands that will be multiplied by <code>input_b</code> tensor.</p>
</li>
<li>
<p>Must follow <a href="#gen-zten-reqs">general tensor requirements</a></p>
</li>
<li>
<p><code>zdnn_ztensor *input_b</code></p>
</li>
<li>
<p>Tensor with multipliers for <code>input_a</code> tensor.</p>
</li>
<li>
<p>Must follow <a href="#gen-zten-reqs">general tensor requirements</a></p>
</li>
<li>
<p><code>zdnn_ztensor *output</code></p>
</li>
<li>Tensor to hold the result of the multiplication.</li>
<li>Must follow <a href="#gen-zten-reqs">general tensor requirements</a></li>
</ul>
<h4 id="returns-see-zdnn-statuses-for-descriptions_2">Returns (see <a href="#common-statuses">zDNN Statuses</a> for descriptions)<a class="headerlink" href="#returns-see-zdnn-statuses-for-descriptions_2" title="Permanent link">&para;</a></h4>
<ul>
<li><code>ZDNN_OK</code></li>
<li><a href="#warning-statuses">warning statuses</a></li>
<li><code>ZDNN_INVALID_SHAPE</code></li>
<li><code>ZDNN_INVALID_TYPE</code></li>
<li><code>ZDNN_INVALID_FORMAT</code></li>
<li><a href="#hw-statuses">hardware statuses</a></li>
</ul>
<h4 id="framework-examples_2">Framework Examples<a class="headerlink" href="#framework-examples_2" title="Permanent link">&para;</a></h4>
<p><a href="https://www.tensorflow.org/api_docs/python/tf/math/multiply">TensorFlow Multiplication</a></p>
<p><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Mul">ONNX Multiplication</a></p>
<hr />
<h3 id="zdnn_div">zdnn_div<a class="headerlink" href="#zdnn_div" title="Permanent link">&para;</a></h3>
<ul>
<li><a href="#TOC">Back to Table of Contents</a></li>
<li><a href="#elwise-ops">Back to Element-wise Operations</a></li>
</ul>
<h4 id="description_30">Description<a class="headerlink" href="#description_30" title="Permanent link">&para;</a></h4>
<p>Given two input tensors in zDNN transformed format, performs element-wise
division and stores the result into the provided output zDNN tensor.</p>
<p><em>Note that for zDNN use, broadcasting of the input tensor(s) must be performed
by the caller. As such, the input tensors must be of the same shape.</em></p>
<h4 id="format_30">Format<a class="headerlink" href="#format_30" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code>zdnn_status zdnn_div(const zdnn_ztensor *input_a, const zdnn_ztensor *input_b,
                     zdnn_ztensor *output);
</code></pre></div>
<h4 id="parameters_28">Parameters<a class="headerlink" href="#parameters_28" title="Permanent link">&para;</a></h4>
<ul>
<li>
<p><code>zdnn_ztensor *input_a</code></p>
</li>
<li>
<p>Tensor with dividends that will be divided by <code>input_b</code> tensor.</p>
</li>
<li>
<p>Must follow <a href="#gen-zten-reqs">general tensor requirements</a></p>
</li>
<li>
<p><code>zdnn_ztensor *input_b</code></p>
</li>
<li>
<p>Tensor with divisors for <code>input_a</code> tensor.</p>
</li>
<li>
<p>Must follow <a href="#gen-zten-reqs">general tensor requirements</a></p>
</li>
<li>
<p><code>zdnn_ztensor *output</code></p>
</li>
<li>Tensor to hold the result of the division.</li>
<li>Must follow <a href="#gen-zten-reqs">general tensor requirements</a></li>
</ul>
<h4 id="returns-see-zdnn-statuses-for-descriptions_3">Returns (see <a href="#common-statuses">zDNN Statuses</a> for descriptions)<a class="headerlink" href="#returns-see-zdnn-statuses-for-descriptions_3" title="Permanent link">&para;</a></h4>
<ul>
<li><code>ZDNN_OK</code></li>
<li><a href="#warning-statuses">warning statuses</a></li>
<li><code>ZDNN_INVALID_SHAPE</code></li>
<li><code>ZDNN_INVALID_TYPE</code></li>
<li><code>ZDNN_INVALID_FORMAT</code></li>
<li><a href="#hw-statuses">hardware statuses</a></li>
</ul>
<h4 id="framework-examples_3">Framework Examples<a class="headerlink" href="#framework-examples_3" title="Permanent link">&para;</a></h4>
<p><a href="https://www.tensorflow.org/api_docs/python/tf/math/divide">TensorFlow Division</a></p>
<p><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Div">ONNX Division</a></p>
<hr />
<h3 id="zdnn_min">zdnn_min<a class="headerlink" href="#zdnn_min" title="Permanent link">&para;</a></h3>
<ul>
<li><a href="#TOC">Back to Table of Contents</a></li>
<li><a href="#elwise-ops">Back to Element-wise Operations</a></li>
</ul>
<h4 id="description_31">Description<a class="headerlink" href="#description_31" title="Permanent link">&para;</a></h4>
<p>Given two input tensors in zDNN transformed format, computes the element-wise
minimum and stores the result into the provided output zDNN tensor.</p>
<p><em>Note that for zDNN use, broadcasting of the input tensor(s) must be performed
by the caller. As such, the input tensors must be of the same shape.</em></p>
<h4 id="format_31">Format<a class="headerlink" href="#format_31" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code>zdnn_status zdnn_min(const zdnn_ztensor *input_a, const zdnn_ztensor *input_b,
                     zdnn_ztensor *output);
</code></pre></div>
<h4 id="parameters_29">Parameters<a class="headerlink" href="#parameters_29" title="Permanent link">&para;</a></h4>
<ul>
<li>
<p><code>zdnn_ztensor *input_a</code></p>
</li>
<li>
<p>Tensor with values that will be compared with <code>input_b</code> tensor.</p>
</li>
<li>
<p>Must follow <a href="#gen-zten-reqs">general tensor requirements</a></p>
</li>
<li>
<p><code>zdnn_ztensor *input_b</code></p>
</li>
<li>
<p>Tensor with values that will be compared with <code>input_a</code> tensor.</p>
</li>
<li>
<p>Must follow <a href="#gen-zten-reqs">general tensor requirements</a></p>
</li>
<li>
<p><code>zdnn_ztensor *output</code></p>
</li>
<li>Tensor that holds the smaller value from each comparison of the inputs.</li>
<li>Must follow <a href="#gen-zten-reqs">general tensor requirements</a></li>
</ul>
<h4 id="returns-see-zdnn-statuses-for-descriptions_4">Returns (see <a href="#common-statuses">zDNN Statuses</a> for descriptions)<a class="headerlink" href="#returns-see-zdnn-statuses-for-descriptions_4" title="Permanent link">&para;</a></h4>
<ul>
<li><code>ZDNN_OK</code></li>
<li><a href="#warning-statuses">warning statuses</a></li>
<li><code>ZDNN_INVALID_SHAPE</code></li>
<li><code>ZDNN_INVALID_TYPE</code></li>
<li><code>ZDNN_INVALID_FORMAT</code></li>
<li><a href="#hw-statuses">hardware statuses</a></li>
</ul>
<h4 id="framework-examples_4">Framework Examples<a class="headerlink" href="#framework-examples_4" title="Permanent link">&para;</a></h4>
<p><a href="https://www.tensorflow.org/api_docs/python/tf/math/minimum">TensorFlow Minimum</a></p>
<p><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#min">ONNX Minimum</a></p>
<hr />
<h3 id="zdnn_max">zdnn_max<a class="headerlink" href="#zdnn_max" title="Permanent link">&para;</a></h3>
<ul>
<li><a href="#TOC">Back to Table of Contents</a></li>
<li><a href="#elwise-ops">Back to Element-wise Operations</a></li>
</ul>
<h4 id="description_32">Description<a class="headerlink" href="#description_32" title="Permanent link">&para;</a></h4>
<p>Given two input tensors in zDNN transformed format, computes the element-wise
maximum and stores the result into the provided output zDNN tensor.</p>
<p><em>Note that for zDNN use, broadcasting of the input tensor(s) must be performed
by the caller. As such, the input tensors must be of the same shape.</em></p>
<h4 id="format_32">Format<a class="headerlink" href="#format_32" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code>zdnn_status zdnn_max(const zdnn_ztensor *input_a, const zdnn_ztensor *input_b,
                     zdnn_ztensor *output);
</code></pre></div>
<h4 id="parameters_30">Parameters<a class="headerlink" href="#parameters_30" title="Permanent link">&para;</a></h4>
<ul>
<li>
<p><code>zdnn_ztensor *input_a</code></p>
</li>
<li>
<p>Tensor with values that will be compared with <code>input_b</code> tensor.</p>
</li>
<li>
<p>Must follow <a href="#gen-zten-reqs">general tensor requirements</a></p>
</li>
<li>
<p><code>zdnn_ztensor *input_b</code></p>
</li>
<li>
<p>Tensor with values that will be compared with <code>input_a</code> tensor.</p>
</li>
<li>
<p>Must follow <a href="#gen-zten-reqs">general tensor requirements</a></p>
</li>
<li>
<p><code>zdnn_ztensor *output</code></p>
</li>
<li>Tensor that holds the larger value from each comparison of the inputs.</li>
<li>Must follow <a href="#gen-zten-reqs">general tensor requirements</a></li>
</ul>
<h4 id="returns-see-zdnn-statuses-for-descriptionss">Returns (see <a href="#common-statuses">zDNN Statuses</a> for descriptions)s<a class="headerlink" href="#returns-see-zdnn-statuses-for-descriptionss" title="Permanent link">&para;</a></h4>
<ul>
<li><code>ZDNN_OK</code></li>
<li><a href="#warning-statuses">warning statuses</a></li>
<li><code>ZDNN_INVALID_SHAPE</code></li>
<li><code>ZDNN_INVALID_TYPE</code></li>
<li><code>ZDNN_INVALID_FORMAT</code></li>
<li><a href="#hw-statuses">hardware statuses</a></li>
</ul>
<h4 id="framework-examples_5">Framework Examples<a class="headerlink" href="#framework-examples_5" title="Permanent link">&para;</a></h4>
<p><a href="https://www.tensorflow.org/api_docs/python/tf/math/maximum">TensorFlow Maximum</a></p>
<p><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#max">ONNX Maximum</a></p>
<hr />
<h3 id="zdnn_log">zdnn_log<a class="headerlink" href="#zdnn_log" title="Permanent link">&para;</a></h3>
<ul>
<li><a href="#TOC">Back to Table of Contents</a></li>
<li><a href="#elwise-ops">Back to Element-wise Operations</a></li>
</ul>
<h4 id="description_33">Description<a class="headerlink" href="#description_33" title="Permanent link">&para;</a></h4>
<p>Given an input tensor in zDNN transformed format, computes the natural logarithm
element-wise and stores the result into the provided output zDNN tensor.</p>
<h4 id="format_33">Format<a class="headerlink" href="#format_33" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code>zdnn_status zdnn_log(const zdnn_ztensor *input, zdnn_ztensor *output);
</code></pre></div>
<h4 id="parameters_31">Parameters<a class="headerlink" href="#parameters_31" title="Permanent link">&para;</a></h4>
<ul>
<li>
<p><code>zdnn_ztensor *input</code></p>
</li>
<li>
<p>Tensor with values to evaluate.</p>
</li>
<li>
<p>Must follow <a href="#gen-zten-reqs">general tensor requirements</a></p>
</li>
<li>
<p><code>zdnn_ztensor *output</code></p>
</li>
<li>Tensor that holds the calculated natural logarithm of each value from
    <code>input_a</code></li>
<li>Must follow <a href="#gen-zten-reqs">general tensor requirements</a></li>
</ul>
<h4 id="returns-see-zdnn-statuses-for-descriptions_5">Returns (see <a href="#common-statuses">zDNN Statuses</a> for descriptions)<a class="headerlink" href="#returns-see-zdnn-statuses-for-descriptions_5" title="Permanent link">&para;</a></h4>
<ul>
<li><code>ZDNN_OK</code></li>
<li><a href="#warning-statuses">warning statuses</a></li>
<li><code>ZDNN_INVALID_SHAPE</code></li>
<li><code>ZDNN_INVALID_TYPE</code></li>
<li><code>ZDNN_INVALID_FORMAT</code></li>
<li><a href="#hw-statuses">hardware statuses</a></li>
</ul>
<h4 id="framework-examples_6">Framework Examples<a class="headerlink" href="#framework-examples_6" title="Permanent link">&para;</a></h4>
<p><a href="https://www.tensorflow.org/api_docs/python/tf/math/log">TensorFlow Natural Logarithm</a></p>
<p><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Log">ONNX Natural Logarithm</a></p>
<hr />
<h3 id="zdnn_exp">zdnn_exp<a class="headerlink" href="#zdnn_exp" title="Permanent link">&para;</a></h3>
<ul>
<li><a href="#TOC">Back to Table of Contents</a></li>
<li><a href="#elwise-ops">Back to Element-wise Operations</a></li>
</ul>
<h4 id="description_34">Description<a class="headerlink" href="#description_34" title="Permanent link">&para;</a></h4>
<p>Given an input tensor in zDNN transformed format, computes the exponential
element-wise and stores the result into the provided output zDNN tensor.</p>
<h4 id="format_34">Format<a class="headerlink" href="#format_34" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code>zdnn_status zdnn_exp(const zdnn_ztensor *input, zdnn_ztensor *output);
</code></pre></div>
<h4 id="parameters_32">Parameters<a class="headerlink" href="#parameters_32" title="Permanent link">&para;</a></h4>
<ul>
<li>
<p><code>zdnn_ztensor *input</code></p>
</li>
<li>
<p>Tensor with values to evaluate.</p>
</li>
<li>
<p>Must follow <a href="#gen-zten-reqs">general tensor requirements</a></p>
</li>
<li>
<p><code>zdnn_ztensor *output</code></p>
</li>
<li>Tensor that holds the calculated exponential of each value from <code>input</code></li>
<li>Must follow <a href="#gen-zten-reqs">general tensor requirements</a></li>
</ul>
<h4 id="returns-see-zdnn-statuses-for-descriptions_6">Returns (see <a href="#common-statuses">zDNN Statuses</a> for descriptions)<a class="headerlink" href="#returns-see-zdnn-statuses-for-descriptions_6" title="Permanent link">&para;</a></h4>
<ul>
<li><code>ZDNN_OK</code></li>
<li><a href="#warning-statuses">warning statuses</a></li>
<li><code>ZDNN_INVALID_SHAPE</code></li>
<li><code>ZDNN_INVALID_TYPE</code></li>
<li><code>ZDNN_INVALID_FORMAT</code></li>
<li><a href="#hw-statuses">hardware statuses</a></li>
</ul>
<h4 id="framework-examples_7">Framework Examples<a class="headerlink" href="#framework-examples_7" title="Permanent link">&para;</a></h4>
<p><a href="https://www.tensorflow.org/api_docs/python/tf/math/exp">TensorFlow Exponential</a></p>
<p><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Exp">ONNX Exponential</a></p>
<hr />
<h2 id="activation-operations">Activation Operations <a id="act-ops"></a><a class="headerlink" href="#activation-operations" title="Permanent link">&para;</a></h2>
<p><a href="#TOC">Back to Table of Contents</a></p>
<ul>
<li><a href="#zdnn_relu">Rectified Linear</a></li>
<li><a href="#zdnn_tanh">Hyperbolic Tangent</a></li>
<li><a href="#zdnn_sigmoid">Sigmoid</a></li>
<li><a href="#zdnn_softmax">Softmax</a></li>
</ul>
<hr />
<h3 id="zdnn_relu">zdnn_relu<a class="headerlink" href="#zdnn_relu" title="Permanent link">&para;</a></h3>
<ul>
<li><a href="#TOC">Back to Table of Contents</a></li>
<li><a href="#act-ops">Back to Activation Operations</a></li>
</ul>
<h4 id="description_35">Description<a class="headerlink" href="#description_35" title="Permanent link">&para;</a></h4>
<p>Given an input tensor in zDNN transformed format produce an output tensor where
the rectified linear function, y = max(0, x) is applied to the input
element-wise. If an optional clipping_value is provided, clipping is performed
against the intermediate output where z = min(y, clipping_value).</p>
<h4 id="format_35">Format<a class="headerlink" href="#format_35" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code>zdnn_status zdnn_relu(const zdnn_ztensor *input, const void *clipping_value,
                      zdnn_ztensor *output);
</code></pre></div>
<h4 id="parameters_33">Parameters<a class="headerlink" href="#parameters_33" title="Permanent link">&para;</a></h4>
<ul>
<li>
<p><code>zdnn_ztensor *input</code></p>
</li>
<li>
<p>Tensor with values to evaluate.</p>
</li>
<li>
<p>Must follow <a href="#gen-zten-reqs">general tensor requirements</a></p>
</li>
<li>
<p><code>void *clipping_value</code></p>
</li>
<li>
<p>A pointer to an FP32 value, used to clip input tensor's elements.</p>
</li>
<li>If set to NULL or 0, no clipping will occur.</li>
<li>
<p>Must not be a negative value.</p>
</li>
<li>
<p><code>zdnn_ztensor *output</code></p>
</li>
<li>Tensor that holds the rectified linear function result of each value from
    <code>input</code></li>
<li>Must follow <a href="#gen-zten-reqs">general tensor requirements</a></li>
</ul>
<h4 id="returns-see-zdnn-statuses-for-descriptions_7">Returns (see <a href="#common-statuses">zDNN Statuses</a> for descriptions)<a class="headerlink" href="#returns-see-zdnn-statuses-for-descriptions_7" title="Permanent link">&para;</a></h4>
<ul>
<li><code>ZDNN_OK</code></li>
<li><a href="#warning-statuses">warning statuses</a></li>
<li><code>ZDNN_INVALID_SHAPE</code></li>
<li><code>ZDNN_INVALID_TYPE</code></li>
<li><code>ZDNN_INVALID_FORMAT</code></li>
<li><code>ZDNN_INVALID_CLIPPING_VALUE</code></li>
<li><a href="#hw-statuses">hardware statuses</a></li>
</ul>
<h4 id="framework-examples_8">Framework Examples<a class="headerlink" href="#framework-examples_8" title="Permanent link">&para;</a></h4>
<p><a href="https://www.tensorflow.org/api_docs/python/tf/nn/relu">TensorFlow Rectified Linear</a></p>
<p><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#relu">ONNX Rectified Linear</a></p>
<hr />
<h3 id="zdnn_tanh">zdnn_tanh<a class="headerlink" href="#zdnn_tanh" title="Permanent link">&para;</a></h3>
<ul>
<li><a href="#TOC">Back to Table of Contents</a></li>
<li><a href="#act-ops">Back to Activation Operations</a></li>
</ul>
<h4 id="description_36">Description<a class="headerlink" href="#description_36" title="Permanent link">&para;</a></h4>
<p>Given an input tensor in zDNN transformed format, produces an output tensor
where the hyperbolic tangent is applied to the input element-wise.</p>
<h4 id="format_36">Format<a class="headerlink" href="#format_36" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code>zdnn_status zdnn_tanh(const zdnn_ztensor *input, zdnn_ztensor *output);
</code></pre></div>
<h4 id="parameters_34">Parameters<a class="headerlink" href="#parameters_34" title="Permanent link">&para;</a></h4>
<ul>
<li>
<p><code>zdnn_ztensor *input</code></p>
</li>
<li>
<p>Tensor with values to evaluate.</p>
</li>
<li>
<p>Must follow <a href="#gen-zten-reqs">general tensor requirements</a></p>
</li>
<li>
<p><code>zdnn_ztensor *output</code></p>
</li>
<li>Tensor that holds the hyperbolic tangent result of each value from <code>input</code></li>
<li>Must follow <a href="#gen-zten-reqs">general tensor requirements</a></li>
</ul>
<h4 id="returns-see-zdnn-statuses-for-descriptions_8">Returns (see <a href="#common-statuses">zDNN Statuses</a> for descriptions)<a class="headerlink" href="#returns-see-zdnn-statuses-for-descriptions_8" title="Permanent link">&para;</a></h4>
<ul>
<li><code>ZDNN_OK</code></li>
<li><a href="#warning-statuses">warning statuses</a></li>
<li><code>ZDNN_INVALID_SHAPE</code></li>
<li><code>ZDNN_INVALID_TYPE</code></li>
<li><code>ZDNN_INVALID_FORMAT</code></li>
<li><a href="#hw-statuses">hardware statuses</a></li>
</ul>
<h4 id="framework-examples_9">Framework Examples<a class="headerlink" href="#framework-examples_9" title="Permanent link">&para;</a></h4>
<p><a href="https://www.tensorflow.org/api_docs/python/tf/math/tanh">TensorFlow Hyperbolic Tangent</a></p>
<p><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Tanh">ONNX Hyperbolic Tangent</a></p>
<hr />
<h3 id="zdnn_sigmoid">zdnn_sigmoid<a class="headerlink" href="#zdnn_sigmoid" title="Permanent link">&para;</a></h3>
<ul>
<li><a href="#TOC">Back to Table of Contents</a></li>
<li><a href="#act-ops">Back to Activation Operations</a></li>
</ul>
<h4 id="description_37">Description<a class="headerlink" href="#description_37" title="Permanent link">&para;</a></h4>
<p>Given an input tensor in zDNN transformed format, produces an output tensor
where the sigmoid function is applied to the input element-wise.</p>
<h4 id="format_37">Format<a class="headerlink" href="#format_37" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code>zdnn_status zdnn_sigmoid(const zdnn_ztensor *input, zdnn_ztensor *output);
</code></pre></div>
<h4 id="parameters_35">Parameters<a class="headerlink" href="#parameters_35" title="Permanent link">&para;</a></h4>
<ul>
<li>
<p><code>zdnn_ztensor *input</code></p>
</li>
<li>
<p>Tensor with values to evaluate.</p>
</li>
<li>
<p>Must follow <a href="#gen-zten-reqs">general tensor requirements</a></p>
</li>
<li>
<p><code>zdnn_ztensor *output</code></p>
</li>
<li>Tensor that holds the sigmoid result of each value from <code>input</code></li>
<li>Must follow <a href="#gen-zten-reqs">general tensor requirements</a></li>
</ul>
<h4 id="returns-see-zdnn-statuses-for-descriptions_9">Returns (see <a href="#common-statuses">zDNN Statuses</a> for descriptions)<a class="headerlink" href="#returns-see-zdnn-statuses-for-descriptions_9" title="Permanent link">&para;</a></h4>
<ul>
<li><code>ZDNN_OK</code></li>
<li><a href="#warning-statuses">warning statuses</a></li>
<li><code>ZDNN_INVALID_SHAPE</code></li>
<li><code>ZDNN_INVALID_TYPE</code></li>
<li><code>ZDNN_INVALID_FORMAT</code></li>
<li><a href="#hw-statuses">hardware statuses</a></li>
</ul>
<h4 id="framework-examples_10">Framework Examples<a class="headerlink" href="#framework-examples_10" title="Permanent link">&para;</a></h4>
<p><a href="https://www.tensorflow.org/api_docs/python/tf/math/sigmoid">TensorFlow Sigmoid</a></p>
<p><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Sigmoid">ONNX Sigmoid</a></p>
<hr />
<h3 id="zdnn_softmax">zdnn_softmax<a class="headerlink" href="#zdnn_softmax" title="Permanent link">&para;</a></h3>
<ul>
<li><a href="#TOC">Back to Table of Contents</a></li>
<li><a href="#act-ops">Back to Activation Operations</a></li>
</ul>
<h4 id="description_38">Description<a class="headerlink" href="#description_38" title="Permanent link">&para;</a></h4>
<p>Given an input tensor in zDNN transformed format, computes the softmax
(normalized exponential) for each vector formed in dimension-1, then if
<code>act_func</code> is not <code>SOFTMAX_ACT_NONE</code>, the activation function is applied to the
results. Finally stores the results into the provided output zDNN tensor.</p>
<p><em>Note: Other parameters, such as axis, are not supported.</em></p>
<h4 id="format_38">Format<a class="headerlink" href="#format_38" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code>zdnn_status zdnn_softmax(const zdnn_ztensor *input, void *save_area,
                         zdnn_softmax_act act_func, zdnn_ztensor *output);
</code></pre></div>
<h4 id="parameters_36">Parameters<a class="headerlink" href="#parameters_36" title="Permanent link">&para;</a></h4>
<ul>
<li>
<p><code>zdnn_ztensor *input</code></p>
</li>
<li>
<p><a href="#common-layouts">ZDNN_3DS</a> tensor with pre-transformed shape [batch size,
    batch size, vector dimension size] or output from another operation that is
    of the correct shape.</p>
</li>
<li>
<p>Must follow <a href="#gen-zten-reqs">general tensor requirements</a></p>
</li>
<li>
<p><code>void *save_area</code></p>
</li>
<li>
<p>A preallocated memory address to use for temporary storage during internal
    operation processing.</p>
</li>
<li>The preallocate memory must be at least 8K bytes in size, aligned on a 4k
    boundary.</li>
<li>
<p>If set to NULL, the operation will determine, allocate and free storage
    automatically.</p>
</li>
<li>
<p><code>zdnn_softmax_act act_func</code></p>
</li>
<li>
<p>Activation function to apply to the results.</p>
</li>
<li>
<p><code>SOFTMAX_ACT_NONE</code> or <code>SOFTMAX_ACT_LOG</code></p>
</li>
<li>
<p><code>zdnn_ztensor *output</code></p>
</li>
<li><a href="#common-layouts">ZDNN_3DS</a> tensor with the same shape as <code>input_a</code> that
    holds the softmax result of each value from <code>input_a</code>.</li>
<li>Must follow <a href="#gen-zten-reqs">general tensor requirements</a></li>
</ul>
<h4 id="programming-notes_6">Programming Notes<a class="headerlink" href="#programming-notes_6" title="Permanent link">&para;</a></h4>
<ul>
<li>
<p>If all elements of a dimension 1 vector are the largest magnitude negative
  number possible for the transformed data type, accuracy may be reduced.</p>
</li>
<li>
<p>A <code>ZDNN_3DS</code> tensor is expected, where the <code>transformed_desc</code> dim1 describes
  the vector, and dim2 and dim4 are used to batch multiple vector requests
  together. Dim3 must always be 1. The <code>zdnn_softmax</code> operation is performed
  against the vector in dim1 repeating for each dim1 vector in the dim4 and dim2
  dimensions.</p>
</li>
<li>
<p>Tensors that cannot be processed as vectors in dim1 or as batches of dim1
  vectors must be coerced or reshaped by the caller.</p>
</li>
<li>When the entire tensor is to be processed by softmax, it can be coerced by
    simply creating an alternate descriptor prior to zDNN transformation. For
    example:<ul>
<li>A 4D tensor with <code>pre_transformed_desc</code> dimensions 2x2x2x2 and a data
  array of 16 FP32 entries could have an alternate <code>ZDNN_3DS</code> layout
  <code>pre_transformed_desc</code> using dimensions 1x1x16 and use the same original
  data array prior to <code>zdnn_transform_ztensor</code>. After transformation, such a
  tensor would be valid for <code>zdnn_softmax</code>.</li>
<li>In another example, the 4D 2x2x2x2 tensor could be processed as 2 batches
  of 8 vectors using a <code>ZDNN_3DS</code> layout <code>pre_transformed_desc</code> with
  dimensions 1x2x8.</li>
</ul>
</li>
</ul>
<h4 id="returns-see-zdnn-statuses-for-descriptions_10">Returns (see <a href="#common-statuses">zDNN Statuses</a> for descriptions)<a class="headerlink" href="#returns-see-zdnn-statuses-for-descriptions_10" title="Permanent link">&para;</a></h4>
<ul>
<li><code>ZDNN_OK</code></li>
<li><a href="#warning-statuses">warning statuses</a></li>
<li><code>ZDNN_INVALID_SHAPE</code></li>
<li><code>ZDNN_INVALID_TYPE</code></li>
<li><code>ZDNN_INVALID_FORMAT</code></li>
<li><code>ZDNN_ALLOCATION_FAILURE</code> - A preallocated <code>save_area</code> was not specified and
  internal allocation for the required memory failed.</li>
<li><a href="#hw-statuses">hardware statuses</a></li>
<li><code>ZDNN_FUNC_RC_F000</code> - input tensor <code>input-&gt;transformed_desc-&gt;dim3</code> was
    not 1.</li>
<li><code>ZDNN_FUNC_RC_F001</code> - Invalid <code>act_func</code></li>
</ul>
<h4 id="framework-examples_11">Framework Examples<a class="headerlink" href="#framework-examples_11" title="Permanent link">&para;</a></h4>
<p><a href="https://www.tensorflow.org/api_docs/python/tf/nn/softmax">TensorFlow Softmax</a></p>
<p><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Softmax">ONNX Softmax</a></p>
<hr />
<h2 id="normalization-operations">Normalization Operations <a id="norm-ops"></a><a class="headerlink" href="#normalization-operations" title="Permanent link">&para;</a></h2>
<p><a href="#TOC">Back to Table of Contents</a></p>
<ul>
<li><a href="#zdnn_meanreduce2d">Mean Reduce</a></li>
<li><a href="#zdnn_batchnorm">Batch Norm</a></li>
</ul>
<hr />
<h3 id="zdnn_meanreduce2d">zdnn_meanreduce2d<a class="headerlink" href="#zdnn_meanreduce2d" title="Permanent link">&para;</a></h3>
<ul>
<li><a href="#TOC">Back to Table of Contents</a></li>
<li><a href="#norm-ops">Back to Normalization Operations</a></li>
</ul>
<h4 id="description_39">Description<a class="headerlink" href="#description_39" title="Permanent link">&para;</a></h4>
<p>Given an input tensor in zDNN transformed format, produces a downsampled tensor
reducing the middle dimensions to a size of 1 based on the mean of the original
values and stores the result to the provided output zDNN tensor.</p>
<h4 id="format_39">Format<a class="headerlink" href="#format_39" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code>zdnn_status zdnn_meanreduce2d(const zdnn_ztensor *input, zdnn_ztensor *output);
</code></pre></div>
<h4 id="parameters_37">Parameters<a class="headerlink" href="#parameters_37" title="Permanent link">&para;</a></h4>
<ul>
<li>
<p><code>zdnn_ztensor *input</code></p>
</li>
<li>
<p>Must be a <a href="#common-layouts">ZDNN_NHWC</a> tensor with pre_transformed shape
    [batch_Num, Height, Width, Channel].</p>
</li>
<li>Height and Width dimension must be less than or equal to 1024.</li>
<li>
<p>Must follow <a href="#gen-zten-reqs">general tensor requirements</a></p>
</li>
<li>
<p><code>zdnn_ztensor *output</code></p>
</li>
<li>The result tensor which will hold the result of the pooling operation in its
    buffer.</li>
<li>Shape:<ul>
<li><code>output</code> dimensions batch_Num and Channel must be the same as the
  respective input dimensions.</li>
<li><code>output</code> dimensions Height and Width must be 1.</li>
</ul>
</li>
<li>Must follow <a href="#gen-zten-reqs">general tensor requirements</a></li>
</ul>
<h4 id="returns-see-zdnn-statuses-for-descriptions_11">Returns (see <a href="#common-statuses">zDNN Statuses</a> for descriptions)<a class="headerlink" href="#returns-see-zdnn-statuses-for-descriptions_11" title="Permanent link">&para;</a></h4>
<ul>
<li><code>ZDNN_OK</code></li>
<li><code>ZDNN_INVALID_SHAPE</code> - Shape of input or output tensor is invalid based on
  given kernel and stride parameters</li>
<li><code>ZDNN_INVALID_TYPE</code></li>
<li><code>ZDNN_INVALID_FORMAT</code></li>
<li><a href="#hw-statuses">hardware statuses</a></li>
<li><code>ZDNN_FUNC_RC_F001</code> - <code>input</code> tensor has a Height or Width dimension greater
    than allowed for <code>zdnn_meanreduce2d</code>.</li>
</ul>
<h4 id="framework-examples_12">Framework Examples<a class="headerlink" href="#framework-examples_12" title="Permanent link">&para;</a></h4>
<p><a href="https://www.tensorflow.org/api_docs/python/tf/math/reduce_mean">TensorFlow Reduce Mean</a> with <code>axis</code> set for the Height and Width axes and
<code>keepdims</code> set to True.</p>
<p><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#ReduceMean">ONNX Reduce Mean</a></p>
<hr />
<h3 id="zdnn_batchnorm">zdnn_batchnorm<a class="headerlink" href="#zdnn_batchnorm" title="Permanent link">&para;</a></h3>
<ul>
<li><a href="#TOC">Back to Table of Contents</a></li>
<li><a href="#norm-ops">Back to Normalization Operations</a></li>
</ul>
<h4 id="description_40">Description<a class="headerlink" href="#description_40" title="Permanent link">&para;</a></h4>
<p>Given three input zDNN tensors <code>input_a</code>, <code>input_b</code>, and <code>input_c</code>, computes the
batch-normalized result for each vector formed in dimension-1 as follows:</p>
<p>output = input_b * input_a + input_c</p>
<p>where <code>input_b</code> is a precomputed elementwise divide of scale and variance
tensors, and <code>input_c</code> is a precomputed elementwise multiply of (-1) * mean and
'input_b' + input bias tensors.</p>
<h4 id="format_40">Format<a class="headerlink" href="#format_40" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code>zdnn_status zdnn_batchnorm(const zdnn_ztensor *input_a,
                           const zdnn_ztensor *input_b,
                           const zdnn_ztensor *input_c, zdnn_ztensor *output);
</code></pre></div>
<h4 id="parameters_38">Parameters<a class="headerlink" href="#parameters_38" title="Permanent link">&para;</a></h4>
<ul>
<li>
<p><code>zdnn_ztensor *input_a</code></p>
</li>
<li>
<p>Must be a 4D <a href="#common-layouts">ZDNN_NHWC</a> tensor</p>
</li>
<li>
<p>Must follow <a href="#gen-zten-reqs">general tensor requirements</a></p>
</li>
<li>
<p><code>zdnn_ztensor *input_b</code></p>
</li>
<li>
<p>Must be a 1D <a href="#common-layouts">ZDNN_1D</a> tensor</p>
</li>
<li>
<p>Must follow <a href="#gen-zten-reqs">general tensor requirements</a></p>
</li>
<li>
<p><code>zdnn_ztensor *input_c</code></p>
</li>
<li>
<p>Must be a 1D <a href="#common-layouts">ZDNN_1D</a> tensor</p>
</li>
<li>
<p>Must follow <a href="#gen-zten-reqs">general tensor requirements</a></p>
</li>
<li>
<p><code>zdnn_ztensor *output</code></p>
</li>
<li>A zdnn_ztensor of the same size as <code>input_a</code> representing the computed value
    of the above formula</li>
<li>Must follow <a href="#gen-zten-reqs">general tensor requirements</a></li>
</ul>
<h4 id="returns-see-zdnn-statuses-for-descriptions_12">Returns (see <a href="#common-statuses">zDNN Statuses</a> for descriptions)<a class="headerlink" href="#returns-see-zdnn-statuses-for-descriptions_12" title="Permanent link">&para;</a></h4>
<ul>
<li><code>ZDNN_OK</code></li>
<li><a href="#warning-statuses">warning statuses</a></li>
<li><code>ZDNN_INVALID_SHAPE</code></li>
<li><code>ZDNN_INVALID_TYPE</code></li>
<li><code>ZDNN_INVALID_FORMAT</code></li>
<li><a href="#hw-statuses">hardware statuses</a></li>
</ul>
<h4 id="framework-examples_13">Framework Examples<a class="headerlink" href="#framework-examples_13" title="Permanent link">&para;</a></h4>
<p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/BatchNormalization">TensorFlow Batchnorm</a></p>
<p><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#BatchNormalization">ONNX Batchnorm</a></p>
<hr />
<h3 id="zdnn_matmul_op">zdnn_matmul_op<a class="headerlink" href="#zdnn_matmul_op" title="Permanent link">&para;</a></h3>
<p><a href="#TOC">Back to Table of Contents</a></p>
<h4 id="description_41">Description<a class="headerlink" href="#description_41" title="Permanent link">&para;</a></h4>
<p>Given three input zDNN tensors <code>input_a</code>, <code>input_b</code>, and <code>input_c</code>, determine
the matrix multiplication of <code>input_a</code> * <code>input_b</code> then perform one of the
following operations, using <code>input_c</code> against the dot product, storing the
result into the specified <code>output</code> zDNN tensor:</p>
<ul>
<li>Addition</li>
<li>Compare - If dot product is greater than element.</li>
<li>Compare - If dot product is greater or equal to element.</li>
<li>Compare - If dot product is equal to element.</li>
<li>Compare - If dot product is not equal to element.</li>
<li>Compare - If dot product is less than or equal to element.</li>
<li>Compare - If dot product is less than element.</li>
</ul>
<p>For an operation type of addition, <code>input_c</code> is added to the intermediate dot
product. For operation types of comparison, the intermediate dot product is
compared to <code>input_c</code> and if the comparison is true, the result is set to a
value of 1; otherwise it is set to a value of 0.</p>
<p>The outermost dimension can optionally indicate that the inputs are stacks of
matrices. The results for each matrix stack is independent of other stacks but
all stacks are calculated in a single call.</p>
<h4 id="format_41">Format<a class="headerlink" href="#format_41" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code>zdnn_status zdnn_matmul_op(const zdnn_ztensor *input_a,
                           const zdnn_ztensor *input_b,
                           const zdnn_ztensor *input_c,
                           zdnn_matmul_ops op_type, zdnn_ztensor *output);
</code></pre></div>
<h4 id="input-output-matmul-tensor-requirements">Input / Output matmul tensor requirements <a id="matmul-io-table"></a><a class="headerlink" href="#input-output-matmul-tensor-requirements" title="Permanent link">&para;</a></h4>
<ul>
<li>See table in this section for <code>pre_transformed_desc</code> and shape requirements
  for each tensor.</li>
<li>All tensors must either be stacked or unstacked.</li>
<li>Must follow <a href="#gen-zten-reqs">general tensor requirements</a></li>
</ul>
<table>
<thead>
<tr>
<th>type</th>
<th>input_a</th>
<th>input_b</th>
<th>input_c</th>
<th>result</th>
</tr>
</thead>
<tbody>
<tr>
<td>unstacked</td>
<td><code>ZDNN_2D</code> (m, n)</td>
<td><code>ZDNN_2D</code> (n, p)</td>
<td><code>ZDNN_1D</code> (p)</td>
<td><code>ZDNN_2D</code> (m, p)</td>
</tr>
<tr>
<td>stacked</td>
<td><code>ZDNN_3DS</code> (s, m, n)</td>
<td><code>ZDNN_3DS</code> (s, n, p)</td>
<td><code>ZDNN_2DS</code> (s, p)</td>
<td><code>ZDNN_3DS</code> (s, m, p)</td>
</tr>
</tbody>
</table>
<h4 id="parameters_39">Parameters<a class="headerlink" href="#parameters_39" title="Permanent link">&para;</a></h4>
<ul>
<li>
<p><code>zdnn_ztensor *input_a</code></p>
</li>
<li>
<p>Input tensor with the first matrix for multiplication</p>
</li>
<li>
<p>pre_transformed shape and layout must match
    <a href="#matmul-io-table">matmul tensor requirements</a></p>
</li>
<li>
<p><code>zdnn_ztensor *input_b</code></p>
</li>
<li>
<p>Input tensor with the second matrix for multiplication</p>
</li>
<li>
<p>pre_transformed shape and layout must match
    <a href="#matmul-io-table">matmul tensor requirements</a></p>
</li>
<li>
<p><code>zdnn_ztensor *input_c</code></p>
</li>
<li>
<p>Input tensor that will have the requested operation performed against the
    intermediate dot product of <code>input_a</code> and <code>input_b</code>.</p>
</li>
<li>
<p>pre_transformed shape and layout must match
    <a href="#matmul-io-table">matmul tensor requirements</a></p>
</li>
<li>
<p><code>zdnn_matmul_ops op_type</code></p>
</li>
<li>
<p>Operation to perform on dot product.</p>
<ul>
<li><code>MATMUL_OP_ADDITION</code></li>
<li><code>MATMUL_OP_GREATER</code></li>
<li><code>MATMUL_OP_GREATER_EQUAL</code></li>
<li><code>MATMUL_OP_EQUAL</code></li>
<li><code>MATMUL_OP_NOT_EQUAL</code></li>
<li><code>MATMUL_OP_LESSER_EQUAL</code></li>
<li><code>MATMUL_OP_LESSER</code></li>
</ul>
</li>
<li>
<p><code>zdnn_ztensor *output</code></p>
</li>
<li>The output tensor which will hold the result of the operation in its buffer.</li>
<li>pre_transformed shape and layout must match
    <a href="#matmul-io-table">matmul tensor requirements</a></li>
</ul>
<h4 id="programming-notes_7">Programming Notes<a class="headerlink" href="#programming-notes_7" title="Permanent link">&para;</a></h4>
<ul>
<li>Care must be exercised when comparing values for equality or inequality since
  the order of operations and rounding may produce, what appear to be, slightly
  different values when they are essentially the same value.</li>
</ul>
<h4 id="returns-see-zdnn-statuses-for-descriptions_13">Returns (see <a href="#common-statuses">zDNN Statuses</a> for descriptions)<a class="headerlink" href="#returns-see-zdnn-statuses-for-descriptions_13" title="Permanent link">&para;</a></h4>
<ul>
<li><code>ZDNN_OK</code></li>
<li><code>ZDNN_INVALID_SHAPE</code></li>
<li><code>ZDNN_INVALID_TYPE</code></li>
<li><code>ZDNN_INVALID_FORMAT</code></li>
<li><a href="#hw-statuses">hardware statuses</a></li>
<li><code>ZDNN_FUNC_RC_F000</code> - Invalid <code>op_type</code>.</li>
</ul>
<h4 id="framework-examples_14">Framework Examples<a class="headerlink" href="#framework-examples_14" title="Permanent link">&para;</a></h4>
<p><a href="https://www.tensorflow.org/api_docs/cc/class/tensorflow/ops/mat-mul">TensorFlow MatMul</a></p>
<p><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#MatMul">ONNX MatMul</a></p>
<hr />
<h3 id="zdnn_matmul_bcast_op">zdnn_matmul_bcast_op<a class="headerlink" href="#zdnn_matmul_bcast_op" title="Permanent link">&para;</a></h3>
<p><a href="#TOC">Back to Table of Contents</a></p>
<h4 id="description_42">Description<a class="headerlink" href="#description_42" title="Permanent link">&para;</a></h4>
<p>Given three input zDNN tensors <code>input_a</code>, <code>input_b</code>, and <code>input_c</code>, determine
the matrix multiplication of <code>input_a</code> * <code>input_b</code>, then perform one of the
following operations, using <code>input_c</code> against the dot product, storing the
result into the specified <code>output</code> zDNN tensor:</p>
<ul>
<li>Addition</li>
</ul>
<p>The outermost dimension for <code>input_a</code> can optionally indicate that the input is
a stack of matrices. Each stack of <code>input_a</code> is then multiplied by the same
<code>input_b</code> matrix and <code>input_c</code> which are broadcast over each stack of <code>input_a</code>.
Results for each stack are returned in the corresponding stack index of
<code>output</code>.</p>
<h4 id="format_42">Format<a class="headerlink" href="#format_42" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code>zdnn_status zdnn_matmul_bcast_op(const zdnn_ztensor *input_a,
                                 const zdnn_ztensor *input_b,
                                 const zdnn_ztensor *input_c,
                                 zdnn_matmul_bcast_ops op_type, zdnn_ztensor *output);
</code></pre></div>
<h4 id="input-output-matmul-broadcast-tensor-requirements">Input / Output matmul broadcast tensor requirements <a id="matmul-bcast-io-table"></a><a class="headerlink" href="#input-output-matmul-broadcast-tensor-requirements" title="Permanent link">&para;</a></h4>
<ul>
<li>See table in this section for <code>pre_transformed_desc</code> and shape requirements
  for each tensor.</li>
<li>Must follow <a href="#gen-zten-reqs">general tensor requirements</a></li>
</ul>
<table>
<thead>
<tr>
<th>input_a</th>
<th>input_b</th>
<th>input_c</th>
<th>result</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>ZDNN_3DS</code> (s, m, n)</td>
<td><code>ZDNN_2D</code> (n, p)</td>
<td><code>ZDNN_1D</code> (p)</td>
<td><code>ZDNN_3DS</code> (s, m, p)</td>
</tr>
</tbody>
</table>
<h4 id="parameters_40">Parameters<a class="headerlink" href="#parameters_40" title="Permanent link">&para;</a></h4>
<ul>
<li>
<p><code>zdnn_ztensor *input_a</code></p>
</li>
<li>
<p>Input tensor with the first matrix for multiplication.</p>
</li>
<li>
<p>pre_transformed shape and layout must match
    <a href="#matmul-bcast-io-table">matmul broadcast tensor requirements</a></p>
</li>
<li>
<p><code>zdnn_ztensor *input_b</code></p>
</li>
<li>
<p>Input tensor with the second matrix for multiplication.</p>
</li>
<li>The same single <code>input_b</code> matrix is broadcast and used as the multiplier for
    each stack dimension of <code>input_a</code></li>
<li>
<p>pre_transformed shape and layout must match
    <a href="#matmul-bcast-io-table">matmul broadcast tensor requirements</a></p>
</li>
<li>
<p><code>zdnn_ztensor *input_c</code></p>
</li>
<li>
<p>Input tensor that will have the requested operation performed against the
    intermediate dot product for each "m" dimension in <code>output</code>.</p>
</li>
<li>
<p>pre_transformed shape and layout must match
    <a href="#matmul-bcast-io-table">matmul broadcast tensor requirements</a></p>
</li>
<li>
<p><code>zdnn_matmul_bcast_ops op_type</code></p>
</li>
<li>
<p>Operation to perform on dot product.</p>
<ul>
<li><code>MATMUL_BCAST_OP_ADDITION</code></li>
</ul>
</li>
<li>
<p><code>zdnn_ztensor *output</code></p>
</li>
<li>The output tensor which will hold the result of the operation in its buffer.</li>
<li>pre_transformed shape and layout must match
    <a href="#matmul-bcast-io-table">matmul broadcast tensor requirements</a></li>
</ul>
<h4 id="programming-notes_8">Programming Notes<a class="headerlink" href="#programming-notes_8" title="Permanent link">&para;</a></h4>
<ul>
<li><code>zdnn_matmul_bcast_ops</code> only supports <code>MATMUL_BCAST_OP_ADDITION</code> op_type, any
  other op_types will be ignored and may not operate compatibly in the future.</li>
</ul>
<h4 id="returns-see-zdnn-statuses-for-descriptions_14">Returns (see <a href="#common-statuses">zDNN Statuses</a> for descriptions)<a class="headerlink" href="#returns-see-zdnn-statuses-for-descriptions_14" title="Permanent link">&para;</a></h4>
<ul>
<li><code>ZDNN_OK</code></li>
<li><code>ZDNN_INVALID_SHAPE</code></li>
<li><code>ZDNN_INVALID_TYPE</code></li>
<li><code>ZDNN_INVALID_FORMAT</code></li>
<li><a href="#hw-statuses">hardware statuses</a></li>
</ul>
<h4 id="framework-examples_15">Framework Examples<a class="headerlink" href="#framework-examples_15" title="Permanent link">&para;</a></h4>
<p><a href="https://www.tensorflow.org/api_docs/cc/class/tensorflow/ops/mat-mul">TensorFlow MatMul</a></p>
<p><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#MatMul">ONNX MatMul</a></p>
<hr />
<h3 id="zdnn_lstm">zdnn_lstm<a class="headerlink" href="#zdnn_lstm" title="Permanent link">&para;</a></h3>
<p><a href="#TOC">Back to Table of Contents</a></p>
<h4 id="description_43">Description<a class="headerlink" href="#description_43" title="Permanent link">&para;</a></h4>
<p>Implements Long-Short Term Memory layer (LSTM - Hochreiter 1997).</p>
<p>The following formula is computed for the input tensor input(t) for all time
steps:</p>
<p>(Default: f=Sigmoid, g=Tanh, h=Tanh):</p>
<div class="highlight"><pre><span></span><code>- it = f(Xt*(Wi^T) + Ht-1*(Ri^T) + Wbi + Rbi)

- ft = f(Xt*(Wf^T) + Ht-1*(Rf^T) + Wbf + Rbf)

- ct = g(Xt*(Wc^T) + Ht-1*(Rc^T) + Wbc + Rbc)

- Ct = ft (.) Ct-1 + it (.) ct

- ot = f(Xt*(Wo^T) + Ht-1*(Ro^T) + Wbo + Rbo)

- Ht = ot (.) h(Ct)
</code></pre></div>
<h4 id="format_43">Format<a class="headerlink" href="#format_43" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code>zdnn_status zdnn_lstm(const zdnn_ztensor *input, const zdnn_ztensor *h0,
                      const zdnn_ztensor *c0, const zdnn_ztensor *weights,
                      const zdnn_ztensor *biases,
                      const zdnn_ztensor *hidden_weights,
                      const zdnn_ztensor *hidden_biases,
                      lstm_gru_direction direction, void *work_area,
                      zdnn_ztensor *hn_output, zdnn_ztensor *cf_output);
</code></pre></div>
<p>Also see an <a href="#example-of-an-application-calling-the-zdnn_lstm-api">example</a> in
the usage example section.</p>
<h4 id="lstm-input-output-requirements">LSTM Input / Output requirements<a class="headerlink" href="#lstm-input-output-requirements" title="Permanent link">&para;</a></h4>
<ul>
<li><code>num_hidden</code> dimensions: <a id="lstm-hid_sz"></a></li>
<li>Any num_hidden dimension must be less than or equal to 8192 elements.</li>
</ul>
<h4 id="parameters_41">Parameters<a class="headerlink" href="#parameters_41" title="Permanent link">&para;</a></h4>
<ul>
<li>
<p><code>zdnn_ztensor *input</code></p>
</li>
<li>
<p>Input must be a tensor with the shape (num_timesteps, num_batches,
    num_features) prior to transformation with the <code>zdnn_transform_ztensor</code> API.</p>
</li>
<li>Expects <code>pre_transformed_desc-&gt;layout</code> to be <code>ZDNN_3DS</code>.</li>
<li>
<p>Must follow <a href="#gen-zten-reqs">general tensor requirements</a></p>
</li>
<li>
<p><code>zdnn_ztensor *h0</code></p>
</li>
<li>
<p>Tensor containing the initial hidden state with shape (num_dirs,
    num_batches, num_hidden) prior to transformation with the
    <code>zdnn_transform_ztensor</code> API.</p>
</li>
<li>Expects <code>pre_transformed_desc-&gt;layout</code> to be <code>ZDNN_3DS</code>.</li>
<li>Must follow <a href="#gen-zten-reqs">general tensor requirements</a></li>
<li>
<p>Must follow <a href="#lstm-hid_sz">num_hidden requirements</a></p>
</li>
<li>
<p><code>zdnn_ztensor *c0</code></p>
</li>
<li>
<p>Tensor containing the initial cell state with shape (num_dirs, num_batches,
    num_hidden) prior to transformation with the <code>zdnn_transform_ztensor</code> API.</p>
</li>
<li>Expects <code>pre_transformed_desc-&gt;layout</code> to be <code>ZDNN_3DS</code>.</li>
<li>Must follow <a href="#gen-zten-reqs">general tensor requirements</a></li>
<li>
<p>Must follow <a href="#lstm-hid_sz">num_hidden requirements</a></p>
</li>
<li>
<p><code>zdnn_ztensor *weights</code></p>
</li>
<li>
<p>Tensor containing the concatenated input connection weights in Forget,
    Input, Cell, Output (FICO) order.</p>
</li>
<li>Prior to transformation, each gate needs to be transposed to shape
    (num_dirs, num_features, num_hidden) by the caller.</li>
<li>Expects <code>pre_transformed_desc-&gt;layout</code> to be <code>ZDNN_3DS</code>.</li>
<li>Expects <code>zdnn_concat_info</code> having the following flags turned on:<ul>
<li><code>RNN_TYPE_LSTM</code></li>
<li><code>USAGE_WEIGHTS</code></li>
<li>Appropriate <code>PREV_LAYER</code> flag:</li>
<li><code>PREV_LAYER_NONE</code> if <code>input</code> tensor is not from a previous RNN layer</li>
<li><code>PREV_LAYER_UNI</code> if <code>input</code> tensor is uni-directional output from a
    previous RNN layer</li>
<li><code>PREV_LAYER_BIDIR</code> if <code>input</code> tensor is bi-directional output from a
    previous RNN layer</li>
</ul>
</li>
<li>Must follow <a href="#concat-zten-reqs">concatenated tensor requirements</a></li>
<li>
<p>Must follow <a href="#lstm-hid_sz">num_hidden requirements</a></p>
</li>
<li>
<p><code>zdnn_ztensor *biases</code></p>
</li>
<li>
<p>Tensor containing the concatenated input connection bias in Forget, Input,
    Cell, Output (FICO) order.</p>
</li>
<li>Prior to transformation, expects each gate needs to be shape (num_dirs,
    num_hidden).</li>
<li>Expects <code>pre_transformed_desc-&gt;layout</code> to be <code>ZDNN_2DS</code>.</li>
<li>Expects <code>zdnn_concat_info</code> having the following flags turned on:<ul>
<li><code>RNN_TYPE_LSTM</code></li>
<li><code>USAGE_HIDDEN_WEIGHTS</code></li>
<li>Appropriate <code>PREV_LAYER</code> flag:</li>
<li><code>PREV_LAYER_NONE</code> if <code>input</code> tensor is not from a previous RNN layer</li>
<li><code>PREV_LAYER_UNI</code> if <code>input</code> tensor is uni-directional output from a
    previous RNN layer</li>
<li><code>PREV_LAYER_BIDIR</code> if <code>input</code> tensor is bi-directional output from a
    previous RNN layer</li>
</ul>
</li>
<li>Must follow <a href="#concat-zten-reqs">concatenated tensor requirements</a></li>
<li>
<p>Must follow <a href="#lstm-hid_sz">num_hidden requirements</a></p>
</li>
<li>
<p><code>zdnn_ztensor *hidden_weights</code></p>
</li>
<li>
<p>Tensor containing the concatenated hidden connection weights in Forget,
    Input, Cell, Output (FICO) order.</p>
</li>
<li>Prior to transformation, each gate needs to be transposed to shape
    (num_dirs, num_hidden, num_hidden) by the caller.</li>
<li>Expects <code>pre_transformed_desc-&gt;layout</code> to be <code>ZDNN_3DS</code>.</li>
<li>Expects <code>zdnn_concat_info</code> having the following flags turned on:<ul>
<li><code>RNN_TYPE_LSTM</code></li>
<li><code>USAGE_BIASES</code></li>
<li>Appropriate <code>PREV_LAYER</code> flag:</li>
<li><code>PREV_LAYER_NONE</code> if <code>input</code> tensor is not from a previous RNN layer</li>
<li><code>PREV_LAYER_UNI</code> if <code>input</code> tensor is uni-directional output from a
    previous RNN layer</li>
<li><code>PREV_LAYER_BIDIR</code> if <code>input</code> tensor is bi-directional output from a
    previous RNN layer</li>
</ul>
</li>
<li>Must follow <a href="#concat-zten-reqs">concatenated tensor requirements</a></li>
<li>
<p>Must follow <a href="#lstm-hid_sz">num_hidden requirements</a></p>
</li>
<li>
<p><code>zdnn_ztensor *hidden_biases</code></p>
</li>
<li>
<p>Tensor containing the concatenated hidden connection bias in Forget, Input,
    Cell, Output (FICO) order.</p>
</li>
<li>Prior to transformation, expects each gate needs to be shape (num_dirs,
    num_hidden).</li>
<li>Expects <code>pre_transformed_desc-&gt;layout</code> to be <code>ZDNN_2DS</code>.</li>
<li>Expects <code>zdnn_concat_info</code> having the following flags turned on:<ul>
<li><code>RNN_TYPE_LSTM</code></li>
<li><code>USAGE_HIDDEN_BIASES</code></li>
<li>Appropriate <code>PREV_LAYER</code> flag:</li>
<li><code>PREV_LAYER_NONE</code> if <code>input</code> tensor is not from a previous RNN layer</li>
<li><code>PREV_LAYER_UNI</code> if <code>input</code> tensor is uni-directional output from a
    previous RNN layer</li>
<li><code>PREV_LAYER_BIDIR</code> if <code>input</code> tensor is bi-directional output from a
    previous RNN layer</li>
</ul>
</li>
<li>Must follow <a href="#concat-zten-reqs">concatenated tensor requirements</a></li>
<li>
<p>Must follow <a href="#lstm-hid_sz">num_hidden requirements</a></p>
</li>
<li>
<p><code>lstm_gru_direction direction</code></p>
</li>
<li>
<p>Direction indicator of <code>lstm_gru_direction direction</code> type. Valid values:</p>
<ul>
<li><code>FWD</code> (forward)</li>
<li><code>BWD</code> (backward)</li>
<li><code>BIDIR</code> (bi-directional).</li>
</ul>
</li>
<li>
<p>For input and output shapes, the num_dirs dimension should be:</p>
<ul>
<li><code>1</code> for unidirectional calls such as FWD or BWD</li>
<li><code>2</code> for bidirectional calls such that:</li>
<li>dimension 0 contains FWD values.</li>
<li>dimension 1 contains BWD values.</li>
</ul>
</li>
<li>
<p><code>void *work_area</code></p>
</li>
<li>
<p>A preallocated memory address to use for temporary storage during internal
    operation processing.</p>
</li>
<li>If set to NULL, the operation will determine, allocate and free storage
    automatically.</li>
<li>
<p>Amount of required storage can be determined given the LSTM timestep, batch,
    and num_hidden values.</p>
<ul>
<li>The sample code below creates a ztensor descriptor that is an equivalent
  size of the required <code>work_area</code>. To use this sample code yourself,
  replace the <code>num_timesteps</code>, <code>num_batches</code>, and <code>num_hidden</code> variables
  with your own values.</li>
</ul>
<div class="highlight"><pre><span></span><code>  zdnn_tensor_desc desc;
  desc.dim4 = (4 * num_timesteps) + 6;
  desc.dim3 = 1;
  desc.dim2 = num_batches;
  desc.dim1 = num_hidden;
  uint64_t work_area_size = zdnn_getsize_ztensor(&amp;desc);
</code></pre></div>
</li>
<li>
<p>For bidirectional, twice the amount of contiguous storage is required.</p>
</li>
<li>
<p>The start of the buffer must be 4k aligned.</p>
</li>
<li>
<p><code>zdnn_ztensor *hn_output</code></p>
</li>
<li>
<p>Output results of the hidden states</p>
</li>
<li>
<p>Expects pre_transformed_desc-&gt;layout to be <code>ZDNN_4DS</code>.</p>
</li>
<li>
<p>Must follow <a href="#gen-zten-reqs">general tensor requirements</a></p>
</li>
<li>
<p>Must follow <a href="#lstm-hid_sz">num_hidden requirements</a></p>
</li>
<li>
<p>Output pre-transformed shapes:</p>
<ul>
<li>all timesteps: (num_timesteps, num_dirs, num_batches, num_hidden)</li>
<li>final timestep only: (1, num_dirs, num_batches, num_hidden)</li>
</ul>
</li>
<li>
<p>For bidirectional (<code>BIDIR</code>) output:</p>
<ul>
<li>Forward and backward results are concatenated on the innermost dimension.</li>
<li>Can be used directly as input for subsequent RNN layers without needing
  untransformation.</li>
<li>Can not be used directly as input for other non-RNN zDNN ops.</li>
<li>Untransformation is supported.</li>
</ul>
</li>
<li>
<p>Note that for <code>BWD</code> and the backward component of <code>BIDIR</code> directions, the
    output order matches the order of the input, not the processing order. For
    example, the first input timestep is the last to be processed and its result
    is the first timestep of the output.</p>
</li>
<li>
<p><code>zdnn_ztensor *cf_output</code></p>
</li>
<li>
<p>Output results of the cell state for the last processed timestep</p>
</li>
<li>
<p>Expects pre_transformed_desc-&gt;layout to be <code>ZDNN_4DS</code>.</p>
</li>
<li>
<p>Must follow <a href="#gen-zten-reqs">general tensor requirements</a></p>
</li>
<li>
<p>Must follow <a href="#lstm-hid_sz">num_hidden requirements</a></p>
</li>
<li>
<p>Output pre-transformed shapes:</p>
<ul>
<li>(1, num_dirs, num_batches, num_hidden)</li>
</ul>
</li>
<li>
<p>For bidirectional (<code>BIDIR</code>):</p>
<ul>
<li>Forward and backward results are concatenated on the innermost dimension.</li>
<li>Can not be used directly as input for other non-RNN zDNN ops.</li>
<li>Untransformation is supported.</li>
</ul>
</li>
</ul>
<h4 id="summary">Summary<a class="headerlink" href="#summary" title="Permanent link">&para;</a></h4>
<table>
<thead>
<tr>
<th></th>
<th>pre-transformed layout</th>
<th>pre-transformed shape</th>
</tr>
</thead>
<tbody>
<tr>
<td>input</td>
<td><code>ZDNN_3DS</code></td>
<td>(num_timesteps, num_batches, num_features)</td>
</tr>
<tr>
<td>h0</td>
<td><code>ZDNN_3DS</code></td>
<td>(num_dirs, num_batches, num_hidden)</td>
</tr>
<tr>
<td>c0</td>
<td><code>ZDNN_3DS</code></td>
<td>(num_dirs, num_batches, num_hidden)</td>
</tr>
<tr>
<td>weights</td>
<td><code>ZDNN_3DS</code></td>
<td>(num_dirs, num_features, num_hidden)</td>
</tr>
<tr>
<td>bias</td>
<td><code>ZDNN_2DS</code></td>
<td>(num_dirs, num_hidden)</td>
</tr>
<tr>
<td>hidden_weights</td>
<td><code>ZDNN_3DS</code></td>
<td>(num_dirs, num_hidden, num_hidden)</td>
</tr>
<tr>
<td>hidden_biases</td>
<td><code>ZDNN_2DS</code></td>
<td>(num_dirs, num_hidden)</td>
</tr>
<tr>
<td>hn_output</td>
<td><code>ZDNN_4DS</code></td>
<td>(num_timesteps, num_dirs, num_batches, num_hidden)<br>(last timestep only when <code>num_timesteps</code> = 1)</td>
</tr>
<tr>
<td>cf_output</td>
<td><code>ZDNN_4DS</code></td>
<td>(1, num_dirs, num_batches, num_hidden)</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th></th>
<th>create transformed descriptor via</th>
</tr>
</thead>
<tbody>
<tr>
<td>input</td>
<td><code>zdnn_generate_transformed_desc</code></td>
</tr>
<tr>
<td>h0</td>
<td><code>zdnn_generate_transformed_desc</code></td>
</tr>
<tr>
<td>c0</td>
<td><code>zdnn_generate_transformed_desc</code></td>
</tr>
<tr>
<td>weights</td>
<td><code>zdnn_generate_transformed_desc_concatenated</code> - <code>RNN_TYPE_LSTM</code> + <code>USAGE_WEIGHTS</code> + one of the following:<br><code>PREV_LAYER_NONE</code>/<code>PREV_LAYER_UNI</code>/<code>PREV_LAYER_BIDIR</code></td>
</tr>
<tr>
<td>bias</td>
<td><code>zdnn_generate_transformed_desc_concatenated</code> - <code>RNN_TYPE_LSTM</code> + <code>USAGE_BIASES</code> + one of the following:<br><code>PREV_LAYER_NONE</code>/<code>PREV_LAYER_UNI</code>/<code>PREV_LAYER_BIDIR</code></td>
</tr>
<tr>
<td>hidden_weights</td>
<td><code>zdnn_generate_transformed_desc_concatenated</code> - <code>RNN_TYPE_LSTM</code> + <code>USAGE_HIDDEN_WEIGHTS</code> + one of the following:<br><code>PREV_LAYER_NONE</code>/<code>PREV_LAYER_UNI</code>/<code>PREV_LAYER_BIDIR</code></td>
</tr>
<tr>
<td>hidden_biases</td>
<td><code>zdnn_generate_transformed_desc_concatenated</code> - <code>RNN_TYPE_LSTM</code> + <code>USAGE_HIDDEN_BIASES</code> + one of the following:<br><code>PREV_LAYER_NONE</code>/<code>PREV_LAYER_UNI</code>/<code>PREV_LAYER_BIDIR</code></td>
</tr>
<tr>
<td>hn_output</td>
<td><code>zdnn_generate_transformed_desc</code></td>
</tr>
<tr>
<td>cf_output</td>
<td><code>zdnn_generate_transformed_desc</code></td>
</tr>
</tbody>
</table>
<h4 id="returns-see-zdnn-statuses-for-descriptions_15">Returns (see <a href="#common-statuses">zDNN Statuses</a> for descriptions)<a class="headerlink" href="#returns-see-zdnn-statuses-for-descriptions_15" title="Permanent link">&para;</a></h4>
<ul>
<li><code>ZDNN_OK</code></li>
<li><code>ZDNN_INVALID_TYPE</code></li>
<li><code>ZDNN_INVALID_FORMAT</code></li>
<li><code>ZDNN_INVALID_SHAPE</code> - (if any of the following are not true)</li>
<li><code>hn_output</code> timesteps dimension must be 1 or the same size as <code>input</code>
    timestep dimension.</li>
<li>All tensors with a direction dimension have the same direction dimension
    size.</li>
<li><code>input</code> timestep dimension must be greater than or equal to 1.</li>
<li>Other general shape violations (exceeds MDIS, etc.)</li>
<li><code>ZDNN_INVALID_DIRECTION</code> - <code>direction</code> parameter was not a recognized
  <code>lstm_gru_direction</code>.</li>
<li><code>ZDNN_ALLOCATION_FAILURE</code> - A preallocated <code>work_area</code> was not specified and
  internal allocation for the required memory failed.</li>
<li><a href="#hw-statuses">hardware statuses</a></li>
</ul>
<h4 id="framework-examples_16">Framework Examples<a class="headerlink" href="#framework-examples_16" title="Permanent link">&para;</a></h4>
<p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTMCell">TensorFlow LSTM</a></p>
<p><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#LSTM">ONNX LSTM</a></p>
<hr />
<h3 id="zdnn_gru">zdnn_gru<a class="headerlink" href="#zdnn_gru" title="Permanent link">&para;</a></h3>
<p><a href="#TOC">Back to Table of Contents</a></p>
<h4 id="description_44">Description<a class="headerlink" href="#description_44" title="Permanent link">&para;</a></h4>
<p>Implements Gated Recurrent Unit (Kyunghyun Cho 2014). Supports only reset after
linear.</p>
<p>The following formula is computed for the input tensor input(t) for all time
steps:</p>
<div class="highlight"><pre><span></span><code>(Default: f=Sigmoid, g=Tanh):

- zt = f(Xt*(Wz^T) + Ht-1*(Rz^T) + Wbz + Rbz)

- rt = f(Xt*(Wr^T) + Ht-1*(Rr^T) + Wbr + Rbr)

- ht = g(Xt*(Wh^T) + (rt (.) (Ht-1*(Rh^T) + Rbh)) + Wbh)

- Ht = (1 - zt) (.) ht + zt (.) Ht-1
</code></pre></div>
<h4 id="format_44">Format<a class="headerlink" href="#format_44" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code>zdnn_status zdnn_gru(const zdnn_ztensor *input, const zdnn_ztensor *h0,
                     const zdnn_ztensor *weights, const zdnn_ztensor *biases,
                     const zdnn_ztensor *hidden_weights,
                     const zdnn_ztensor *hidden_biases,
                     lstm_gru_direction direction, void *work_area,
                     zdnn_ztensor *hn_output);
</code></pre></div>
<p>Also see an <a href="#example-of-an-application-calling-the-zdnn_gru-api">example</a> in
the usage example section.</p>
<h4 id="gru-input-output-requirements">GRU Input / Output requirements<a class="headerlink" href="#gru-input-output-requirements" title="Permanent link">&para;</a></h4>
<ul>
<li><code>num_hidden</code> dimensions: <a id="gru-hid_sz"></a></li>
<li>Any num_hidden dimension must be less than or equal to 10880 elements.</li>
</ul>
<h4 id="parameters_42">Parameters<a class="headerlink" href="#parameters_42" title="Permanent link">&para;</a></h4>
<ul>
<li>
<p><code>zdnn_ztensor *input</code></p>
</li>
<li>
<p>Input must be a tensor with the shape (num_timesteps, num_batches,
    num_features) prior to transformation with the <code>zdnn_transform_ztensor</code> API.</p>
</li>
<li>Expects <code>pre_transformed_desc-&gt;layout</code> to be <code>ZDNN_3DS</code>.</li>
<li>
<p>Must follow <a href="#gen-zten-reqs">general tensor requirements</a></p>
</li>
<li>
<p><code>zdnn_ztensor *h0</code></p>
</li>
<li>
<p>Tensor containing the initial hidden state with shape (num_dirs,
    num_batches, num_hidden) prior to transformation with the
    <code>zdnn_transform_ztensor</code> API.</p>
</li>
<li>Expects <code>pre_transformed_desc-&gt;layout</code> to be <code>ZDNN_3DS</code>.</li>
<li>Must follow <a href="#gen-zten-reqs">general tensor requirements</a></li>
<li>
<p>Must follow <a href="#gru-hid_sz">num_hidden requirements</a></p>
</li>
<li>
<p><code>zdnn_ztensor *weights</code></p>
</li>
<li>
<p>Tensor containing the concatenated input connection weights in (Z)update,
    Reset, Hidden, (ZRH) order.</p>
</li>
<li>Prior to transformation, each gate needs to be transposed to shape
    (num_dirs, num_features, num_hidden) by the caller.</li>
<li>Expects <code>pre_transformed_desc-&gt;layout</code> to be <code>ZDNN_3DS</code>.</li>
<li>Expects <code>zdnn_concat_info</code> having the following flags turned on:<ul>
<li><code>RNN_TYPE_GRU</code></li>
<li><code>USAGE_WEIGHTS</code></li>
<li>Appropriate <code>PREV_LAYER</code> flag:</li>
<li><code>PREV_LAYER_NONE</code> if <code>input</code> tensor is not from a previous RNN layer</li>
<li><code>PREV_LAYER_UNI</code> if <code>input</code> tensor is uni-directional output from a
    previous RNN layer</li>
<li><code>PREV_LAYER_BIDIR</code> if <code>input</code> tensor is bi-directional output from a
    previous RNN layer</li>
</ul>
</li>
<li>Must follow <a href="#concat-zten-reqs">concatenated tensor requirements</a></li>
<li>
<p>Must follow <a href="#gru-hid_sz">num_hidden requirements</a></p>
</li>
<li>
<p><code>zdnn_ztensor *biases</code></p>
</li>
<li>
<p>Tensor containing the concatenated input connection bias in (Z)update,
    Reset, Hidden, (ZRH) order.</p>
</li>
<li>Prior to transformation, expects each gate needs to be shape (num_dirs,
    num_hidden).</li>
<li>Expects <code>pre_transformed_desc-&gt;layout</code> to be <code>ZDNN_2DS</code>.</li>
<li>Expects <code>zdnn_concat_info</code> having the following flags turned on:<ul>
<li><code>RNN_TYPE_GRU</code></li>
<li><code>USAGE_HIDDEN_WEIGHTS</code></li>
<li>Appropriate <code>PREV_LAYER</code> flag:</li>
<li><code>PREV_LAYER_NONE</code> if <code>input</code> tensor is not from a previous RNN layer</li>
<li><code>PREV_LAYER_UNI</code> if <code>input</code> tensor is uni-directional output from a
    previous RNN layer</li>
<li><code>PREV_LAYER_BIDIR</code> if <code>input</code> tensor is bi-directional output from a
    previous RNN layer</li>
</ul>
</li>
<li>Must follow <a href="#concat-zten-reqs">concatenated tensor requirements</a></li>
<li>
<p>Must follow <a href="#gru-hid_sz">num_hidden requirements</a></p>
</li>
<li>
<p><code>zdnn_ztensor *hidden_weights</code></p>
</li>
<li>
<p>Tensor containing the concatenated hidden connection weights in (Z)update,
    Reset, Hidden, (ZRH) order.</p>
</li>
<li>Prior to transformation, each gate needs to be transposed to shape
    (num_dirs, num_hidden, num_hidden) by the caller.</li>
<li>Expects <code>pre_transformed_desc-&gt;layout</code> to be <code>ZDNN_3DS</code>.</li>
<li>Expects <code>zdnn_concat_info</code> having the following flags turned on:<ul>
<li><code>RNN_TYPE_GRU</code></li>
<li><code>USAGE_BIASES</code></li>
<li>Appropriate <code>PREV_LAYER</code> flag:</li>
<li><code>PREV_LAYER_NONE</code> if <code>input</code> tensor is not from a previous RNN layer</li>
<li><code>PREV_LAYER_UNI</code> if <code>input</code> tensor is uni-directional output from a
    previous RNN layer</li>
<li><code>PREV_LAYER_BIDIR</code> if <code>input</code> tensor is bi-directional output from a
    previous RNN layer</li>
</ul>
</li>
<li>Must follow <a href="#concat-zten-reqs">concatenated tensor requirements</a></li>
<li>
<p>Must follow <a href="#gru-hid_sz">num_hidden requirements</a></p>
</li>
<li>
<p><code>zdnn_ztensor *hidden_biases</code></p>
</li>
<li>
<p>Tensor containing the concatenated hidden connection bias in (Z)update,
    Reset, Hidden, (ZRH) order.</p>
</li>
<li>Prior to transformation, expects each gate needs to be shape (num_dirs,
    num_hidden).</li>
<li>Expects <code>pre_transformed_desc-&gt;layout</code> to be <code>ZDNN_2DS</code>.</li>
<li>Expects <code>zdnn_concat_info</code> having the following flags turned on:<ul>
<li><code>RNN_TYPE_GRU</code></li>
<li><code>USAGE_HIDDEN_BIASES</code></li>
<li>Appropriate <code>PREV_LAYER</code> flag:</li>
<li><code>PREV_LAYER_NONE</code> if <code>input</code> tensor is not from a previous RNN layer</li>
<li><code>PREV_LAYER_UNI</code> if <code>input</code> tensor is uni-directional output from a
    previous RNN layer</li>
<li><code>PREV_LAYER_BIDIR</code> if <code>input</code> tensor is bi-directional output from a
    previous RNN layer</li>
</ul>
</li>
<li>Must follow <a href="#concat-zten-reqs">concatenated tensor requirements</a></li>
<li>
<p>Must follow <a href="#gru-hid_sz">num_hidden requirements</a></p>
</li>
<li>
<p><code>lstm_gru_direction direction</code></p>
</li>
<li>
<p>Direction indicator of <code>lstm_gru_direction direction</code> type. Valid values:</p>
<ul>
<li><code>FWD</code> (forward)</li>
<li><code>BWD</code> (backward)</li>
<li><code>BIDIR</code> (bi-directional).</li>
</ul>
</li>
<li>
<p>For input shapes, the num_dirs dimension should be:</p>
<ul>
<li><code>1</code> for unidirectional calls such as FWD or BWD</li>
<li><code>2</code> for bidirectional calls such that:</li>
<li>dimension 0 contains FWD values.</li>
<li>dimension 1 contains BWD values.</li>
</ul>
</li>
<li>
<p><code>void *work_area</code></p>
</li>
<li>
<p>A preallocated memory address to use for temporary storage during internal
    operation processing.</p>
</li>
<li>If set to NULL, the operation will determine, allocate and free storage
    automatically.</li>
<li>
<p>Amount of required storage can be determined given the GRU timestep, batch,
    and num_hidden values.</p>
<ul>
<li>The sample code below creates a ztensor descriptor that is an equivalent
  size of the required <code>work_area</code>. To use this sample code yourself,
  replace the <code>num_timesteps</code>, <code>num_batches</code>, and <code>num_hidden</code> variables
  with your own values.</li>
</ul>
<div class="highlight"><pre><span></span><code>  zdnn_tensor_desc desc;
  desc.dim4 = (3 * num_timesteps) + 5;
  desc.dim3 = 1;
  desc.dim2 = num_batches;
  desc.dim1 = num_hidden;
  uint64_t work_area_size = zdnn_getsize_ztensor(&amp;desc);
</code></pre></div>
</li>
<li>
<p>For bidirectional, twice the amount of contiguous storage is required.</p>
</li>
<li>
<p>The start of the buffer must be 4k aligned.</p>
</li>
<li>
<p><code>zdnn_ztensor *hn_output</code></p>
</li>
<li>
<p>Output results of the hidden states</p>
</li>
<li>
<p>Expects pre_transformed_desc-&gt;layout to be <code>ZDNN_4DS</code>.</p>
</li>
<li>
<p>Must follow <a href="#gen-zten-reqs">general tensor requirements</a></p>
</li>
<li>
<p>Must follow <a href="#lstm-hid_sz">num_hidden requirements</a></p>
</li>
<li>
<p>Output pre-transformed shapes:</p>
<ul>
<li>all timesteps: (num_timesteps, num_dirs, num_batches, num_hidden)</li>
<li>final timestep only: (1, num_dirs, num_batches, num_hidden)</li>
</ul>
</li>
<li>
<p>For bidirectional (<code>BIDIR</code>) output:</p>
<ul>
<li>Forward and backward results are concatenated on the innermost dimension.</li>
<li>Can be used directly as input for subsequent RNN layers without needing
  untransformation.</li>
<li>Can not be used directly as input for other non-RNN zDNN ops.</li>
<li>Untransformation is supported.</li>
</ul>
</li>
<li>
<p>Note that for <code>BWD</code> and the backward component of <code>BIDIR</code> directions, the
    output order matches the order of the input, not the processing order. For
    example, the first input timestep is the last to be processed and its result
    is the first timestep of the output.</p>
</li>
</ul>
<h4 id="summary_1">Summary<a class="headerlink" href="#summary_1" title="Permanent link">&para;</a></h4>
<table>
<thead>
<tr>
<th></th>
<th>pre-transformed layout</th>
<th>pre-transformed shape</th>
</tr>
</thead>
<tbody>
<tr>
<td>input</td>
<td><code>ZDNN_3DS</code></td>
<td>(num_timesteps, num_batches, num_features)</td>
</tr>
<tr>
<td>h0</td>
<td><code>ZDNN_3DS</code></td>
<td>(num_dirs, num_batches, num_hidden)</td>
</tr>
<tr>
<td>c0</td>
<td><code>ZDNN_3DS</code></td>
<td>(num_dirs, num_batches, num_hidden)</td>
</tr>
<tr>
<td>weights</td>
<td><code>ZDNN_3DS</code></td>
<td>(num_dirs, num_features, num_hidden)</td>
</tr>
<tr>
<td>bias</td>
<td><code>ZDNN_2DS</code></td>
<td>(num_dirs, num_hidden)</td>
</tr>
<tr>
<td>hidden_weights</td>
<td><code>ZDNN_3DS</code></td>
<td>(num_dirs, num_hidden, num_hidden)</td>
</tr>
<tr>
<td>hidden_biases</td>
<td><code>ZDNN_2DS</code></td>
<td>(num_dirs, num_hidden)</td>
</tr>
<tr>
<td>hn_output</td>
<td><code>ZDNN_4DS</code></td>
<td>(num_timesteps, num_dirs, num_batches, num_hidden)<br>(last timestep only when <code>num_timesteps</code> = 1)</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th></th>
<th>create transformed descriptor via</th>
</tr>
</thead>
<tbody>
<tr>
<td>input</td>
<td><code>zdnn_generate_transformed_desc</code></td>
</tr>
<tr>
<td>h0</td>
<td><code>zdnn_generate_transformed_desc</code></td>
</tr>
<tr>
<td>c0</td>
<td><code>zdnn_generate_transformed_desc</code></td>
</tr>
<tr>
<td>weights</td>
<td><code>zdnn_generate_transformed_desc_concatenated</code> - <code>RNN_TYPE_LSTM</code> + <code>USAGE_WEIGHTS</code> + one of the following:<br><code>PREV_LAYER_NONE</code>/<code>PREV_LAYER_UNI</code>/<code>PREV_LAYER_BIDIR</code></td>
</tr>
<tr>
<td>bias</td>
<td><code>zdnn_generate_transformed_desc_concatenated</code> - <code>RNN_TYPE_LSTM</code> + <code>USAGE_BIASES</code> + one of the following:<br><code>PREV_LAYER_NONE</code>/<code>PREV_LAYER_UNI</code>/<code>PREV_LAYER_BIDIR</code></td>
</tr>
<tr>
<td>hidden_weights</td>
<td><code>zdnn_generate_transformed_desc_concatenated</code> - <code>RNN_TYPE_LSTM</code> + <code>USAGE_HIDDEN_WEIGHTS</code> + one of the following:<br><code>PREV_LAYER_NONE</code>/<code>PREV_LAYER_UNI</code>/<code>PREV_LAYER_BIDIR</code></td>
</tr>
<tr>
<td>hidden_biases</td>
<td><code>zdnn_generate_transformed_desc_concatenated</code> - <code>RNN_TYPE_LSTM</code> + <code>USAGE_HIDDEN_BIASES</code> + one of the following:<br><code>PREV_LAYER_NONE</code>/<code>PREV_LAYER_UNI</code>/<code>PREV_LAYER_BIDIR</code></td>
</tr>
<tr>
<td>hn_output</td>
<td><code>zdnn_generate_transformed_desc</code></td>
</tr>
</tbody>
</table>
<h4 id="returns-see-zdnn-statuses-for-descriptions_16">Returns (see <a href="#common-statuses">zDNN Statuses</a> for descriptions)<a class="headerlink" href="#returns-see-zdnn-statuses-for-descriptions_16" title="Permanent link">&para;</a></h4>
<ul>
<li><code>ZDNN_OK</code></li>
<li><code>ZDNN_INVALID_TYPE</code></li>
<li><code>ZDNN_INVALID_FORMAT</code></li>
<li><code>ZDNN_INVALID_SHAPE</code> - (if any of the following are not true)</li>
<li><code>hn_output</code> timesteps dimension must be 1 or the same size as <code>input</code>
    timestep dimension.</li>
<li>All tensors with a direction dimension have the same direction dimension
    size.</li>
<li><code>input</code> timestep dimension must be greater than or equal to 1.</li>
<li>Other general shape violations (exceeds MDIS, etc.)</li>
<li><code>ZDNN_INVALID_DIRECTION</code> - <code>direction</code> parameter was not a recognized
  <code>lstm_gru_direction</code>.</li>
<li><code>ZDNN_ALLOCATION_FAILURE</code> - A preallocated <code>work_area</code> was not specified and
  internal allocation for the required memory failed.</li>
<li><a href="#hw-statuses">hardware statuses</a></li>
</ul>
<h4 id="framework-examples_17">Framework Examples<a class="headerlink" href="#framework-examples_17" title="Permanent link">&para;</a></h4>
<p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/GRUCell">TensorFlow GRU</a></p>
<p><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#GRU">ONNX GRU</a></p>
<hr />
<h3 id="zdnn_avgpool2d">zdnn_avgpool2d<a class="headerlink" href="#zdnn_avgpool2d" title="Permanent link">&para;</a></h3>
<p><a href="#TOC">Back to Table of Contents</a></p>
<h4 id="description_45">Description<a class="headerlink" href="#description_45" title="Permanent link">&para;</a></h4>
<p>Given an input tensor in zDNN transformed format, padding type, kernel size and
kernel stride, produces a downsampled tensor reducing the middle dimensions
based on the mean values within the kernel window at each step and stores the
results into the provided output zDNN tensor.</p>
<h4 id="format_45">Format<a class="headerlink" href="#format_45" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code>zdnn_status zdnn_avgpool2d(const zdnn_ztensor *input,
                           zdnn_pool_padding padding_type,
                           uint32_t kernel_height, uint32_t kernel_width,
                           uint32_t stride_height, uint32_t stride_width,
                           zdnn_ztensor *output);
</code></pre></div>
<h4 id="parameters_43">Parameters<a class="headerlink" href="#parameters_43" title="Permanent link">&para;</a></h4>
<ul>
<li>
<p><code>zdnn_ztensor *input</code></p>
</li>
<li>
<p>Tensor with original values to be downsampled in the output tensor.</p>
</li>
<li>Must be a <a href="#common-layouts">ZDNN_NHWC</a> tensor with pre_transformed shape
    [batch_Num, Height, Width, Channel].</li>
<li>See <a href="#avgpool2d-parm-restrictions">Parameter Restrictions</a> below for
    information on the expected shape of the input tensor.</li>
<li>
<p>Must follow <a href="#gen-zten-reqs">general tensor requirements</a></p>
</li>
<li>
<p><code>padding_type</code></p>
</li>
<li>
<p>The type of padding to use for the pooling operations.</p>
</li>
<li>Valid values: are <code>SAME_PADDING</code> or <code>VALID_PADDING</code>.</li>
<li>See <a href="#avgpool2d-parm-restrictions">Parameter Restrictions</a> below for
    information on the expected value of padding_type.</li>
<li>
<p>For information on "same" vs "valid" padding see:
    <a href="https://www.pico.net/kb/what-is-the-difference-between-same-and-valid-padding-in-tf-nn-max-pool-of-tensorflow">https://www.pico.net/kb/what-is-the-difference-between-same-and-valid-padding-in-tf-nn-max-pool-of-tensorflow</a>.</p>
</li>
<li>
<p><code>kernel_height</code></p>
</li>
<li>
<p>Size of the kernel window that passes over the input's height dimension.</p>
</li>
<li>
<p>See <a href="#avgpool2d-parm-restrictions">Parameter Restrictions</a> below for
    information on the expected value of kerneL_height.</p>
</li>
<li>
<p><code>kernel_width</code></p>
</li>
<li>
<p>Size of the kernel window that passes over the input's width dimension.</p>
</li>
<li>
<p>See <a href="#avgpool2d-parm-restrictions">Parameter Restrictions</a> below for
    information on the expected value of kerneL_width.</p>
</li>
<li>
<p><code>stride_height</code></p>
</li>
<li>
<p>Number of positions the kernel moves over input's height dimension at each
    step.</p>
</li>
<li>If <code>stride_height</code> is 0 then <code>stride_width</code> must also be 0.</li>
<li>
<p>If strides are greater than 0 then <code>stride_height</code> must be less than or
    equal to 30.</p>
</li>
<li>
<p><code>stride_width</code></p>
</li>
<li>
<p>Number of positions the kernel moves over the input's width dimension at
    each step.</p>
</li>
<li>If <code>stride_height</code> is 0 then <code>stride_width</code> must also be 0.</li>
<li>
<p>If strides are greater than 0 then <code>stride_width</code> must be less than or equal
    to 30.</p>
</li>
<li>
<p><code>zdnn_ztensor *output</code></p>
</li>
<li>The result tensor which will hold the result of the pooling operation its
    buffer.</li>
<li>Must be a <a href="#common-layouts">ZDNN_NHWC</a> tensor with pre_transformed shape
    [batch_Num, Height, Width, Channel].</li>
<li>See <a href="#avgpool2d-parm-restrictions">Parameter Restrictions</a> below for
    information on the expected shape of the output tensor.</li>
<li>Must follow <a href="#gen-zten-reqs">general tensor requirements</a></li>
</ul>
<h4 id="avgpool2d-parameter-restrictions">AvgPool2D Parameter Restrictions <a id="avgpool2d-parm-restrictions"></a><a class="headerlink" href="#avgpool2d-parameter-restrictions" title="Permanent link">&para;</a></h4>
<p>Parameter restrictions may vary based on provided strides and padding_type.</p>
<ul>
<li>
<p>Input tensor batch_Num and Channel dimensions must always match the output
  tensor's respective dimensions.</p>
</li>
<li>
<p>If strides are 0:</p>
</li>
<li>Both input tensor's Height dimension and the kernel_height must match and be
    less than or equal to 1024.</li>
<li>Both input tensor's Width dimension and the kernel_width must match and be
    less than or equal to 1024.</li>
<li>Output tensor's height and width dimensions must be 1.</li>
<li>padding_type must be <code>VALID_PADDING</code>.</li>
<li>If strides are greater than zero:</li>
<li>kernel_width and kernel_height must be less than or equal to 64.</li>
<li>input tensor's height or weight dimension must not be greater than 1024.</li>
<li>If padding_type is <code>SAME_PADDING</code>:<ul>
<li>Output tensor's height dimension must equal
  <code>ceil((float)input's height / stride_height)</code>.</li>
<li>Output tensor's width dimension must equal
  <code>ceil((float)input's width / stride_width)</code>.</li>
</ul>
</li>
<li>If padding_type is <code>VALID_PADDING</code>:<ul>
<li>Output tensor's height dimension must equal
  <code>ceil((float)(input's height - kernel_height + 1) / stride_height)</code>.</li>
<li>Output tensor's width dimension must equal
  <code>ceil((float)(input's width - kernel_width + 1) / stride_width)</code>.</li>
</ul>
</li>
</ul>
<h4 id="programming-notes_9">Programming Notes<a class="headerlink" href="#programming-notes_9" title="Permanent link">&para;</a></h4>
<ul>
<li>If the magnitude of difference between elements of <code>input</code> is large (greater
  than 10), accuracy may be reduced.</li>
</ul>
<h4 id="returns-see-zdnn-statuses-for-descriptions_17">Returns (see <a href="#common-statuses">zDNN Statuses</a> for descriptions)<a class="headerlink" href="#returns-see-zdnn-statuses-for-descriptions_17" title="Permanent link">&para;</a></h4>
<ul>
<li><code>ZDNN_OK</code></li>
<li><code>ZDNN_INVALID_SHAPE</code></li>
<li>Shape of input or output tensor is invalid based on given kernel and stride
    parameters</li>
<li>Other general shape violations (exceeds MDIS, etc.)</li>
<li><code>ZDNN_INVALID_TYPE</code></li>
<li><code>ZDNN_INVALID_FORMAT</code></li>
<li><code>ZDNN_INVALID_STRIDE_PADDING</code></li>
<li><code>ZDNN_INVALID_STRIDES</code> - One stride was non-zero, but not the other.</li>
<li><a href="#hw-statuses">hardware statuses</a></li>
<li><code>ZDNN_EXCEEDS_MDIS</code> will also occur if any of the following conditions
    occur:<ul>
<li>stride_height is larger than <code>zdnn_get_nnpa_max_dim_idx_size</code>.</li>
<li>stride_width is larger than <code>zdnn_get_nnpa_max_dim_idx_size</code>.</li>
<li>kernel_height is 0 or is larger than <code>zdnn_get_nnpa_max_dim_idx_size</code>.</li>
<li>kernel_width is 0 or is larger than <code>zdnn_get_nnpa_max_dim_idx_size</code>.</li>
</ul>
</li>
<li><code>ZDNN_FUNC_RC_F000</code> - Invalid <code>padding_type</code></li>
<li><code>ZDNN_FUNC_RC_F001</code> - <code>stride_height</code> = 0 and <code>stride_width</code> = 0, but a
    kernel parameter is greater than allowed (see <code>kernel_height</code> or
    <code>kernel_width</code> above)</li>
<li><code>ZDNN_FUNC_RC_F002</code> - <code>stride_height</code> &gt; 0 and <code>stride_width</code> &gt; 0, but a
    kernel parameter is greater than allowed (see <code>kernel_height</code> or
    <code>kernel_width</code> above)</li>
<li><code>ZDNN_FUNC_RC_F003</code> - <code>stride_height</code> &gt; 0 and <code>stride_width</code> &gt; 0, but a
    stride parameter is greater than allowed (see <code>stride_height</code> or
    <code>stride_width</code> above)</li>
<li><code>ZDNN_FUNC_RC_F004</code> - <code>stride_height</code> &gt; 0 and <code>stride_width</code> &gt; 0, but either
    input tensor's height or weight dimension is greater than 1024.</li>
</ul>
<h4 id="framework-examples_18">Framework Examples<a class="headerlink" href="#framework-examples_18" title="Permanent link">&para;</a></h4>
<p><a href="https://www.tensorflow.org/api_docs/cc/class/tensorflow/ops/avg-pool">TensorFlow AvgPool</a></p>
<p><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#AveragePool">ONNX AvgPool</a></p>
<hr />
<h3 id="zdnn_maxpool2d">zdnn_maxpool2d<a class="headerlink" href="#zdnn_maxpool2d" title="Permanent link">&para;</a></h3>
<p><a href="#TOC">Back to Table of Contents</a></p>
<h4 id="description_46">Description<a class="headerlink" href="#description_46" title="Permanent link">&para;</a></h4>
<p>Given an input tensor in zDNN transformed format, padding type, kernel size and
kernel stride, produces a downsampled tensor reducing the middle dimensions
based on the maximum values within the kernel window at each step and stores the
results into the provided output zDNN tensor.</p>
<h4 id="format_46">Format<a class="headerlink" href="#format_46" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code>zdnn_status zdnn_maxpool2d(const zdnn_ztensor *input,
                           zdnn_pool_padding padding_type,
                           uint32_t kernel_height, uint32_t kernel_width,
                           uint32_t stride_height, uint32_t stride_width,
                           zdnn_ztensor *output);
</code></pre></div>
<h4 id="parameters_44">Parameters<a class="headerlink" href="#parameters_44" title="Permanent link">&para;</a></h4>
<ul>
<li>
<p><code>zdnn_ztensor *input</code></p>
</li>
<li>
<p>Tensor with original values to be downsampled in the output tensor.</p>
</li>
<li>Must be a <a href="#common-layouts">ZDNN_NHWC</a> tensor with pre_transformed shape
    [batch_Num, Height, Width, Channel].</li>
<li>See <a href="#maxpool2d-parm-restrictions">Parameter Restrictions</a> below for
    information on the expected shape of the input tensor.</li>
<li>
<p>Must follow <a href="#gen-zten-reqs">general tensor requirements</a></p>
</li>
<li>
<p><code>padding_type</code></p>
</li>
<li>
<p>The type of padding to use for the pooling operations.</p>
</li>
<li>Valid values: are <code>SAME_PADDING</code> or <code>VALID_PADDING</code>.</li>
<li>See <a href="#maxpool2d-parm-restrictions">Parameter Restrictions</a> below for
    information on the expected value of padding_type.</li>
<li>
<p>For information on "same" vs "valid" padding see:
    <a href="https://www.pico.net/kb/what-is-the-difference-between-same-and-valid-padding-in-tf-nn-max-pool-of-tensorflow">https://www.pico.net/kb/what-is-the-difference-between-same-and-valid-padding-in-tf-nn-max-pool-of-tensorflow</a>.</p>
</li>
<li>
<p><code>kernel_height</code></p>
</li>
<li>
<p>Size of the kernel window that passes over the input's height dimension.</p>
</li>
<li>
<p>See <a href="#maxpool2d-parm-restrictions">Parameter Restrictions</a> below for
    information on the expected value of kerneL_height.</p>
</li>
<li>
<p><code>kernel_width</code></p>
</li>
<li>
<p>Size of the kernel window that passes over the input's width dimension.</p>
</li>
<li>
<p>See <a href="#maxpool2d-parm-restrictions">Parameter Restrictions</a> below for
    information on the expected value of kerneL_width.</p>
</li>
<li>
<p><code>stride_height</code></p>
</li>
<li>
<p>Number of positions the kernel moves over input's height dimension at each
    step.</p>
</li>
<li>If <code>stride_height</code> is 0 then <code>stride_width</code> must also be 0.</li>
<li>
<p>If strides are greater than 0 then <code>stride_height</code> must be less than or
    equal to 30.</p>
</li>
<li>
<p><code>stride_width</code></p>
</li>
<li>
<p>Number of positions the kernel moves over the input's width dimension at
    each step.</p>
</li>
<li>If <code>stride_height</code> is 0 then <code>stride_width</code> must also be 0.</li>
<li>
<p>If strides are greater than 0 then <code>stride_width</code> must be less than or equal
    to 30.</p>
</li>
<li>
<p><code>zdnn_ztensor *output</code></p>
</li>
<li>The result tensor which will hold the result of the pooling operation its
    buffer.</li>
<li>Must be a <a href="#common-layouts">ZDNN_NHWC</a> tensor with pre_transformed shape
    [batch_Num, Height, Width, Channel].</li>
<li>See <a href="#maxpool2d-parm-restrictions">Parameter Restrictions</a> below for
    information on the expected shape of the output tensor.</li>
<li>Must follow <a href="#gen-zten-reqs">general tensor requirements</a></li>
</ul>
<h4 id="maxpool2d-parameter-restrictions">MaxPool2D Parameter Restrictions <a id="maxpool2d-parm-restrictions"></a><a class="headerlink" href="#maxpool2d-parameter-restrictions" title="Permanent link">&para;</a></h4>
<p>Parameter restrictions may vary based on provided strides and padding_type.</p>
<ul>
<li>
<p>Input tensor batch_Num and Channel dimensions must always match the output
  tensor's respective dimensions.</p>
</li>
<li>
<p>If strides are 0:</p>
</li>
<li>Both input tensor's Height dimension and the kernel_height must match and be
    less than or equal to 1024.</li>
<li>Both input tensor's Width dimension and the kernel_width must match and be
    less than or equal to 1024.</li>
<li>Output tensor's height and width dimensions must be 1.</li>
<li>padding_type must be <code>VALID_PADDING</code>.</li>
<li>If strides are greater than zero:</li>
<li>kernel_width and kernel_height must be less than or equal to 64.</li>
<li>input tensor's height or weight dimension must not be greater than 1024.</li>
<li>If padding_type is <code>SAME_PADDING</code>:<ul>
<li>Output tensor's height dimension must equal
  <code>ceil((float)input's height / stride_height)</code>.</li>
<li>Output tensor's width dimension must equal
  <code>ceil((float)input's width / stride_width)</code>.</li>
</ul>
</li>
<li>If padding_type is <code>VALID_PADDING</code>:<ul>
<li>Output tensor's height dimension must equal
  <code>ceil((float)(input's height - kernel_height + 1) / stride_height)</code>.</li>
<li>Output tensor's width dimension must equal
  <code>ceil((float)(input's width - kernel_width + 1) / stride_width)</code>.</li>
</ul>
</li>
</ul>
<h4 id="programming-notes_10">Programming Notes<a class="headerlink" href="#programming-notes_10" title="Permanent link">&para;</a></h4>
<ul>
<li>If the magnitude of difference between elements of <code>input</code> is large (greater
  than 10), accuracy may be reduced.</li>
</ul>
<h4 id="returns-see-zdnn-statuses-for-descriptions_18">Returns (see <a href="#common-statuses">zDNN Statuses</a> for descriptions)<a class="headerlink" href="#returns-see-zdnn-statuses-for-descriptions_18" title="Permanent link">&para;</a></h4>
<ul>
<li><code>ZDNN_OK</code></li>
<li><code>ZDNN_INVALID_SHAPE</code></li>
<li>Shape of input or output tensor is invalid based on given kernel and stride
    parameters</li>
<li>Other general shape violations (exceeds MDIS, etc.)</li>
<li><code>ZDNN_INVALID_TYPE</code></li>
<li><code>ZDNN_INVALID_FORMAT</code></li>
<li><code>ZDNN_INVALID_STRIDE_PADDING</code></li>
<li><code>ZDNN_INVALID_STRIDES</code> - One stride was non-zero, but not the other.</li>
<li><a href="#hw-statuses">hardware statuses</a></li>
<li><code>ZDNN_EXCEEDS_MDIS</code> will also occur if any of the following conditions
    occur:<ul>
<li>stride_height is larger than <code>zdnn_get_nnpa_max_dim_idx_size</code>.</li>
<li>stride_width is larger than <code>zdnn_get_nnpa_max_dim_idx_size</code>.</li>
<li>kernel_height is 0 or is larger than <code>zdnn_get_nnpa_max_dim_idx_size</code>.</li>
<li>kernel_width is 0 or is larger than <code>zdnn_get_nnpa_max_dim_idx_size</code>.</li>
</ul>
</li>
<li><code>ZDNN_FUNC_RC_F000</code> - Invalid <code>padding_type</code></li>
<li><code>ZDNN_FUNC_RC_F001</code> - <code>stride_height</code> = 0 and <code>stride_width</code> = 0, but a
    kernel parameter is greater than allowed (see <code>kernel_height</code> or
    <code>kernel_width</code> above)</li>
<li><code>ZDNN_FUNC_RC_F002</code> - <code>stride_height</code> &gt; 0 and <code>stride_width</code> &gt; 0, but a
    kernel parameter is greater than allowed (see <code>kernel_height</code> or
    <code>kernel_width</code> above)</li>
<li><code>ZDNN_FUNC_RC_F003</code> - <code>stride_height</code> &gt; 0 and <code>stride_width</code> &gt; 0, but a
    stride parameter is greater than allowed (see <code>stride_height</code> or
    <code>stride_width</code> above)</li>
<li><code>ZDNN_FUNC_RC_F004</code> - <code>stride_height</code> &gt; 0 and <code>stride_width</code> &gt; 0, but either
    input tensor's height or weight dimension is greater than 1024.</li>
</ul>
<h4 id="framework-examples_19">Framework Examples<a class="headerlink" href="#framework-examples_19" title="Permanent link">&para;</a></h4>
<p><a href="https://www.tensorflow.org/api_docs/cc/class/tensorflow/ops/max-pool">TensorFlow MaxPool</a></p>
<p><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#MaxPool">ONNX MaxPool</a></p>
<hr />
<h3 id="zdnn_conv2d">zdnn_conv2d<a class="headerlink" href="#zdnn_conv2d" title="Permanent link">&para;</a></h3>
<p><a href="#TOC">Back to Table of Contents</a></p>
<h4 id="description_47">Description<a class="headerlink" href="#description_47" title="Permanent link">&para;</a></h4>
<p>Perform 2D convolution over an input tensor in zDNN transformed format.</p>
<p>First the <code>input</code> tensor is convolved with the <code>kernel</code> tensor. Then the <code>bias</code>
tensor is added to the results. Then if <code>act_func</code> is not <code>CONV2D_ACT_NONE</code>, the
activation function is applied to the results. Then if <code>act_func</code> is set to
<code>CONV2D_ACT_RELU</code>, and clipping_value is not <code>NULL</code> or <code>0</code>, clipping is
performed against the intermediate result where z = min(intermediate_result,
clipping_value). Finally the results are stored into the provided output zDNN
tensor.</p>
<h4 id="format_47">Format<a class="headerlink" href="#format_47" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code>zdnn_status zdnn_conv2d(const zdnn_ztensor *input,
                        const zdnn_ztensor *kernel,
                        const zdnn_ztensor *bias,
                        zdnn_pool_padding padding_type,
                        uint32_t stride_height, uint32_t stride_width,
                        zdnn_conv2d_act act_func,
                        const void *clipping_value, zdnn_ztensor *output);
</code></pre></div>
<h4 id="parameters_45">Parameters<a class="headerlink" href="#parameters_45" title="Permanent link">&para;</a></h4>
<ul>
<li>
<p><code>zdnn_ztensor *input</code></p>
</li>
<li>
<p>Tensor with original values to be downsampled in the output tensor.</p>
</li>
<li>Must be a <a href="#common-layouts">ZDNN_NHWC</a> tensor with pre_transformed shape
    [num_batches, height_in, width_in, channels_in].</li>
<li>See <a href="#convolution-2d-requirements">Convolution 2D Requirements</a> for
    requirements.</li>
<li>
<p>Must follow <a href="#gen-zten-reqs">general tensor requirements</a></p>
</li>
<li>
<p><code>zdnn_ztensor *kernel</code></p>
</li>
<li>
<p>The kernel tensor to convolute with the input tensor.</p>
</li>
<li>Must be a <a href="#common-layouts">ZDNN_HWCK</a> tensor with pre_transformed shape
    [kernel_height, kernel_width, channels_in, channels_out].</li>
<li>See <a href="#convolution-2d-requirements">Convolution 2D Requirements</a> for
    requirements.</li>
<li>
<p>Must follow <a href="#gen-zten-reqs">general tensor requirements</a></p>
</li>
<li>
<p><code>zdnn_ztensor *bias</code></p>
</li>
<li>
<p>The bias tensor to add to the convoluted results.</p>
</li>
<li>Must be a <a href="#common-layouts">ZDNN_1D</a> tensor with pre_transformed shape
    [channels_out].</li>
<li>See <a href="#convolution-2d-requirements">Convolution 2D Requirements</a> for
    requirements.</li>
<li>
<p>Must follow <a href="#gen-zten-reqs">general tensor requirements</a></p>
</li>
<li>
<p><code>zdnn_pool_padding padding_type</code></p>
</li>
<li>
<p>The type of padding to use for the pooling operations.</p>
</li>
<li>Valid values: are <code>SAME_PADDING</code> or <code>VALID_PADDING</code>.</li>
<li>
<p>For information on "same" vs "valid" padding see:
    <a href="https://www.pico.net/kb/what-is-the-difference-between-same-and-valid-padding-in-tf-nn-max-pool-of-tensorflow">https://www.pico.net/kb/what-is-the-difference-between-same-and-valid-padding-in-tf-nn-max-pool-of-tensorflow</a>.</p>
</li>
<li>
<p><code>uint32_t stride_height</code></p>
</li>
<li>
<p>Number of positions the kernel moves over the input's <code>dim3</code> dimension at
    each step.</p>
</li>
<li>
<p>See <a href="#convolution-2d-requirements">Convolution 2D Requirements</a> for
    requirements.</p>
</li>
<li>
<p><code>uint32_t stride_width</code></p>
</li>
<li>
<p>Number of positions the kernel moves over the input's <code>dim2</code> dimension at
    each step.</p>
</li>
<li>
<p>See <a href="#convolution-2d-requirements">Convolution 2D Requirements</a> for
    requirements.</p>
</li>
<li>
<p><code>zdnn_conv2d_act act_func</code></p>
</li>
<li>
<p>Activation function to apply to the results.</p>
</li>
<li>
<p><code>CONV2D_ACT_NONE</code> or <code>CONV2D_ACT_RELU</code></p>
</li>
<li>
<p><code>void *clipping_value</code></p>
</li>
<li>
<p>A pointer to an FP32 value, used to clip input tensor's elements.</p>
</li>
<li>If set to NULL or 0, no clipping will occur.</li>
<li>Must not be a negative value.</li>
<li>
<p>Value is ignored if <code>act_func</code> is not set to <code>CONV2D_ACT_RELU</code>.</p>
</li>
<li>
<p><code>zdnn_ztensor *output</code></p>
</li>
<li>
<p>The result tensor which will hold the results.</p>
</li>
<li>Must be a <a href="#common-layouts">ZDNN_NHWC</a> tensor with pre_transformed shape
    [num_batches, height_out, width_out, channels_out].</li>
<li>See <a href="#convolution-2d-requirements">Convolution 2D Requirements</a> for
    requirements.</li>
<li>Must follow <a href="#gen-zten-reqs">general tensor requirements</a></li>
</ul>
<h4 id="convolution-2d-requirements">Convolution 2D Requirements<a class="headerlink" href="#convolution-2d-requirements" title="Permanent link">&para;</a></h4>
<table>
<thead>
<tr>
<th>strides and padding</th>
<th>input (num_batches, height_in, width_in, channels_in)</th>
<th>kernel (kernel_height, kernel_width, channels_in, channels_out)</th>
<th>bias (channels_out)</th>
<th>output (num_batches, height_out, width_out, channels_out)</th>
</tr>
</thead>
<tbody>
<tr>
<td>both strides &gt; 0 and =&lt; 13, SAME padding</td>
<td></td>
<td>both kernel_height and kernel_width must be =&lt; 64</td>
<td></td>
<td>height_out = ceil(kernel_height/stride_height)<br>width_out = ceil(kernel_width/stride_width)</td>
</tr>
<tr>
<td>both strides &gt; 0 and =&lt; 13, VALID padding</td>
<td>height_in must be &gt; kernel_height<br>width_in must be &gt; kernel_width</td>
<td>both kernel_height and kernel_width must be =&lt; 64</td>
<td></td>
<td>height_out = ceil((height_in - kernel_height + 1)/stride_height)<br>width_out = ceil((width_in - kernel_width + 1)/stride_width)</td>
</tr>
<tr>
<td>both strides = 0, VALID padding</td>
<td>height_in must be = kernel_height<br>width_in must be = kernel_width</td>
<td>both kernel_height and kernel_width must be =&lt; 448</td>
<td></td>
<td>both height_out and width_out must be 1</td>
</tr>
</tbody>
</table>
<h4 id="returns-see-zdnn-statuses-for-descriptions_19">Returns (see <a href="#common-statuses">zDNN Statuses</a> for descriptions)<a class="headerlink" href="#returns-see-zdnn-statuses-for-descriptions_19" title="Permanent link">&para;</a></h4>
<ul>
<li><code>ZDNN_OK</code></li>
<li><a href="#warning-statuses">warning statuses</a></li>
<li><code>ZDNN_INVALID_SHAPE</code></li>
<li>Shape of input or output tensor is invalid based on given kernel and stride
    parameters</li>
<li>Other general shape violations (exceeds MDIS, etc.)</li>
<li><code>ZDNN_INVALID_TYPE</code></li>
<li><code>ZDNN_INVALID_FORMAT</code></li>
<li><code>ZDNN_INVALID_STRIDE_PADDING</code></li>
<li><code>ZDNN_INVALID_STRIDES</code></li>
<li><code>ZDNN_INVALID_CLIPPING_VALUE</code></li>
<li><a href="#hw-statuses">hardware statuses</a></li>
<li><code>ZDNN_FUNC_RC_F000</code> - Invalid <code>padding_type</code></li>
<li><code>ZDNN_FUNC_RC_F001</code> - Invalid <code>act_func</code></li>
<li><code>ZDNN_FUNC_RC_F002</code> - <code>stride_height</code> = 0 and <code>stride_width</code> = 0, but either
    <code>kernel_height</code> or <code>kernel_width</code> &gt; 448</li>
<li><code>ZDNN_FUNC_RC_F003</code> - <code>stride_height</code> &gt; 0 and <code>stride_width</code> &gt; 0, but either
    <code>kernel_height</code> or <code>kernel_width</code> &gt; 64</li>
<li><code>ZDNN_FUNC_RC_F004</code> - Either <code>stride_height</code> or <code>stride_width</code> &gt; 13</li>
</ul>
<h4 id="framework-examples_20">Framework Examples<a class="headerlink" href="#framework-examples_20" title="Permanent link">&para;</a></h4>
<p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D">TensorFlow Conv2D</a></p>
<p><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md">ONNX Conv2D</a></p>
<h2 id="convenience-functions">Convenience Functions<a class="headerlink" href="#convenience-functions" title="Permanent link">&para;</a></h2>
<p><a href="#TOC">Back to Table of Contents</a></p>
<ul>
<li>None</li>
</ul>
<hr />
<h2 id="usage-examples">Usage Examples<a class="headerlink" href="#usage-examples" title="Permanent link">&para;</a></h2>
<h3 id="example-flow-of-an-application-calling-the-zdnn-apis">Example flow of an application calling the zDNN APIs<a class="headerlink" href="#example-flow-of-an-application-calling-the-zdnn-apis" title="Permanent link">&para;</a></h3>
<p><a href="#TOC">Back to Table of Contents</a></p>
<div class="highlight"><pre><span></span><code>#include &lt;assert.h&gt;
#include &lt;stdint.h&gt;
#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;string.h&gt;

#include &quot;zdnn.h&quot;

// ***************************************************************************
// Sample:
//
// Create 2 zTensors a and b, and add them together via zdnn_add()
// ***************************************************************************
int main(int argc, char *argv[]) {
  zdnn_tensor_desc pre_tfrmd_desc, tfrmd_desc;
  zdnn_ztensor ztensor_a;
  zdnn_ztensor ztensor_b;
  zdnn_ztensor ztensor_out;
  zdnn_status status;

  uint32_t dim_n = 1, dim_h = 32, dim_w = 32, dim_c = 3;
  zdnn_data_types type = FP32;
  short element_size = 4; // size of each element in bytes
  uint64_t num_elements = dim_n * dim_h * dim_w * dim_c;

  // allocate tensor data storage
  void *data1 = malloc(num_elements * element_size);
  void *data2 = malloc(num_elements * element_size);
  void *data_out = malloc(num_elements * element_size);

  // read input_data

  // check status for AIU availability, supported ops, etc. here
  // status = zdnn_query(…);

  // set input tensor data to 0 to 127 sequentially and repeat
  for (uint64_t i = 0; i &lt; num_elements; i++) {
    ((float *)data1)[i] = (float)(i &amp; 0x7f);
    ((float *)data2)[i] = (float)(i &amp; 0x7f);
  }

  zdnn_init_pre_transformed_desc(ZDNN_NHWC, type, &amp;pre_tfrmd_desc, dim_n, dim_h,
                                 dim_w, dim_c);
  // generate transformed shape information
  status = zdnn_generate_transformed_desc(&amp;pre_tfrmd_desc, &amp;tfrmd_desc);
  assert(status == ZDNN_OK);

  // initialize zTensors and allocate 4k-aligned storage via helper function
  status =
      zdnn_init_ztensor_with_malloc(&amp;pre_tfrmd_desc, &amp;tfrmd_desc, &amp;ztensor_a);
  assert(status == ZDNN_OK);
  status =
      zdnn_init_ztensor_with_malloc(&amp;pre_tfrmd_desc, &amp;tfrmd_desc, &amp;ztensor_b);
  assert(status == ZDNN_OK);
  status =
      zdnn_init_ztensor_with_malloc(&amp;pre_tfrmd_desc, &amp;tfrmd_desc, &amp;ztensor_out);
  assert(status == ZDNN_OK);

  // transform the feature tensor
  status = zdnn_transform_ztensor(&amp;ztensor_a, data1);
  assert(status == ZDNN_OK);
  status = zdnn_transform_ztensor(&amp;ztensor_b, data2);
  assert(status == ZDNN_OK);

  // perform element-wise add between the two input tensors
  status = zdnn_add(&amp;ztensor_a, &amp;ztensor_b, &amp;ztensor_out);
  assert(status == ZDNN_OK);

  // transform resultant zTensor back to original data format
  status = zdnn_transform_origtensor(&amp;ztensor_out, data_out);
  assert(status == ZDNN_OK);

  for (uint64_t i = 0; i &lt; num_elements; i++) {
    printf(&quot;out element %&quot; PRIu64 &quot; %f\n&quot;, i, ((float *)data_out)[i]);
  }

  free(data1);
  free(data2);
  free(data_out);
}
</code></pre></div>
<hr />
<h3 id="example-of-an-application-calling-the-zdnn_lstm-api-forward">Example of an application calling the zdnn_lstm API (forward)<a class="headerlink" href="#example-of-an-application-calling-the-zdnn_lstm-api-forward" title="Permanent link">&para;</a></h3>
<p><a href="#TOC">Back to Table of Contents</a></p>
<div class="highlight"><pre><span></span><code>// SPDX-License-Identifier: Apache-2.0
/*
 * Copyright IBM Corp. 2021
 * 
 * Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 * 
 *     http://www.apache.org/licenses/LICENSE-2.0
 * 
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#include &lt;assert.h&gt;
#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;string.h&gt;

#include &quot;zdnn.h&quot;

// Sample: LSTM
int main(int argc, char *argv[]) {
  zdnn_status status;

#ifdef STATIC_LIB
  zdnn_init();
#endif

  /***********************************************************************
   *
   * LSTM (FWD/BWD):
   *
   * INPUTS --------------------------------------------------------------
   * input           |  ZDNN_3DS  | (num_timesteps, num_batches, num_features)
   * h0              |  ZDNN_3DS  | (1, num_batches, num_hidden)
   * c0              |  ZDNN_3DS  | (1, num_batches, num_hidden)
   * weights         |  ZDNN_3DS  | (1, num_features, num_hidden)
   * biases          |  ZDNN_2DS  | (1, num_hidden)
   * hidden_weights  |  ZDNN_3DS  | (1, num_hidden, num_hidden)
   * hidden_biases   |  ZDNN_2DS  | (1, num_hidden)
   *
   * OUTPUTS -------------------------------------------------------------
   * hn_output       |  ZDNN_4DS  | (num_timesteps, 1, num_batches, num_hidden)
   *                 |            | or (1, 1, num_batches, num_hidden)
   * cf_output       |  ZDNN_4DS  | (1, 1, num_batches, num_hidden)
   ***********************************************************************/

  /***********************************************************************
   * Create input zTensor
   ***********************************************************************/

  zdnn_tensor_desc input_pre_tfrmd_desc, input_tfrmd_desc;
  zdnn_ztensor input;

  uint32_t num_timesteps = 5;
  uint32_t num_batches = 3;
  uint32_t num_features = 32;
  uint32_t num_hidden = 5;

  zdnn_data_types type = FP32;
  short element_size = 4; // size of each element in bytes

  lstm_gru_direction dir = FWD;
  uint8_t num_dirs = 1;

  zdnn_init_pre_transformed_desc(ZDNN_3DS, type, &amp;input_pre_tfrmd_desc,
                                 num_timesteps, num_batches, num_features);
  status =
      zdnn_generate_transformed_desc(&amp;input_pre_tfrmd_desc, &amp;input_tfrmd_desc);
  assert(status == ZDNN_OK);
  status = zdnn_init_ztensor_with_malloc(&amp;input_pre_tfrmd_desc,
                                         &amp;input_tfrmd_desc, &amp;input);
  assert(status == ZDNN_OK);

  uint64_t input_data_size =
      num_timesteps * num_batches * num_features * element_size;
  void *input_data = malloc(input_data_size);

  status = zdnn_transform_ztensor(&amp;input, input_data);
  assert(status == ZDNN_OK);

  /***********************************************************************
   * Create initial hidden and cell state zTensors
   ***********************************************************************/

  zdnn_tensor_desc h0c0_pre_tfrmd_desc, h0c0_tfrmd_desc;
  zdnn_ztensor h0, c0;

  zdnn_init_pre_transformed_desc(ZDNN_3DS, type, &amp;h0c0_pre_tfrmd_desc, num_dirs,
                                 num_batches, num_hidden);
  status =
      zdnn_generate_transformed_desc(&amp;h0c0_pre_tfrmd_desc, &amp;h0c0_tfrmd_desc);
  assert(status == ZDNN_OK);

  status = zdnn_init_ztensor_with_malloc(&amp;h0c0_pre_tfrmd_desc, &amp;h0c0_tfrmd_desc,
                                         &amp;h0);
  assert(status == ZDNN_OK);
  status = zdnn_init_ztensor_with_malloc(&amp;h0c0_pre_tfrmd_desc, &amp;h0c0_tfrmd_desc,
                                         &amp;c0);
  assert(status == ZDNN_OK);

  uint64_t h0c0_data_size = num_batches * num_hidden * element_size;
  void *hidden_state_data = malloc(h0c0_data_size);
  void *cell_state_data = malloc(h0c0_data_size);

  status = zdnn_transform_ztensor(&amp;h0, hidden_state_data);
  assert(status == ZDNN_OK);
  status = zdnn_transform_ztensor(&amp;c0, cell_state_data);
  assert(status == ZDNN_OK);

  /***********************************************************************
   * Create input weights zTensor
   * Resultant zTensor is concatenated
   ***********************************************************************/

  zdnn_tensor_desc weights_pre_tfrmd_desc, weights_tfrmd_desc;
  zdnn_ztensor weights;

  zdnn_init_pre_transformed_desc(ZDNN_3DS, type, &amp;weights_pre_tfrmd_desc,
                                 num_dirs, num_features, num_hidden);
  status = zdnn_generate_transformed_desc_concatenated(
      &amp;weights_pre_tfrmd_desc, RNN_TYPE_LSTM | USAGE_WEIGHTS | PREV_LAYER_NONE,
      &amp;weights_tfrmd_desc);
  assert(status == ZDNN_OK);

  status = zdnn_init_ztensor_with_malloc(&amp;weights_pre_tfrmd_desc,
                                         &amp;weights_tfrmd_desc, &amp;weights);
  assert(status == ZDNN_OK);

  uint64_t weights_data_size = num_features * num_hidden * element_size;
  void *weights_data_f = malloc(weights_data_size);
  void *weights_data_i = malloc(weights_data_size);
  void *weights_data_c = malloc(weights_data_size);
  void *weights_data_o = malloc(weights_data_size);

  status = zdnn_transform_ztensor(&amp;weights, weights_data_f, weights_data_i,
                                  weights_data_c, weights_data_o);
  assert(status == ZDNN_OK);

  /***********************************************************************
   * Create biases zTensors
   * Resultant zTensors are concatenated
   ***********************************************************************/

  zdnn_tensor_desc biases_pre_tfrmd_desc, biases_tfrmd_desc;
  zdnn_ztensor biases;

  zdnn_init_pre_transformed_desc(ZDNN_2DS, type, &amp;biases_pre_tfrmd_desc,
                                 num_dirs, num_hidden);
  status = zdnn_generate_transformed_desc_concatenated(
      &amp;biases_pre_tfrmd_desc, RNN_TYPE_LSTM | USAGE_BIASES | PREV_LAYER_NONE,
      &amp;biases_tfrmd_desc);
  assert(status == ZDNN_OK);

  status = zdnn_init_ztensor_with_malloc(&amp;biases_pre_tfrmd_desc,
                                         &amp;biases_tfrmd_desc, &amp;biases);
  assert(status == ZDNN_OK);

  uint64_t biases_data_size = num_hidden * element_size;
  void *biases_data_f = malloc(biases_data_size);
  void *biases_data_i = malloc(biases_data_size);
  void *biases_data_c = malloc(biases_data_size);
  void *biases_data_o = malloc(biases_data_size);

  status = zdnn_transform_ztensor(&amp;biases, biases_data_f, biases_data_i,
                                  biases_data_c, biases_data_o);
  assert(status == ZDNN_OK);

  /***********************************************************************
   * Create hidden weights zTensor
   * Resultant zTensor is concatenated
   ***********************************************************************/

  zdnn_tensor_desc hidden_weights_pre_tfrmd_desc, hidden_weights_tfrmd_desc;
  zdnn_ztensor hidden_weights;

  zdnn_init_pre_transformed_desc(ZDNN_3DS, type, &amp;hidden_weights_pre_tfrmd_desc,
                                 num_dirs, num_hidden, num_hidden);
  status = zdnn_generate_transformed_desc_concatenated(
      &amp;hidden_weights_pre_tfrmd_desc,
      RNN_TYPE_LSTM | USAGE_HIDDEN_WEIGHTS | PREV_LAYER_NONE,
      &amp;hidden_weights_tfrmd_desc);
  assert(status == ZDNN_OK);
  status = zdnn_init_ztensor_with_malloc(&amp;hidden_weights_pre_tfrmd_desc,
                                         &amp;hidden_weights_tfrmd_desc,
                                         &amp;hidden_weights);
  assert(status == ZDNN_OK);

  uint64_t hidden_weights_data_size = num_hidden * num_hidden * element_size;
  void *hidden_weights_data_f = malloc(hidden_weights_data_size);
  void *hidden_weights_data_i = malloc(hidden_weights_data_size);
  void *hidden_weights_data_c = malloc(hidden_weights_data_size);
  void *hidden_weights_data_o = malloc(hidden_weights_data_size);

  status = zdnn_transform_ztensor(&amp;hidden_weights, hidden_weights_data_f,
                                  hidden_weights_data_i, hidden_weights_data_c,
                                  hidden_weights_data_o);
  assert(status == ZDNN_OK);

  /***********************************************************************
   * Create hidden biases zTensors
   * Resultant zTensors are concatenated
   ***********************************************************************/

  zdnn_tensor_desc hidden_biases_pre_tfrmd_desc, hidden_biases_tfrmd_desc;
  zdnn_ztensor hidden_biases;

  zdnn_init_pre_transformed_desc(ZDNN_2DS, type, &amp;hidden_biases_pre_tfrmd_desc,
                                 num_dirs, num_hidden);
  status = zdnn_generate_transformed_desc_concatenated(
      &amp;hidden_biases_pre_tfrmd_desc,
      RNN_TYPE_LSTM | USAGE_HIDDEN_BIASES | PREV_LAYER_NONE,
      &amp;hidden_biases_tfrmd_desc);
  assert(status == ZDNN_OK);

  status = zdnn_init_ztensor_with_malloc(
      &amp;hidden_biases_pre_tfrmd_desc, &amp;hidden_biases_tfrmd_desc, &amp;hidden_biases);
  assert(status == ZDNN_OK);

  uint64_t hidden_biases_data_size = num_hidden * element_size;

  void *hidden_biases_data_f = malloc(hidden_biases_data_size);
  void *hidden_biases_data_i = malloc(hidden_biases_data_size);
  void *hidden_biases_data_c = malloc(hidden_biases_data_size);
  void *hidden_biases_data_o = malloc(hidden_biases_data_size);

  status = zdnn_transform_ztensor(&amp;hidden_biases, hidden_biases_data_f,
                                  hidden_biases_data_i, hidden_biases_data_c,
                                  hidden_biases_data_o);
  assert(status == ZDNN_OK);

  /***********************************************************************
   * Create output zTensor
   ***********************************************************************/

  // get only the last timestep, thus hn and cf can share descriptor
  zdnn_tensor_desc hncf_pre_tfrmd_desc, hncf_tfrmd_desc;

  zdnn_ztensor hn_output_ztensor, cf_output_ztensor;

  zdnn_init_pre_transformed_desc(ZDNN_4DS, type, &amp;hncf_pre_tfrmd_desc, 1, 1,
                                 num_batches, num_hidden);
  status =
      zdnn_generate_transformed_desc(&amp;hncf_pre_tfrmd_desc, &amp;hncf_tfrmd_desc);
  assert(status == ZDNN_OK);

  status = zdnn_init_ztensor_with_malloc(&amp;hncf_pre_tfrmd_desc, &amp;hncf_tfrmd_desc,
                                         &amp;hn_output_ztensor);
  assert(status == ZDNN_OK);
  status = zdnn_init_ztensor_with_malloc(&amp;hncf_pre_tfrmd_desc, &amp;hncf_tfrmd_desc,
                                         &amp;cf_output_ztensor);
  assert(status == ZDNN_OK);

  /***********************************************************************
   * Call the AIU
   ***********************************************************************/

  void *work_area = NULL;

  status = zdnn_lstm(&amp;input, &amp;h0, &amp;c0, &amp;weights, &amp;biases, &amp;hidden_weights,
                     &amp;hidden_biases, dir, work_area, &amp;hn_output_ztensor,
                     &amp;cf_output_ztensor);
  assert(status == ZDNN_OK);

  /***********************************************************************
   * Output and Cleanup
   ***********************************************************************/

  uint64_t hncf_data_size = num_batches * num_hidden * element_size;
  void *hn_output_data = malloc(hncf_data_size);
  void *cf_output_data = malloc(hncf_data_size);

  status = zdnn_transform_origtensor(&amp;hn_output_ztensor, hn_output_data);
  assert(status == ZDNN_OK);
  status = zdnn_transform_origtensor(&amp;cf_output_ztensor, cf_output_data);
  assert(status == ZDNN_OK);

  status = zdnn_free_ztensor_buffer(&amp;input);
  assert(status == ZDNN_OK);
  status = zdnn_free_ztensor_buffer(&amp;h0);
  assert(status == ZDNN_OK);
  status = zdnn_free_ztensor_buffer(&amp;c0);
  assert(status == ZDNN_OK);
  status = zdnn_free_ztensor_buffer(&amp;weights);
  assert(status == ZDNN_OK);
  status = zdnn_free_ztensor_buffer(&amp;biases);
  assert(status == ZDNN_OK);
  status = zdnn_free_ztensor_buffer(&amp;hidden_weights);
  assert(status == ZDNN_OK);
  status = zdnn_free_ztensor_buffer(&amp;hidden_biases);
  assert(status == ZDNN_OK);
  status = zdnn_free_ztensor_buffer(&amp;hn_output_ztensor);
  assert(status == ZDNN_OK);
  status = zdnn_free_ztensor_buffer(&amp;cf_output_ztensor);
  assert(status == ZDNN_OK);

  free(input_data);
  free(hidden_state_data);
  free(cell_state_data);
  free(weights_data_f);
  free(weights_data_i);
  free(weights_data_c);
  free(weights_data_o);
  free(hidden_weights_data_f);
  free(hidden_weights_data_i);
  free(hidden_weights_data_c);
  free(hidden_weights_data_o);
  free(biases_data_f);
  free(biases_data_i);
  free(biases_data_c);
  free(biases_data_o);
  free(hidden_biases_data_f);
  free(hidden_biases_data_i);
  free(hidden_biases_data_c);
  free(hidden_biases_data_o);
  free(hn_output_data);
  free(cf_output_data);
}
</code></pre></div>
<hr />
<h3 id="example-of-an-application-calling-the-zdnn_lstm-api-bi-directional">Example of an application calling the zdnn_lstm API (bi-directional)<a class="headerlink" href="#example-of-an-application-calling-the-zdnn_lstm-api-bi-directional" title="Permanent link">&para;</a></h3>
<p><a href="#TOC">Back to Table of Contents</a></p>
<div class="highlight"><pre><span></span><code>// SPDX-License-Identifier: Apache-2.0
/*
 * Copyright IBM Corp. 2021
 * 
 * Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 * 
 *     http://www.apache.org/licenses/LICENSE-2.0
 * 
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#include &lt;assert.h&gt;
#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;string.h&gt;

#include &quot;zdnn.h&quot;

// Sample: LSTM BI-DIR
int main(int argc, char *argv[]) {
  zdnn_status status;

#ifdef STATIC_LIB
  zdnn_init();
#endif

  /***********************************************************************
   *
   * LSTM (BI-DIR):
   *
   * INPUTS --------------------------------------------------------------
   * input           |  ZDNN_3DS  | (num_timesteps, num_batches, num_features)
   * h0              |  ZDNN_3DS  | (2, num_batches, num_hidden)
   * c0              |  ZDNN_3DS  | (2, num_batches, num_hidden)
   * weights         |  ZDNN_3DS  | (2, num_features, num_hidden)
   * biases          |  ZDNN_2DS  | (2, num_hidden)
   * hidden_weights  |  ZDNN_3DS  | (2, num_hidden, num_hidden)
   * hidden_biases   |  ZDNN_2DS  | (2, num_hidden)
   *
   * OUTPUTS -------------------------------------------------------------
   * hn_output       |  ZDNN_4DS  | (num_timesteps, 2, num_batches, num_hidden)
   *                 |            | or (1, 2, num_batches, num_hidden)
   * cf_output       |  ZDNN_4DS  | (1, 2, num_batches, num_hidden)
   ***********************************************************************/

  /***********************************************************************
   * Create input zTensor
   ***********************************************************************/

  zdnn_tensor_desc input_pre_tfrmd_desc, input_tfrmd_desc;
  zdnn_ztensor input;

  uint32_t num_timesteps = 5;
  uint32_t num_batches = 3;
  uint32_t num_features = 32;
  uint32_t num_hidden = 5;

  zdnn_data_types type = FP32;
  short element_size = 4; // size of each element in bytes

  lstm_gru_direction dir = BIDIR;
  uint8_t num_dirs = 2;

  zdnn_init_pre_transformed_desc(ZDNN_3DS, type, &amp;input_pre_tfrmd_desc,
                                 num_timesteps, num_batches, num_features);
  status =
      zdnn_generate_transformed_desc(&amp;input_pre_tfrmd_desc, &amp;input_tfrmd_desc);
  assert(status == ZDNN_OK);
  status = zdnn_init_ztensor_with_malloc(&amp;input_pre_tfrmd_desc,
                                         &amp;input_tfrmd_desc, &amp;input);
  assert(status == ZDNN_OK);

  uint64_t input_data_size =
      num_timesteps * num_batches * num_features * element_size;
  void *input_data = malloc(input_data_size);

  status = zdnn_transform_ztensor(&amp;input, input_data);
  assert(status == ZDNN_OK);

  /***********************************************************************
   * Create initial hidden and cell state zTensors
   ***********************************************************************/

  zdnn_tensor_desc h0c0_pre_tfrmd_desc, h0c0_tfrmd_desc;
  zdnn_ztensor h0, c0;

  zdnn_init_pre_transformed_desc(ZDNN_3DS, type, &amp;h0c0_pre_tfrmd_desc, num_dirs,
                                 num_batches, num_hidden);
  status =
      zdnn_generate_transformed_desc(&amp;h0c0_pre_tfrmd_desc, &amp;h0c0_tfrmd_desc);
  assert(status == ZDNN_OK);

  status = zdnn_init_ztensor_with_malloc(&amp;h0c0_pre_tfrmd_desc, &amp;h0c0_tfrmd_desc,
                                         &amp;h0);
  assert(status == ZDNN_OK);
  status = zdnn_init_ztensor_with_malloc(&amp;h0c0_pre_tfrmd_desc, &amp;h0c0_tfrmd_desc,
                                         &amp;c0);
  assert(status == ZDNN_OK);

  uint64_t h0c0_data_size = num_batches * num_hidden * element_size;
  void *hidden_state_data = malloc(h0c0_data_size);
  void *cell_state_data = malloc(h0c0_data_size);

  status = zdnn_transform_ztensor(&amp;h0, hidden_state_data);
  assert(status == ZDNN_OK);
  status = zdnn_transform_ztensor(&amp;c0, cell_state_data);
  assert(status == ZDNN_OK);

  /***********************************************************************
   * Create input weights zTensor
   * Resultant zTensor is concatenated
   ***********************************************************************/

  zdnn_tensor_desc weights_pre_tfrmd_desc, weights_tfrmd_desc;
  zdnn_ztensor weights;

  zdnn_init_pre_transformed_desc(ZDNN_3DS, type, &amp;weights_pre_tfrmd_desc,
                                 num_dirs, num_features, num_hidden);
  status = zdnn_generate_transformed_desc_concatenated(
      &amp;weights_pre_tfrmd_desc, RNN_TYPE_LSTM | USAGE_WEIGHTS | PREV_LAYER_NONE,
      &amp;weights_tfrmd_desc);
  assert(status == ZDNN_OK);

  status = zdnn_init_ztensor_with_malloc(&amp;weights_pre_tfrmd_desc,
                                         &amp;weights_tfrmd_desc, &amp;weights);
  assert(status == ZDNN_OK);

  uint64_t weights_data_size = num_features * num_hidden * element_size;
  void *weights_data_f = malloc(weights_data_size);
  void *weights_data_i = malloc(weights_data_size);
  void *weights_data_c = malloc(weights_data_size);
  void *weights_data_o = malloc(weights_data_size);

  status = zdnn_transform_ztensor(&amp;weights, weights_data_f, weights_data_i,
                                  weights_data_c, weights_data_o);
  assert(status == ZDNN_OK);

  /***********************************************************************
   * Create biases zTensors
   * Resultant zTensors are concatenated
   ***********************************************************************/

  zdnn_tensor_desc biases_pre_tfrmd_desc, biases_tfrmd_desc;
  zdnn_ztensor biases;

  zdnn_init_pre_transformed_desc(ZDNN_2DS, type, &amp;biases_pre_tfrmd_desc,
                                 num_dirs, num_hidden);
  status = zdnn_generate_transformed_desc_concatenated(
      &amp;biases_pre_tfrmd_desc, RNN_TYPE_LSTM | USAGE_BIASES | PREV_LAYER_NONE,
      &amp;biases_tfrmd_desc);
  assert(status == ZDNN_OK);

  status = zdnn_init_ztensor_with_malloc(&amp;biases_pre_tfrmd_desc,
                                         &amp;biases_tfrmd_desc, &amp;biases);
  assert(status == ZDNN_OK);

  uint64_t biases_data_size = num_hidden * element_size;
  void *biases_data_f = malloc(biases_data_size);
  void *biases_data_i = malloc(biases_data_size);
  void *biases_data_c = malloc(biases_data_size);
  void *biases_data_o = malloc(biases_data_size);

  status = zdnn_transform_ztensor(&amp;biases, biases_data_f, biases_data_i,
                                  biases_data_c, biases_data_o);
  assert(status == ZDNN_OK);

  /***********************************************************************
   * Create hidden weights zTensor
   * Resultant zTensor is concatenated
   ***********************************************************************/

  zdnn_tensor_desc hidden_weights_pre_tfrmd_desc, hidden_weights_tfrmd_desc;
  zdnn_ztensor hidden_weights;

  zdnn_init_pre_transformed_desc(ZDNN_3DS, type, &amp;hidden_weights_pre_tfrmd_desc,
                                 num_dirs, num_hidden, num_hidden);
  status = zdnn_generate_transformed_desc_concatenated(
      &amp;hidden_weights_pre_tfrmd_desc,
      RNN_TYPE_LSTM | USAGE_HIDDEN_WEIGHTS | PREV_LAYER_NONE,
      &amp;hidden_weights_tfrmd_desc);
  assert(status == ZDNN_OK);
  status = zdnn_init_ztensor_with_malloc(&amp;hidden_weights_pre_tfrmd_desc,
                                         &amp;hidden_weights_tfrmd_desc,
                                         &amp;hidden_weights);
  assert(status == ZDNN_OK);

  uint64_t hidden_weights_data_size = num_hidden * num_hidden * element_size;
  void *hidden_weights_data_f = malloc(hidden_weights_data_size);
  void *hidden_weights_data_i = malloc(hidden_weights_data_size);
  void *hidden_weights_data_c = malloc(hidden_weights_data_size);
  void *hidden_weights_data_o = malloc(hidden_weights_data_size);

  status = zdnn_transform_ztensor(&amp;hidden_weights, hidden_weights_data_f,
                                  hidden_weights_data_i, hidden_weights_data_c,
                                  hidden_weights_data_o);
  assert(status == ZDNN_OK);

  /***********************************************************************
   * Create hidden biases zTensors
   * Resultant zTensors are concatenated
   ***********************************************************************/

  zdnn_tensor_desc hidden_biases_pre_tfrmd_desc, hidden_biases_tfrmd_desc;
  zdnn_ztensor hidden_biases;

  zdnn_init_pre_transformed_desc(ZDNN_2DS, type, &amp;hidden_biases_pre_tfrmd_desc,
                                 num_dirs, num_hidden);
  status = zdnn_generate_transformed_desc_concatenated(
      &amp;hidden_biases_pre_tfrmd_desc,
      RNN_TYPE_LSTM | USAGE_HIDDEN_BIASES | PREV_LAYER_NONE,
      &amp;hidden_biases_tfrmd_desc);
  assert(status == ZDNN_OK);

  status = zdnn_init_ztensor_with_malloc(
      &amp;hidden_biases_pre_tfrmd_desc, &amp;hidden_biases_tfrmd_desc, &amp;hidden_biases);
  assert(status == ZDNN_OK);

  uint64_t hidden_biases_data_size = num_hidden * element_size;

  void *hidden_biases_data_f = malloc(hidden_biases_data_size);
  void *hidden_biases_data_i = malloc(hidden_biases_data_size);
  void *hidden_biases_data_c = malloc(hidden_biases_data_size);
  void *hidden_biases_data_o = malloc(hidden_biases_data_size);

  status = zdnn_transform_ztensor(&amp;hidden_biases, hidden_biases_data_f,
                                  hidden_biases_data_i, hidden_biases_data_c,
                                  hidden_biases_data_o);
  assert(status == ZDNN_OK);

  /***********************************************************************
   * Create output zTensor
   ***********************************************************************/

  zdnn_tensor_desc hn_pre_tfrmd_desc, hn_tfrmd_desc, cf_pre_tfrmd_desc,
      cf_tfrmd_desc;

  zdnn_ztensor hn_output_ztensor, cf_output_ztensor;

  zdnn_init_pre_transformed_desc(ZDNN_4DS, type, &amp;hn_pre_tfrmd_desc,
                                 num_timesteps, 2, num_batches, num_hidden);
  status = zdnn_generate_transformed_desc(&amp;hn_pre_tfrmd_desc, &amp;hn_tfrmd_desc);
  assert(status == ZDNN_OK);

  zdnn_init_pre_transformed_desc(ZDNN_3DS, type, &amp;cf_pre_tfrmd_desc, 1, 2,
                                 num_batches, num_hidden);
  status = zdnn_generate_transformed_desc(&amp;cf_pre_tfrmd_desc, &amp;cf_tfrmd_desc);
  assert(status == ZDNN_OK);

  status = zdnn_init_ztensor_with_malloc(&amp;hn_pre_tfrmd_desc, &amp;hn_tfrmd_desc,
                                         &amp;hn_output_ztensor);
  assert(status == ZDNN_OK);
  status = zdnn_init_ztensor_with_malloc(&amp;cf_pre_tfrmd_desc, &amp;cf_tfrmd_desc,
                                         &amp;cf_output_ztensor);
  assert(status == ZDNN_OK);

  /***********************************************************************
   * Call the AIU
   ***********************************************************************/

  void *work_area = NULL;

  status = zdnn_lstm(&amp;input, &amp;h0, &amp;c0, &amp;weights, &amp;biases, &amp;hidden_weights,
                     &amp;hidden_biases, dir, work_area, &amp;hn_output_ztensor,
                     &amp;cf_output_ztensor);
  assert(status == ZDNN_OK);

  /***********************************************************************
   * Output and Cleanup
   ***********************************************************************/

  uint64_t hn_data_size =
      num_timesteps * 2 * num_batches * num_hidden * element_size;
  uint64_t cf_data_size = 2 * num_batches * num_hidden * element_size;
  void *hn_output_data = malloc(hn_data_size);
  void *cf_output_data = malloc(cf_data_size);

  status = zdnn_transform_origtensor(&amp;hn_output_ztensor, hn_output_data);
  assert(status == ZDNN_OK);
  status = zdnn_transform_origtensor(&amp;cf_output_ztensor, cf_output_data);
  assert(status == ZDNN_OK);

  status = zdnn_free_ztensor_buffer(&amp;input);
  assert(status == ZDNN_OK);
  status = zdnn_free_ztensor_buffer(&amp;h0);
  assert(status == ZDNN_OK);
  status = zdnn_free_ztensor_buffer(&amp;c0);
  assert(status == ZDNN_OK);
  status = zdnn_free_ztensor_buffer(&amp;weights);
  assert(status == ZDNN_OK);
  status = zdnn_free_ztensor_buffer(&amp;biases);
  assert(status == ZDNN_OK);
  status = zdnn_free_ztensor_buffer(&amp;hidden_weights);
  assert(status == ZDNN_OK);
  status = zdnn_free_ztensor_buffer(&amp;hidden_biases);
  assert(status == ZDNN_OK);
  status = zdnn_free_ztensor_buffer(&amp;hn_output_ztensor);
  assert(status == ZDNN_OK);
  status = zdnn_free_ztensor_buffer(&amp;cf_output_ztensor);
  assert(status == ZDNN_OK);

  free(input_data);
  free(hidden_state_data);
  free(cell_state_data);
  free(weights_data_f);
  free(weights_data_i);
  free(weights_data_c);
  free(weights_data_o);
  free(hidden_weights_data_f);
  free(hidden_weights_data_i);
  free(hidden_weights_data_c);
  free(hidden_weights_data_o);
  free(biases_data_f);
  free(biases_data_i);
  free(biases_data_c);
  free(biases_data_o);
  free(hidden_biases_data_f);
  free(hidden_biases_data_i);
  free(hidden_biases_data_c);
  free(hidden_biases_data_o);
  free(hn_output_data);
  free(cf_output_data);
}
</code></pre></div>
<hr />
<h3 id="example-of-an-application-calling-the-zdnn_lstm-api-multi-layer-bi-directional">Example of an application calling the zdnn_lstm API (multi-layer bi-directional)<a class="headerlink" href="#example-of-an-application-calling-the-zdnn_lstm-api-multi-layer-bi-directional" title="Permanent link">&para;</a></h3>
<p><a href="#TOC">Back to Table of Contents</a></p>
<div class="highlight"><pre><span></span><code>// SPDX-License-Identifier: Apache-2.0
/*
 * Copyright IBM Corp. 2021
 * 
 * Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 * 
 *     http://www.apache.org/licenses/LICENSE-2.0
 * 
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#include &lt;assert.h&gt;
#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;string.h&gt;

#include &quot;zdnn.h&quot;

void do_bidir_layer(zdnn_ztensor *input, uint32_t num_hidden,
                    zdnn_ztensor *hn_output, bool is_prev_layer_bidir) {

  zdnn_status status;

  uint32_t num_batches = input-&gt;pre_transformed_desc-&gt;dim2;

  // if input is bidir output from previous layer then number of features for
  // this layer is 2x of hidden-state size (dim1) of the previous layer
  uint32_t num_features =
      input-&gt;pre_transformed_desc-&gt;dim1 * (is_prev_layer_bidir ? 2 : 1);

  zdnn_data_types type = FP32;
  short element_size = 4; // size of each element in bytes

  lstm_gru_direction dir = BIDIR;
  uint8_t num_dirs = 2;

  /***********************************************************************
   * Create initial hidden and cell state zTensors
   ***********************************************************************/

  zdnn_tensor_desc h0c0_pre_tfrmd_desc, h0c0_tfrmd_desc;
  zdnn_ztensor h0, c0;

  zdnn_init_pre_transformed_desc(ZDNN_3DS, type, &amp;h0c0_pre_tfrmd_desc, num_dirs,
                                 num_batches, num_hidden);
  status =
      zdnn_generate_transformed_desc(&amp;h0c0_pre_tfrmd_desc, &amp;h0c0_tfrmd_desc);
  assert(status == ZDNN_OK);

  status = zdnn_init_ztensor_with_malloc(&amp;h0c0_pre_tfrmd_desc, &amp;h0c0_tfrmd_desc,
                                         &amp;h0);
  assert(status == ZDNN_OK);
  status = zdnn_init_ztensor_with_malloc(&amp;h0c0_pre_tfrmd_desc, &amp;h0c0_tfrmd_desc,
                                         &amp;c0);
  assert(status == ZDNN_OK);

  uint64_t h0c0_data_size = num_batches * num_hidden * element_size;
  void *hidden_state_data = malloc(h0c0_data_size);
  void *cell_state_data = malloc(h0c0_data_size);

  status = zdnn_transform_ztensor(&amp;h0, hidden_state_data);
  assert(status == ZDNN_OK);
  status = zdnn_transform_ztensor(&amp;c0, cell_state_data);
  assert(status == ZDNN_OK);

  /***********************************************************************
   * Create input weights zTensor
   * Resultant zTensor is concatenated
   ***********************************************************************/

  zdnn_tensor_desc weights_pre_tfrmd_desc, weights_tfrmd_desc;
  zdnn_ztensor weights;

  // if using previous layer bidir output as input then number of features of
  // this layer is
  zdnn_init_pre_transformed_desc(ZDNN_3DS, type, &amp;weights_pre_tfrmd_desc,
                                 num_dirs, num_features, num_hidden);
  status = zdnn_generate_transformed_desc_concatenated(
      &amp;weights_pre_tfrmd_desc,
      RNN_TYPE_LSTM | USAGE_WEIGHTS |
          (is_prev_layer_bidir ? PREV_LAYER_BIDIR : PREV_LAYER_UNI),
      &amp;weights_tfrmd_desc);
  assert(status == ZDNN_OK);

  status = zdnn_init_ztensor_with_malloc(&amp;weights_pre_tfrmd_desc,
                                         &amp;weights_tfrmd_desc, &amp;weights);
  assert(status == ZDNN_OK);

  uint64_t weights_data_size = num_features * num_hidden * element_size;
  void *weights_data_f = malloc(weights_data_size);
  void *weights_data_i = malloc(weights_data_size);
  void *weights_data_c = malloc(weights_data_size);
  void *weights_data_o = malloc(weights_data_size);

  status = zdnn_transform_ztensor(&amp;weights, weights_data_f, weights_data_i,
                                  weights_data_c, weights_data_o);
  assert(status == ZDNN_OK);

  /***********************************************************************
   * Create biases zTensors
   * Resultant zTensors are concatenated
   ***********************************************************************/

  zdnn_tensor_desc biases_pre_tfrmd_desc, biases_tfrmd_desc;
  zdnn_ztensor biases;

  zdnn_init_pre_transformed_desc(ZDNN_2DS, type, &amp;biases_pre_tfrmd_desc,
                                 num_dirs, num_hidden);
  status = zdnn_generate_transformed_desc_concatenated(
      &amp;biases_pre_tfrmd_desc,
      RNN_TYPE_LSTM | USAGE_BIASES |
          (is_prev_layer_bidir ? PREV_LAYER_BIDIR : PREV_LAYER_UNI),
      &amp;biases_tfrmd_desc);
  assert(status == ZDNN_OK);

  status = zdnn_init_ztensor_with_malloc(&amp;biases_pre_tfrmd_desc,
                                         &amp;biases_tfrmd_desc, &amp;biases);
  assert(status == ZDNN_OK);

  uint64_t biases_data_size = num_hidden * element_size;
  void *biases_data_f = malloc(biases_data_size);
  void *biases_data_i = malloc(biases_data_size);
  void *biases_data_c = malloc(biases_data_size);
  void *biases_data_o = malloc(biases_data_size);

  status = zdnn_transform_ztensor(&amp;biases, biases_data_f, biases_data_i,
                                  biases_data_c, biases_data_o);
  assert(status == ZDNN_OK);

  /***********************************************************************
   * Create hidden weights zTensor
   * Resultant zTensor is concatenated
   ***********************************************************************/

  zdnn_tensor_desc hidden_weights_pre_tfrmd_desc, hidden_weights_tfrmd_desc;
  zdnn_ztensor hidden_weights;

  zdnn_init_pre_transformed_desc(ZDNN_3DS, type, &amp;hidden_weights_pre_tfrmd_desc,
                                 num_dirs, num_hidden, num_hidden);
  status = zdnn_generate_transformed_desc_concatenated(
      &amp;hidden_weights_pre_tfrmd_desc,
      RNN_TYPE_LSTM | USAGE_HIDDEN_WEIGHTS |
          (is_prev_layer_bidir ? PREV_LAYER_BIDIR : PREV_LAYER_UNI),
      &amp;hidden_weights_tfrmd_desc);
  assert(status == ZDNN_OK);
  status = zdnn_init_ztensor_with_malloc(&amp;hidden_weights_pre_tfrmd_desc,
                                         &amp;hidden_weights_tfrmd_desc,
                                         &amp;hidden_weights);
  assert(status == ZDNN_OK);

  uint64_t hidden_weights_data_size = num_hidden * num_hidden * element_size;
  void *hidden_weights_data_f = malloc(hidden_weights_data_size);
  void *hidden_weights_data_i = malloc(hidden_weights_data_size);
  void *hidden_weights_data_c = malloc(hidden_weights_data_size);
  void *hidden_weights_data_o = malloc(hidden_weights_data_size);

  status = zdnn_transform_ztensor(&amp;hidden_weights, hidden_weights_data_f,
                                  hidden_weights_data_i, hidden_weights_data_c,
                                  hidden_weights_data_o);
  assert(status == ZDNN_OK);

  /***********************************************************************
   * Create hidden biases zTensors
   * Resultant zTensors are concatenated
   ***********************************************************************/

  zdnn_tensor_desc hidden_biases_pre_tfrmd_desc, hidden_biases_tfrmd_desc;
  zdnn_ztensor hidden_biases;

  zdnn_init_pre_transformed_desc(ZDNN_2DS, type, &amp;hidden_biases_pre_tfrmd_desc,
                                 num_dirs, num_hidden);
  status = zdnn_generate_transformed_desc_concatenated(
      &amp;hidden_biases_pre_tfrmd_desc,
      RNN_TYPE_LSTM | USAGE_HIDDEN_BIASES |
          (is_prev_layer_bidir ? PREV_LAYER_BIDIR : PREV_LAYER_UNI),
      &amp;hidden_biases_tfrmd_desc);
  assert(status == ZDNN_OK);

  status = zdnn_init_ztensor_with_malloc(
      &amp;hidden_biases_pre_tfrmd_desc, &amp;hidden_biases_tfrmd_desc, &amp;hidden_biases);
  assert(status == ZDNN_OK);

  uint64_t hidden_biases_data_size = num_hidden * element_size;

  void *hidden_biases_data_f = malloc(hidden_biases_data_size);
  void *hidden_biases_data_i = malloc(hidden_biases_data_size);
  void *hidden_biases_data_c = malloc(hidden_biases_data_size);
  void *hidden_biases_data_o = malloc(hidden_biases_data_size);

  status = zdnn_transform_ztensor(&amp;hidden_biases, hidden_biases_data_f,
                                  hidden_biases_data_i, hidden_biases_data_c,
                                  hidden_biases_data_o);
  assert(status == ZDNN_OK);

  /***********************************************************************
   * Create cf output zTensor
   ***********************************************************************/

  zdnn_tensor_desc cf_pre_tfrmd_desc, cf_tfrmd_desc;

  zdnn_ztensor cf_output_ztensor;

  zdnn_init_pre_transformed_desc(ZDNN_4DS, type, &amp;cf_pre_tfrmd_desc, 1, 2,
                                 num_batches, num_hidden);
  status = zdnn_generate_transformed_desc(&amp;cf_pre_tfrmd_desc, &amp;cf_tfrmd_desc);
  assert(status == ZDNN_OK);

  status = zdnn_init_ztensor_with_malloc(&amp;cf_pre_tfrmd_desc, &amp;cf_tfrmd_desc,
                                         &amp;cf_output_ztensor);
  assert(status == ZDNN_OK);

  /***********************************************************************
   * Call the AIU
   ***********************************************************************/

  void *work_area = NULL;

  status =
      zdnn_lstm(input, &amp;h0, &amp;c0, &amp;weights, &amp;biases, &amp;hidden_weights,
                &amp;hidden_biases, dir, work_area, hn_output, &amp;cf_output_ztensor);
  assert(status == ZDNN_OK);

  /***********************************************************************
   * Cleanup and Return
   ***********************************************************************/

  status = zdnn_free_ztensor_buffer(&amp;h0);
  assert(status == ZDNN_OK);
  status = zdnn_free_ztensor_buffer(&amp;c0);
  assert(status == ZDNN_OK);
  status = zdnn_free_ztensor_buffer(&amp;weights);
  assert(status == ZDNN_OK);
  status = zdnn_free_ztensor_buffer(&amp;biases);
  assert(status == ZDNN_OK);
  status = zdnn_free_ztensor_buffer(&amp;hidden_weights);
  assert(status == ZDNN_OK);
  status = zdnn_free_ztensor_buffer(&amp;hidden_biases);
  assert(status == ZDNN_OK);
  status = zdnn_free_ztensor_buffer(&amp;cf_output_ztensor);
  assert(status == ZDNN_OK);

  free(hidden_state_data);
  free(cell_state_data);
  free(weights_data_f);
  free(weights_data_i);
  free(weights_data_c);
  free(weights_data_o);
  free(hidden_weights_data_f);
  free(hidden_weights_data_i);
  free(hidden_weights_data_c);
  free(hidden_weights_data_o);
  free(biases_data_f);
  free(biases_data_i);
  free(biases_data_c);
  free(biases_data_o);
  free(hidden_biases_data_f);
  free(hidden_biases_data_i);
  free(hidden_biases_data_c);
  free(hidden_biases_data_o);
}

// Sample: LSTM multi-layer BIDIR
int main(int argc, char *argv[]) {
  zdnn_status status;

#ifdef STATIC_LIB
  zdnn_init();
#endif

  uint32_t num_hidden[2] = {5, 4};

  /***********************************************************************
   * Create input zTensor
   ***********************************************************************/

  zdnn_tensor_desc input_pre_tfrmd_desc, input_tfrmd_desc;
  zdnn_ztensor input;

  uint32_t num_timesteps = 5;
  uint32_t num_batches = 3;
  uint32_t num_features = 32;

  zdnn_data_types type = FP32;
  short element_size = 4; // size of each element in bytes

  zdnn_init_pre_transformed_desc(ZDNN_3DS, type, &amp;input_pre_tfrmd_desc,
                                 num_timesteps, num_batches, num_features);
  status =
      zdnn_generate_transformed_desc(&amp;input_pre_tfrmd_desc, &amp;input_tfrmd_desc);
  assert(status == ZDNN_OK);
  status = zdnn_init_ztensor_with_malloc(&amp;input_pre_tfrmd_desc,
                                         &amp;input_tfrmd_desc, &amp;input);
  assert(status == ZDNN_OK);

  uint64_t input_data_size =
      num_timesteps * num_batches * num_features * element_size;
  void *input_data = malloc(input_data_size);

  status = zdnn_transform_ztensor(&amp;input, input_data);
  assert(status == ZDNN_OK);

  /***********************************************************************
   * Create 2 hn output zTensors
   ***********************************************************************/

  zdnn_tensor_desc hn_pre_tfrmd_desc[2], hn_tfrmd_desc[2];
  zdnn_ztensor hn_output[2];

  for (int i = 0; i &lt; 2; i++) {
    zdnn_init_pre_transformed_desc(ZDNN_4DS, type, &amp;hn_pre_tfrmd_desc[i],
                                   num_timesteps, 2, num_batches,
                                   num_hidden[i]);
    status = zdnn_generate_transformed_desc(&amp;hn_pre_tfrmd_desc[i],
                                            &amp;hn_tfrmd_desc[i]);
    assert(status == ZDNN_OK);

    status = zdnn_init_ztensor_with_malloc(&amp;hn_pre_tfrmd_desc[i],
                                           &amp;hn_tfrmd_desc[i], &amp;hn_output[i]);
    assert(status == ZDNN_OK);
  }

  /***********************************************************************
   * Do the layers
   ***********************************************************************/

  // call the first layer with input, previous layer bidir = false, output goes
  // to hn_output[0]
  do_bidir_layer(&amp;input, num_hidden[0], &amp;hn_output[0], false);

  // call the second layer with hn_output[0] from layer 1, previous layer bidir
  // = true, output goes to hn_output[1]
  do_bidir_layer(&amp;hn_output[0], num_hidden[1], &amp;hn_output[1], true);

  /***********************************************************************
   * Output and Cleanup
   ***********************************************************************/

  void *hn_output_data[2];

  for (int i = 0; i &lt; 2; i++) {
    uint64_t hn_output_data_size = (uint64_t)num_timesteps * num_batches *
                                   num_hidden[i] * 2 * element_size;
    hn_output_data[i] = malloc(hn_output_data_size);

    status = zdnn_transform_origtensor(&amp;hn_output[i], hn_output_data[i]);
    assert(status == ZDNN_OK);
  }

  status = zdnn_free_ztensor_buffer(&amp;input);
  assert(status == ZDNN_OK);
  status = zdnn_free_ztensor_buffer(&amp;hn_output[0]);
  assert(status == ZDNN_OK);
  status = zdnn_free_ztensor_buffer(&amp;hn_output[1]);
  assert(status == ZDNN_OK);

  free(input_data);
  free(hn_output_data[0]);
  free(hn_output_data[1]);
}
</code></pre></div>
<hr />
<h3 id="example-of-an-application-calling-the-zdnn_gru-api-forward">Example of an application calling the zdnn_gru API (forward)<a class="headerlink" href="#example-of-an-application-calling-the-zdnn_gru-api-forward" title="Permanent link">&para;</a></h3>
<p><a href="#TOC">Back to Table of Contents</a></p>
<div class="highlight"><pre><span></span><code>// SPDX-License-Identifier: Apache-2.0
/*
 * Copyright IBM Corp. 2021
 * 
 * Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 * 
 *     http://www.apache.org/licenses/LICENSE-2.0
 * 
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#include &lt;assert.h&gt;
#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;string.h&gt;

#include &quot;zdnn.h&quot;

// Sample: GRU
int main(int argc, char *argv[]) {
  zdnn_status status;

#ifdef STATIC_LIB
  zdnn_init();
#endif

  /***********************************************************************
   *
   * GRU (FWD/BWD):
   *
   * INPUTS --------------------------------------------------------------
   * input           |  ZDNN_3DS  | (num_timesteps, num_batches, num_features)
   * h0              |  ZDNN_3DS  | (1, num_batches, num_hidden)
   * weights         |  ZDNN_3DS  | (1, num_features, num_hidden)
   * input_biases    |  ZDNN_2DS  | (1, num_hidden)
   * hidden_weights  |  ZDNN_3DS  | (1, num_hidden, num_hidden)
   * hidden_biases   |  ZDNN_2DS  | (1, num_hidden)
   *
   * OUTPUTS -------------------------------------------------------------
   * hn_output       |  ZDNN_4DS  | (num_timesteps, 1, num_batches, num_hidden)
   *                 |            | or (1, 1, num_batches, num_hidden)
   ***********************************************************************/

  /***********************************************************************
   * Create input zTensor
   ***********************************************************************/

  zdnn_tensor_desc input_pre_tfrmd_desc, input_tfrmd_desc;
  zdnn_ztensor input;

  uint32_t num_timesteps = 5;
  uint32_t num_batches = 3;
  uint32_t num_features = 32;
  uint32_t num_hidden = 5;

  zdnn_data_types type = FP32;
  short element_size = 4; // size of each element in bytes

  lstm_gru_direction dir = FWD;
  uint8_t num_dirs = 1;

  zdnn_init_pre_transformed_desc(ZDNN_3DS, type, &amp;input_pre_tfrmd_desc,
                                 num_timesteps, num_batches, num_features);
  status =
      zdnn_generate_transformed_desc(&amp;input_pre_tfrmd_desc, &amp;input_tfrmd_desc);
  assert(status == ZDNN_OK);
  status = zdnn_init_ztensor_with_malloc(&amp;input_pre_tfrmd_desc,
                                         &amp;input_tfrmd_desc, &amp;input);
  assert(status == ZDNN_OK);

  uint64_t input_data_size =
      num_timesteps * num_batches * num_features * element_size;
  void *input_data = malloc(input_data_size);

  status = zdnn_transform_ztensor(&amp;input, input_data);
  assert(status == ZDNN_OK);

  /***********************************************************************
   * Create initial hidden zTensor
   ***********************************************************************/

  zdnn_tensor_desc h0_pre_tfrmd_desc, h0_tfrmd_desc;
  zdnn_ztensor h0;

  zdnn_init_pre_transformed_desc(ZDNN_3DS, type, &amp;h0_pre_tfrmd_desc, num_dirs,
                                 num_batches, num_hidden);
  status = zdnn_generate_transformed_desc(&amp;h0_pre_tfrmd_desc, &amp;h0_tfrmd_desc);
  assert(status == ZDNN_OK);

  status =
      zdnn_init_ztensor_with_malloc(&amp;h0_pre_tfrmd_desc, &amp;h0_tfrmd_desc, &amp;h0);
  assert(status == ZDNN_OK);

  uint64_t h0_data_size = num_batches * num_hidden * element_size;
  void *hidden_state_data = malloc(h0_data_size);

  status = zdnn_transform_ztensor(&amp;h0, hidden_state_data);
  assert(status == ZDNN_OK);

  /***********************************************************************
   * Create input weights zTensor
   * Resultant zTensor is concatenated
   ***********************************************************************/

  zdnn_tensor_desc weights_pre_tfrmd_desc, weights_tfrmd_desc;
  zdnn_ztensor weights;

  zdnn_init_pre_transformed_desc(ZDNN_3DS, type, &amp;weights_pre_tfrmd_desc,
                                 num_dirs, num_features, num_hidden);
  status = zdnn_generate_transformed_desc_concatenated(
      &amp;weights_pre_tfrmd_desc, RNN_TYPE_GRU | USAGE_WEIGHTS | PREV_LAYER_NONE,
      &amp;weights_tfrmd_desc);
  assert(status == ZDNN_OK);

  status = zdnn_init_ztensor_with_malloc(&amp;weights_pre_tfrmd_desc,
                                         &amp;weights_tfrmd_desc, &amp;weights);
  assert(status == ZDNN_OK);

  uint64_t weights_data_size = num_features * num_hidden * element_size;
  void *weights_data_z = malloc(weights_data_size);
  void *weights_data_r = malloc(weights_data_size);
  void *weights_data_h = malloc(weights_data_size);

  status = zdnn_transform_ztensor(&amp;weights, weights_data_z, weights_data_r,
                                  weights_data_h);
  assert(status == ZDNN_OK);

  /***********************************************************************
   * Create biases zTensors
   * Resultant zTensors are concatenated
   ***********************************************************************/

  zdnn_tensor_desc biases_pre_tfrmd_desc, biases_tfrmd_desc;
  zdnn_ztensor biases;

  zdnn_init_pre_transformed_desc(ZDNN_2DS, type, &amp;biases_pre_tfrmd_desc,
                                 num_dirs, num_hidden);
  status = zdnn_generate_transformed_desc_concatenated(
      &amp;biases_pre_tfrmd_desc, RNN_TYPE_GRU | USAGE_BIASES | PREV_LAYER_NONE,
      &amp;biases_tfrmd_desc);
  assert(status == ZDNN_OK);

  status = zdnn_init_ztensor_with_malloc(&amp;biases_pre_tfrmd_desc,
                                         &amp;biases_tfrmd_desc, &amp;biases);
  assert(status == ZDNN_OK);

  uint64_t biases_data_size = num_hidden * element_size;
  void *biases_data_z = malloc(biases_data_size);
  void *biases_data_r = malloc(biases_data_size);
  void *biases_data_h = malloc(biases_data_size);

  status = zdnn_transform_ztensor(&amp;biases, biases_data_z, biases_data_r,
                                  biases_data_h);
  assert(status == ZDNN_OK);

  /***********************************************************************
   * Create hidden weights zTensor
   * Resultant zTensor is concatenated
   ***********************************************************************/

  zdnn_tensor_desc hidden_weights_pre_tfrmd_desc, hidden_weights_tfrmd_desc;
  zdnn_ztensor hidden_weights;

  zdnn_init_pre_transformed_desc(ZDNN_3DS, type, &amp;hidden_weights_pre_tfrmd_desc,
                                 num_dirs, num_hidden, num_hidden);
  status = zdnn_generate_transformed_desc_concatenated(
      &amp;hidden_weights_pre_tfrmd_desc,
      RNN_TYPE_GRU | USAGE_HIDDEN_WEIGHTS | PREV_LAYER_NONE,
      &amp;hidden_weights_tfrmd_desc);
  assert(status == ZDNN_OK);
  status = zdnn_init_ztensor_with_malloc(&amp;hidden_weights_pre_tfrmd_desc,
                                         &amp;hidden_weights_tfrmd_desc,
                                         &amp;hidden_weights);
  assert(status == ZDNN_OK);

  uint64_t hidden_weights_data_size = num_hidden * num_hidden * element_size;
  void *hidden_weights_data_z = malloc(hidden_weights_data_size);
  void *hidden_weights_data_r = malloc(hidden_weights_data_size);
  void *hidden_weights_data_h = malloc(hidden_weights_data_size);

  status = zdnn_transform_ztensor(&amp;hidden_weights, hidden_weights_data_z,
                                  hidden_weights_data_r, hidden_weights_data_h);
  assert(status == ZDNN_OK);

  /***********************************************************************
   * Create hidden biases zTensors
   * Resultant zTensors are concatenated
   ***********************************************************************/

  zdnn_tensor_desc hidden_biases_pre_tfrmd_desc, hidden_biases_tfrmd_desc;
  zdnn_ztensor hidden_biases;

  zdnn_init_pre_transformed_desc(ZDNN_2DS, type, &amp;hidden_biases_pre_tfrmd_desc,
                                 num_dirs, num_hidden);
  status = zdnn_generate_transformed_desc_concatenated(
      &amp;hidden_biases_pre_tfrmd_desc,
      RNN_TYPE_GRU | USAGE_HIDDEN_BIASES | PREV_LAYER_NONE,
      &amp;hidden_biases_tfrmd_desc);
  assert(status == ZDNN_OK);

  status = zdnn_init_ztensor_with_malloc(
      &amp;hidden_biases_pre_tfrmd_desc, &amp;hidden_biases_tfrmd_desc, &amp;hidden_biases);
  assert(status == ZDNN_OK);

  uint64_t hidden_biases_data_size = num_hidden * element_size;
  void *hidden_biases_data_z = malloc(hidden_biases_data_size);
  void *hidden_biases_data_r = malloc(hidden_biases_data_size);
  void *hidden_biases_data_h = malloc(hidden_biases_data_size);

  status = zdnn_transform_ztensor(&amp;hidden_biases, hidden_biases_data_z,
                                  hidden_biases_data_r, hidden_biases_data_h);
  assert(status == ZDNN_OK);

  /***********************************************************************
   * Create output zTensor
   ***********************************************************************/

  // get only the last timestep
  zdnn_tensor_desc hn_pre_tfrmd_desc, hn_tfrmd_desc;

  zdnn_ztensor hn_output_ztensor;

  zdnn_init_pre_transformed_desc(ZDNN_4DS, type, &amp;hn_pre_tfrmd_desc, 1, 1,
                                 num_batches, num_hidden);
  status = zdnn_generate_transformed_desc(&amp;hn_pre_tfrmd_desc, &amp;hn_tfrmd_desc);
  assert(status == ZDNN_OK);

  status = zdnn_init_ztensor_with_malloc(&amp;hn_pre_tfrmd_desc, &amp;hn_tfrmd_desc,
                                         &amp;hn_output_ztensor);
  assert(status == ZDNN_OK);

  /***********************************************************************
   * Call the AIU
   ***********************************************************************/

  void *work_area = NULL;

  status = zdnn_gru(&amp;input, &amp;h0, &amp;weights, &amp;biases, &amp;hidden_weights,
                    &amp;hidden_biases, dir, work_area, &amp;hn_output_ztensor);
  assert(status == ZDNN_OK);

  /***********************************************************************
   * Output and Cleanup
   ***********************************************************************/

  uint64_t hn_data_size = num_batches * num_hidden * element_size;
  void *hn_output_data = malloc(hn_data_size);

  status = zdnn_transform_origtensor(&amp;hn_output_ztensor, hn_output_data);
  assert(status == ZDNN_OK);

  status = zdnn_free_ztensor_buffer(&amp;input);
  assert(status == ZDNN_OK);
  status = zdnn_free_ztensor_buffer(&amp;h0);
  assert(status == ZDNN_OK);
  status = zdnn_free_ztensor_buffer(&amp;weights);
  assert(status == ZDNN_OK);
  status = zdnn_free_ztensor_buffer(&amp;biases);
  assert(status == ZDNN_OK);
  status = zdnn_free_ztensor_buffer(&amp;hidden_weights);
  assert(status == ZDNN_OK);
  status = zdnn_free_ztensor_buffer(&amp;hidden_biases);
  assert(status == ZDNN_OK);
  status = zdnn_free_ztensor_buffer(&amp;hn_output_ztensor);
  assert(status == ZDNN_OK);

  free(input_data);
  free(hidden_state_data);
  free(weights_data_z);
  free(weights_data_r);
  free(weights_data_h);
  free(hidden_weights_data_z);
  free(hidden_weights_data_r);
  free(hidden_weights_data_h);
  free(biases_data_z);
  free(biases_data_r);
  free(biases_data_h);
  free(hidden_biases_data_z);
  free(hidden_biases_data_r);
  free(hidden_biases_data_h);
  free(hn_output_data);
}
</code></pre></div>

              
            </article>
          </div>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright &copy; 2020 IBM Developer
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
        <div class="md-social">
  
    
    
      
      
    
    <a href="https://github.com/ibm" target="_blank" rel="noopener" title="github.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.1.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
    </a>
  
    
    
      
      
    
    <a href="https://twitter.com/ibmdeveloper" target="_blank" rel="noopener" title="twitter.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.1.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg>
    </a>
  
    
    
      
      
    
    <a href="https://www.linkedin.com/company/ibm/" target="_blank" rel="noopener" title="www.linkedin.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.1.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"/></svg>
    </a>
  
    
    
      
      
    
    <a href="https://www.youtube.com/user/developerworks" target="_blank" rel="noopener" title="www.youtube.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!--! Font Awesome Free 6.1.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M549.655 124.083c-6.281-23.65-24.787-42.276-48.284-48.597C458.781 64 288 64 288 64S117.22 64 74.629 75.486c-23.497 6.322-42.003 24.947-48.284 48.597-11.412 42.867-11.412 132.305-11.412 132.305s0 89.438 11.412 132.305c6.281 23.65 24.787 41.5 48.284 47.821C117.22 448 288 448 288 448s170.78 0 213.371-11.486c23.497-6.321 42.003-24.171 48.284-47.821 11.412-42.867 11.412-132.305 11.412-132.305s0-89.438-11.412-132.305zm-317.51 213.508V175.185l142.739 81.205-142.739 81.201z"/></svg>
    </a>
  
    
    
      
      
    
    <a href="https://dev.to/ibmdeveloper" target="_blank" rel="noopener" title="dev.to" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.1.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M120.12 208.29c-3.88-2.9-7.77-4.35-11.65-4.35H91.03v104.47h17.45c3.88 0 7.77-1.45 11.65-4.35 3.88-2.9 5.82-7.25 5.82-13.06v-69.65c-.01-5.8-1.96-10.16-5.83-13.06zM404.1 32H43.9C19.7 32 .06 51.59 0 75.8v360.4C.06 460.41 19.7 480 43.9 480h360.2c24.21 0 43.84-19.59 43.9-43.8V75.8c-.06-24.21-19.7-43.8-43.9-43.8zM154.2 291.19c0 18.81-11.61 47.31-48.36 47.25h-46.4V172.98h47.38c35.44 0 47.36 28.46 47.37 47.28l.01 70.93zm100.68-88.66H201.6v38.42h32.57v29.57H201.6v38.41h53.29v29.57h-62.18c-11.16.29-20.44-8.53-20.72-19.69V193.7c-.27-11.15 8.56-20.41 19.71-20.69h63.19l-.01 29.52zm103.64 115.29c-13.2 30.75-36.85 24.63-47.44 0l-38.53-144.8h32.57l29.71 113.72 29.57-113.72h32.58l-38.46 144.8z"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    <script id="__config" type="application/json">{"base": "..", "features": ["navigation.instant"], "search": "../assets/javascripts/workers/search.2a1c317c.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "Search", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version.title": "Select version"}}</script>
    
    
      <script src="../assets/javascripts/bundle.a6c66575.min.js"></script>
      
    
  </body>
</html>