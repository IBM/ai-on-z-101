{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7112bb68-d238-4079-b289-7fd3ba7bfff5",
   "metadata": {},
   "source": [
    "# spaCy on s390x \n",
    "\n",
    "This is a simple example demonstrating the use of spaCy to tokenize and \n",
    "some basic analysis on input text. \n",
    "\n",
    "Numerous additional examples can be found on https://spacy.io/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2e1378-c654-4f23-aa92-ade83960f09d",
   "metadata": {},
   "source": [
    "### First, we'll download a trained english language pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c90358-af06-4588-bd1e-d5f59823f56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6276fcfb-145d-4fb7-8278-3a171194103c",
   "metadata": {},
   "source": [
    "### Next, let's import spaCy and check the version of some key dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3485c457-7b7f-4ab9-8a14-04479b070963",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import thinc\n",
    "print(spacy.__version__)\n",
    "print(thinc.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1280d03b-45c8-45f9-ba5c-f87eafbad880",
   "metadata": {},
   "source": [
    "### Now, import a set of examples and try one out.\n",
    "\n",
    "The logic below will load the spaCy model into the nlp object. It then executes the model using an example\n",
    "sentence. Some basic information on the text analyzed is displayed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee0729a-2e07-4a9b-a229-c81f48c81542",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from spacy.lang.en.examples import sentences \n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "doc = nlp(sentences[0])\n",
    "print(doc.text)\n",
    "\n",
    "# Analyze syntax\n",
    "print(\"Noun phrases:\", [chunk.text for chunk in doc.noun_chunks])\n",
    "print(\"Verbs:\", [token.lemma_ for token in doc if token.pos_ == \"VERB\"])\n",
    "print()\n",
    "# Find named entities, phrases and concepts\n",
    "print(\"List entities;\")\n",
    "for entity in doc.ents:\n",
    "    print(entity.text, entity.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e0a04c-fa01-47fb-83d0-96199fb0e7a7",
   "metadata": {},
   "source": [
    "### Finally, you can also try your own sentence of course.\n",
    "\n",
    "We've primed the text variable below with a paragraph from a blog writen to discuss \n",
    "the IBM Telum announcement in August of 2021. \n",
    "\n",
    "https://www.ibm.com/blogs/systems/ibm-telum-processor-the-next-gen-microprocessor-for-ibm-z-and-ibm-linuxone/\n",
    "\n",
    "Feel free to modify it and try your own example!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1cccc6-2d39-49e8-9e62-a88b41c06b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process whole documents\n",
    "text = (\"Today IBM announced the IBM Telum Processor at HotChips; Telum will be the \" \n",
    "        \"central processor chip for the next generation IBM Z and LinuxONE systems. \" \n",
    "        \"Organizations who want help in preventing fraud in real-time, or other use \"\n",
    "        \"cases, will welcome these new IBM Z innovations designed to deliver in-transaction \" \n",
    "        \"inference in real time and at scale. The 7 nm microprocessor is engineered to meet \" \n",
    "        \"the demands our clients face for gaining AI-based insights from their data without \"\n",
    "        \"compromising response time for high volume transactional workloads. To help \" \n",
    "        \"meet these needs, IBM Telum is designed with a new dedicated on-chip accelerator \"\n",
    "        \"for AI inference, to enable real time AI embedded directly in transactional \" \n",
    "        \"workloads, alongside improvements for performance, security, and availability. \")\n",
    "\n",
    "doc = nlp(text)\n",
    "\n",
    "# Analyze syntax\n",
    "print(\"Noun phrases:\", [chunk.text for chunk in doc.noun_chunks])\n",
    "print()\n",
    "print(\"Verbs:\", [token.lemma_ for token in doc if token.pos_ == \"VERB\"])\n",
    "print()\n",
    "# Find named entities, phrases and concepts\n",
    "print(\"List entities:\")\n",
    "for entity in doc.ents:\n",
    "    print(entity.text, entity.label_)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7252dc85deb17034b7a17627ea505139d2632c23f56c9fc9699db3bda8da1432"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
