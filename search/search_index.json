{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Enabling Smarter Workloads: AI on IBM Z and LinuxONE \u00b6 The IBM zSystems platform excels at processing the most critical enterprise workloads. IBM zSystems have continuously evolved to meet the worlds ever growing needs. With the introduction of the IBM z16 this includes an on-chip AI accelerator which enables workloads to be infused with AI at throughput rates and latencies previously unobtainable. Whether you come here as a beginner or experienced AI practioner, IBM zSystems provide numerous options for getting started with AI. Within these pages, you'll find information on how to leverage the best of the open source ecosystem on IBM zSystems and LinuxONE, as well as pointers to community edition and freely available software that can help you quickly get started. IBM zSystems and LinuxONE are, at their core, enterprise platforms. As such, these pages will also contain pointers to informaton on infusing critical business applications with AI. This Github 101 page has been created to assist in that enablement by providing use cases, code samples, and other content to serve as a technical resource for your AI on Z journey. Use the navigation bar on the left to begin your journey.","title":"Overview"},{"location":"#enabling-smarter-workloads-ai-on-ibm-z-and-linuxone","text":"The IBM zSystems platform excels at processing the most critical enterprise workloads. IBM zSystems have continuously evolved to meet the worlds ever growing needs. With the introduction of the IBM z16 this includes an on-chip AI accelerator which enables workloads to be infused with AI at throughput rates and latencies previously unobtainable. Whether you come here as a beginner or experienced AI practioner, IBM zSystems provide numerous options for getting started with AI. Within these pages, you'll find information on how to leverage the best of the open source ecosystem on IBM zSystems and LinuxONE, as well as pointers to community edition and freely available software that can help you quickly get started. IBM zSystems and LinuxONE are, at their core, enterprise platforms. As such, these pages will also contain pointers to informaton on infusing critical business applications with AI. This Github 101 page has been created to assist in that enablement by providing use cases, code samples, and other content to serve as a technical resource for your AI on Z journey. Use the navigation bar on the left to begin your journey.","title":"Enabling Smarter Workloads: AI on IBM Z and LinuxONE"},{"location":"codingAIU/","text":"Developing for the Integrated Accelerator for AI \u00b6 Most users of the IBM z16 Integrated Accelerator for AI will be accessing it through frameworks and technologies like the IBM Deep Learning Compiler, TensorFlow, or Snap ML. The other pages on this site are focused on this type of usage. For those that wish to develop or enhance AI frameworks and compilers to leverage the Integrated Accelerator for AI, an lower level SDK is needed. To facilitate this, IBM has created the zDNN library. IBM zDNN is the IBM Z Deep Neural Network library, which features C apis that can simplify use of the z16 accelerator. Details and examples can be found in the IBM zDNN github . Note that zDNN library is packaged in z/OS 2.4 and above, and on RHEL, Ubuntu, SUSE at various levels.","title":"Compiler and AI framework developer resources"},{"location":"codingAIU/#developing-for-the-integrated-accelerator-for-ai","text":"Most users of the IBM z16 Integrated Accelerator for AI will be accessing it through frameworks and technologies like the IBM Deep Learning Compiler, TensorFlow, or Snap ML. The other pages on this site are focused on this type of usage. For those that wish to develop or enhance AI frameworks and compilers to leverage the Integrated Accelerator for AI, an lower level SDK is needed. To facilitate this, IBM has created the zDNN library. IBM zDNN is the IBM Z Deep Neural Network library, which features C apis that can simplify use of the z16 accelerator. Details and examples can be found in the IBM zDNN github . Note that zDNN library is packaged in z/OS 2.4 and above, and on RHEL, Ubuntu, SUSE at various levels.","title":"Developing for the Integrated Accelerator for AI"},{"location":"help/","text":"Resources and Contacts \u00b6 The path to getting started with AI on IBM zSystems and LinuxONE can vary based on the use case and goal that you have. In addition to this page, the following resources should be helpful: Journey to AI on IBM Z and LinuxONE content solution AI on IBM Z and LinuxONE Community Contact the IBM zSystems and LinuxONE AI core team Did you know that IBM offers an AI on IBM zSystems and LinuxONE Client Engineering workshop at no charge? \u00b6 This is a discovery workshop designed to help demystify the technology powering AI. It can be in-person or virtual, and tailored for your needs. It's targeted to IBM zSystem and LinuxONE customers who are interested in leveraging AI and analytic capabilities to gain new insights from their workloads and data. Contact SysGarage@ibm.com for more information.","title":"Getting help"},{"location":"help/#resources-and-contacts","text":"The path to getting started with AI on IBM zSystems and LinuxONE can vary based on the use case and goal that you have. In addition to this page, the following resources should be helpful: Journey to AI on IBM Z and LinuxONE content solution AI on IBM Z and LinuxONE Community Contact the IBM zSystems and LinuxONE AI core team","title":"Resources and Contacts"},{"location":"help/#did-you-know-that-ibm-offers-an-ai-on-ibm-zsystems-and-linuxone-client-engineering-workshop-at-no-charge","text":"This is a discovery workshop designed to help demystify the technology powering AI. It can be in-person or virtual, and tailored for your needs. It's targeted to IBM zSystem and LinuxONE customers who are interested in leveraging AI and analytic capabilities to gain new insights from their workloads and data. Contact SysGarage@ibm.com for more information.","title":"Did you know that IBM offers an AI on IBM zSystems and LinuxONE Client Engineering workshop at no charge?"},{"location":"infusing/","text":"Infusing AI into IBM Z and LinuxONE applications \u00b6 For detailed up to date information, see the Journey to AI on IBM Z and LinuxONE content solution See section \"Infusing AI into applications\" under \"Learn more\".","title":"Infusing AI into your IBM zSystem business applications"},{"location":"infusing/#infusing-ai-into-ibm-z-and-linuxone-applications","text":"For detailed up to date information, see the Journey to AI on IBM Z and LinuxONE content solution See section \"Infusing AI into applications\" under \"Learn more\".","title":"Infusing AI into IBM Z and LinuxONE applications"},{"location":"onnxdlc/","text":"Deploying ONNX deep learning models on IBM zSystems \u00b6 ONNX is the Open Neural Network eXchange. You can read more about it here . ONNX establishes a streamlined path to take a project from playground to production. With ONNX, you can start a data science project using the frameworks and libraries of your choosing, including popular frameworks such as PyTorch and TensorFlow. The model can be developed and trained leveraging these frameworks on the training platform of your choice. Once the model is trained and ready to begin the deployment journey, you would export or convert it to the ONNX format. Tools such as Netron allow inspection and exploration of an ONNX model. When it comes to running the model, there are various back-ends that can be used to test and serve ONNX models. This includes model compilers such as the IBM Deep Learning Compiler (DLC), which is based on ONNX-MLIR. The ONNX-MLIR project provides compiler technology to transform a valid Open Neural Network Exchange (ONNX) graph into code that implements the graph with minimum runtime support. It implements the ONNX standard and is based on the underlying LLVM/MLIR compiler technology. The result of this compiler is a lightweight shared object library that has no dependencies on the framework or libraries that the model was developed and trained in. It can easily be used for inference from C++, Java or Python programs. z16 Integrated Accelerator for AI \u00b6 IBM Research enhanced the IBM Deep Learning Compiler (DLC) to target the IBM Integrated Accelerator for AI for a variety of ONNX primitives. This support has been contributed to ONNX-MLIR, which is the foundation for the IBM Deep Learning Compiler. Getting Started with the IBM Deep Learning Compiler \u00b6 The best approach to getting started with ONNX models using the IBM Deep Learning Compiler will depend on the IBM zSystem operating system on which you plan to use the inference program. z/OS users should likely choose a Watson Machine Learning for z/OS (WMLz) based approach. There are two paths: Watson Machine Learning for z/OS Online Scoring Community Edition (OSCE), which is freely available and excels at enabling rapid prototyping and proof of concept exercises. Simple install to z/OS Container Extensions (zCX). Enables you to upload your ONNX model then compile and deploy at the push of a button. Includes serving capability that exposes REST end points to call from an application. Available on the ibm.com WMLz page: 'Download trial code' . Watson Machine Learning for z/OS, which is a z/OS product that manages full model lifecycle and includes numerous features to improve performance for AI models and simplify deployment. Enables you to upload your ONNX model then compile and deploy at the push of a button. Supports server side mini-batching for ONNX/DLC model serving to get the best benefit out of the Integrated Accelerator for AI. Infuse AI into z/OS applications either through native CICS Cobol scoring services or by using model server REST endpoints. Additional resources: If you are interested in trying WMLz OSCE, here is a quick self-directed exercise that demonstrates how to call a ONNX model from a z/OS Java program: Demonstrating a z/OS application calling WMLz OSCE Linux on Z and LinuxONE users can leverage the Deep Learning Compiler directly to create model programs that can be incorporated into serving environments or applications directly. Available through the IBM Z and LinuxONE Container Registry listed under ONNX-MLIR. Command-line model compiler that produces a .so library with optional Java and Python wrappers. Additional resources: Sample C++, Java, and Python clients BentoML ONNX-MLIR support Read our blogs on ONNX for more information: - Leveraging ONNX models on IBM zSystems and LinuxONE","title":"ONNX and the IBM Deep Learning Compiler"},{"location":"onnxdlc/#deploying-onnx-deep-learning-models-on-ibm-zsystems","text":"ONNX is the Open Neural Network eXchange. You can read more about it here . ONNX establishes a streamlined path to take a project from playground to production. With ONNX, you can start a data science project using the frameworks and libraries of your choosing, including popular frameworks such as PyTorch and TensorFlow. The model can be developed and trained leveraging these frameworks on the training platform of your choice. Once the model is trained and ready to begin the deployment journey, you would export or convert it to the ONNX format. Tools such as Netron allow inspection and exploration of an ONNX model. When it comes to running the model, there are various back-ends that can be used to test and serve ONNX models. This includes model compilers such as the IBM Deep Learning Compiler (DLC), which is based on ONNX-MLIR. The ONNX-MLIR project provides compiler technology to transform a valid Open Neural Network Exchange (ONNX) graph into code that implements the graph with minimum runtime support. It implements the ONNX standard and is based on the underlying LLVM/MLIR compiler technology. The result of this compiler is a lightweight shared object library that has no dependencies on the framework or libraries that the model was developed and trained in. It can easily be used for inference from C++, Java or Python programs.","title":"Deploying ONNX deep learning models on IBM zSystems"},{"location":"onnxdlc/#z16-integrated-accelerator-for-ai","text":"IBM Research enhanced the IBM Deep Learning Compiler (DLC) to target the IBM Integrated Accelerator for AI for a variety of ONNX primitives. This support has been contributed to ONNX-MLIR, which is the foundation for the IBM Deep Learning Compiler.","title":"z16 Integrated Accelerator for AI"},{"location":"onnxdlc/#getting-started-with-the-ibm-deep-learning-compiler","text":"The best approach to getting started with ONNX models using the IBM Deep Learning Compiler will depend on the IBM zSystem operating system on which you plan to use the inference program. z/OS users should likely choose a Watson Machine Learning for z/OS (WMLz) based approach. There are two paths: Watson Machine Learning for z/OS Online Scoring Community Edition (OSCE), which is freely available and excels at enabling rapid prototyping and proof of concept exercises. Simple install to z/OS Container Extensions (zCX). Enables you to upload your ONNX model then compile and deploy at the push of a button. Includes serving capability that exposes REST end points to call from an application. Available on the ibm.com WMLz page: 'Download trial code' . Watson Machine Learning for z/OS, which is a z/OS product that manages full model lifecycle and includes numerous features to improve performance for AI models and simplify deployment. Enables you to upload your ONNX model then compile and deploy at the push of a button. Supports server side mini-batching for ONNX/DLC model serving to get the best benefit out of the Integrated Accelerator for AI. Infuse AI into z/OS applications either through native CICS Cobol scoring services or by using model server REST endpoints. Additional resources: If you are interested in trying WMLz OSCE, here is a quick self-directed exercise that demonstrates how to call a ONNX model from a z/OS Java program: Demonstrating a z/OS application calling WMLz OSCE Linux on Z and LinuxONE users can leverage the Deep Learning Compiler directly to create model programs that can be incorporated into serving environments or applications directly. Available through the IBM Z and LinuxONE Container Registry listed under ONNX-MLIR. Command-line model compiler that produces a .so library with optional Java and Python wrappers. Additional resources: Sample C++, Java, and Python clients BentoML ONNX-MLIR support Read our blogs on ONNX for more information: - Leveraging ONNX models on IBM zSystems and LinuxONE","title":"Getting Started with the IBM Deep Learning Compiler"},{"location":"opensource/","text":"Obtaining open source AI packages on IBM Z and LinuxONE \u00b6 You can obtain open source AI packages using many of the methods you are familiar with. Packages can be installed using Linux packages managers, PyPI, Anaconda, or of course built from source where necessary. Resources: Anaconda for s390x IBM Z and LinuxONE Container Registry Additional guidance on building specific packages for s390x can be found on the Linux on Z ecosystem repository If you need assistance with specific other packages, contact us .","title":"Obtaining open-source packages"},{"location":"opensource/#obtaining-open-source-ai-packages-on-ibm-z-and-linuxone","text":"You can obtain open source AI packages using many of the methods you are familiar with. Packages can be installed using Linux packages managers, PyPI, Anaconda, or of course built from source where necessary. Resources: Anaconda for s390x IBM Z and LinuxONE Container Registry Additional guidance on building specific packages for s390x can be found on the Linux on Z ecosystem repository If you need assistance with specific other packages, contact us .","title":"Obtaining open source AI packages on IBM Z and LinuxONE"},{"location":"snapml/","text":"Traditional Machine Learning with IBM Snap ML \u00b6 Snap ML is a library that provides high speed training and inference of popular machine learning models. You can read more about it here . Standard machine learning models power most of today's machine learning applications in business and are very popular among practitioners as well. Snap ML has been designed to address some of the biggest challenges that companies and practitioners face when applying machine learning to real use cases. Snap ML is a library for accelerating the training and inference of popular Machine Learning (ML) models: Provides high-performance implementations of: Generalized Linear Models Tree-based Models Gradient Boosting Machines Addresses ML needs of Data Scientists by being: Fast Resource-efficient Accurate Scalable to TB-scale datasets Snap ML: Is developed & maintained by IBM Research. Is fully compatible with the scikit-learn Python API. Supports scikit-learn, XGBoost and LightGBM trained models when exported or converted to: PMML, JSON, ONNX. In addition to being available through PyPI, Snap ML is an available python framework in IBM Cloud Pak for Data. z16 Integrated Accelerator for AI \u00b6 Starting with Snap ML version 1.9.0, Snap ML can utilize the IBM Integrated Accelerator for AI. Integrated AI Accelerator exploitation can be enabled at model import time for: Random Forest Extra Trees Gradient Boosting Machines Getting Started with the IBM Snap ML \u00b6 Snap ML is available for IBM LinuxONE and Linux on Z environments, including z/OS container extensions. Linux on zSystems package available via PyPI: pip install snapml - This enables install into a python environment through standard mechanisms, at no charge. Snap ML is an available python framework in IBM Cloud Pak for Data. Click here for official documentation Click here for examples using Snap ML Example using Snap ML with BentoML Serving","title":"IBM Snap Machine Learning (Snap ML)"},{"location":"snapml/#traditional-machine-learning-with-ibm-snap-ml","text":"Snap ML is a library that provides high speed training and inference of popular machine learning models. You can read more about it here . Standard machine learning models power most of today's machine learning applications in business and are very popular among practitioners as well. Snap ML has been designed to address some of the biggest challenges that companies and practitioners face when applying machine learning to real use cases. Snap ML is a library for accelerating the training and inference of popular Machine Learning (ML) models: Provides high-performance implementations of: Generalized Linear Models Tree-based Models Gradient Boosting Machines Addresses ML needs of Data Scientists by being: Fast Resource-efficient Accurate Scalable to TB-scale datasets Snap ML: Is developed & maintained by IBM Research. Is fully compatible with the scikit-learn Python API. Supports scikit-learn, XGBoost and LightGBM trained models when exported or converted to: PMML, JSON, ONNX. In addition to being available through PyPI, Snap ML is an available python framework in IBM Cloud Pak for Data.","title":"Traditional Machine Learning with IBM Snap ML"},{"location":"snapml/#z16-integrated-accelerator-for-ai","text":"Starting with Snap ML version 1.9.0, Snap ML can utilize the IBM Integrated Accelerator for AI. Integrated AI Accelerator exploitation can be enabled at model import time for: Random Forest Extra Trees Gradient Boosting Machines","title":"z16 Integrated Accelerator for AI"},{"location":"snapml/#getting-started-with-the-ibm-snap-ml","text":"Snap ML is available for IBM LinuxONE and Linux on Z environments, including z/OS container extensions. Linux on zSystems package available via PyPI: pip install snapml - This enables install into a python environment through standard mechanisms, at no charge. Snap ML is an available python framework in IBM Cloud Pak for Data. Click here for official documentation Click here for examples using Snap ML Example using Snap ML with BentoML Serving","title":"Getting Started with the IBM Snap ML"},{"location":"tensorflow/","text":"TensorFlow on IBM zSystems and LinuxONE \u00b6 TensorFlow is a open source machine learning framework. It has a comphrensive set of tools that enable model development, training and inference. It also features a rich, robust ecosystem. TensorFlow can be used on IBM zSystems and LinuxONE on Linux environments - including z/OS Container Extensions. With TensorFlow Servng, you can expose REST and GRPC endpoints for model inference requests. This supports high throughput, low latency inference serving. On IBM zSystems and LinuxONE, TensorFlow is built to exploit the vector architecture for training and inference operations. On IBM z16 hardware, TensorFlow can leverage new inference acceleration capabilities. Read more below! z16 Integrated Accelerator for AI \u00b6 Starting in late 2Q 2022, IBM will release an open beta of TensorFlow core that includes device support for the IBM Integrated Accelerator for AI. This capability will allow TensorFlow to transparently target the accelerator for a number of compute intenstive operations. The beta container image will be released through the IBM Z and LinuxONE Container Registry (see below). Getting Started with TensorFlow on IBM zSystems and LinuxONE \u00b6 The recommended path for obtaining TensorFlow is to download a prebuilt container image from the IBM Z and LinuxONE Container Registry . The following images are available: TensorFlow Core (CPU) TensorFlow Serving (CPU) Coming soon: TensorFlow Core (IBM z16 Accelerator) If you are interested in trying TensorFlow out, here is a quick self-directed exercise that demonstrates how to call a TensorFlow model from a z/OS Java program: TensorFlow and zCX interaction . Note that although this lab highlights TensorFlow on zCX, the image can just as easily be deployed to a Linux LPAR or VM using these steps.","title":"TensorFlow"},{"location":"tensorflow/#tensorflow-on-ibm-zsystems-and-linuxone","text":"TensorFlow is a open source machine learning framework. It has a comphrensive set of tools that enable model development, training and inference. It also features a rich, robust ecosystem. TensorFlow can be used on IBM zSystems and LinuxONE on Linux environments - including z/OS Container Extensions. With TensorFlow Servng, you can expose REST and GRPC endpoints for model inference requests. This supports high throughput, low latency inference serving. On IBM zSystems and LinuxONE, TensorFlow is built to exploit the vector architecture for training and inference operations. On IBM z16 hardware, TensorFlow can leverage new inference acceleration capabilities. Read more below!","title":"TensorFlow on IBM zSystems and LinuxONE"},{"location":"tensorflow/#z16-integrated-accelerator-for-ai","text":"Starting in late 2Q 2022, IBM will release an open beta of TensorFlow core that includes device support for the IBM Integrated Accelerator for AI. This capability will allow TensorFlow to transparently target the accelerator for a number of compute intenstive operations. The beta container image will be released through the IBM Z and LinuxONE Container Registry (see below).","title":"z16 Integrated Accelerator for AI"},{"location":"tensorflow/#getting-started-with-tensorflow-on-ibm-zsystems-and-linuxone","text":"The recommended path for obtaining TensorFlow is to download a prebuilt container image from the IBM Z and LinuxONE Container Registry . The following images are available: TensorFlow Core (CPU) TensorFlow Serving (CPU) Coming soon: TensorFlow Core (IBM z16 Accelerator) If you are interested in trying TensorFlow out, here is a quick self-directed exercise that demonstrates how to call a TensorFlow model from a z/OS Java program: TensorFlow and zCX interaction . Note that although this lab highlights TensorFlow on zCX, the image can just as easily be deployed to a Linux LPAR or VM using these steps.","title":"Getting Started with TensorFlow on IBM zSystems and LinuxONE"},{"location":"z16Accel/","text":"Leveraging the IBM Integrated Accelerator for AI \u00b6 The IBM Integrated Accelerator for AI is an on-chip AI accelerator available on the IBM Telum chip that is part of IBM z16. It is designed to enable high throughput, low latency inference for deep learning and machine learning. With IBM z16 and the Integrated Accelerator for AI, you can build and train your models on any platform - including IBM zSystems and LinuxONE. When you are ready to deploy your assets, they will receive transparent acceleration and optimization on IBM zSystems, and will leverage the best available acceleration for the model type. The IBM Integrated Accelerator for AI is more than just a matrix multiply accelerator - it provides optimization and acceleration for a set of complex functions commonly found in deep learning and machine learning models. This enables a broader set of functions to be accelerated on the chip. As of IBM z16, the following operations are supported on the accelerator: LSTM Activation GRU Activation Fused Matrix Multiply, Bias op Fused Matrix Multiply (w/ broadcast) Batch Normalization Fused Convolution, Bias Add, Relu Max Pool 2D Average Pool 2D Softmax Relu Tanh Sigmoid Add Subtract Multiply Divide Min Max Log These allow the supporting frameworks to target an even broader set of operations to the Integrated Accelerator for AI. Currently, the following frameworks can leverage the IBM z16 Integrated Accelerator for AI: ONNX deep learning models , when compiled using the IBM Deep Learning Compiler or ONNX-MLIR. Note that Pytorch, TensorFlow, Apache MXNet and other model types can be easily converted to ONNX. IBM Snap ML , a machine learning framework that provides optimized training and inference. Random Forest and Boosting Machine models are accelerated using the Integrated Accelerator for AI. IBM Snap ML provides: Seamless acceleration of sci-kit learn applications. Ability to execute lightGBM and XGBoost trained models when converted to JSON, PMML, or ONNX. TensorFlow (incubating) Available initially as an open beta in late 2Q 2022. For further details, use the navigation bar on this page to select a 'Featured Frameworks and Technologies' choice. Each of these are available as standalone packages, free of charge, or embedded within IBM products such as Watson Machine Learning for z/OS and Cloud Pak for Data. Furthe reading: IBM Telum announcement","title":"Leveraging the IBM z16 Integrated Accelerator for AI"},{"location":"z16Accel/#leveraging-the-ibm-integrated-accelerator-for-ai","text":"The IBM Integrated Accelerator for AI is an on-chip AI accelerator available on the IBM Telum chip that is part of IBM z16. It is designed to enable high throughput, low latency inference for deep learning and machine learning. With IBM z16 and the Integrated Accelerator for AI, you can build and train your models on any platform - including IBM zSystems and LinuxONE. When you are ready to deploy your assets, they will receive transparent acceleration and optimization on IBM zSystems, and will leverage the best available acceleration for the model type. The IBM Integrated Accelerator for AI is more than just a matrix multiply accelerator - it provides optimization and acceleration for a set of complex functions commonly found in deep learning and machine learning models. This enables a broader set of functions to be accelerated on the chip. As of IBM z16, the following operations are supported on the accelerator: LSTM Activation GRU Activation Fused Matrix Multiply, Bias op Fused Matrix Multiply (w/ broadcast) Batch Normalization Fused Convolution, Bias Add, Relu Max Pool 2D Average Pool 2D Softmax Relu Tanh Sigmoid Add Subtract Multiply Divide Min Max Log These allow the supporting frameworks to target an even broader set of operations to the Integrated Accelerator for AI. Currently, the following frameworks can leverage the IBM z16 Integrated Accelerator for AI: ONNX deep learning models , when compiled using the IBM Deep Learning Compiler or ONNX-MLIR. Note that Pytorch, TensorFlow, Apache MXNet and other model types can be easily converted to ONNX. IBM Snap ML , a machine learning framework that provides optimized training and inference. Random Forest and Boosting Machine models are accelerated using the Integrated Accelerator for AI. IBM Snap ML provides: Seamless acceleration of sci-kit learn applications. Ability to execute lightGBM and XGBoost trained models when converted to JSON, PMML, or ONNX. TensorFlow (incubating) Available initially as an open beta in late 2Q 2022. For further details, use the navigation bar on this page to select a 'Featured Frameworks and Technologies' choice. Each of these are available as standalone packages, free of charge, or embedded within IBM products such as Watson Machine Learning for z/OS and Cloud Pak for Data. Furthe reading: IBM Telum announcement","title":"Leveraging the IBM Integrated Accelerator for AI"},{"location":"ai-on-z-containers/","text":"ai-on-z-containers \u00b6 Scope \u00b6 The purpose of this project is to provide container build files for AI software that can be utilized in s390x environments. These container files (i.e., dockerfiles or containerfiles) are provided as examples that can be used directly or built upon. They build open-source based (not proprietary) images. Usage \u00b6 These build files commonly rely on base images from the IBM Z and LinuxONE Container Image Registry (ICR) . This will require free basic authentication. Details can be found at the ICR link above. Additionally, note that numerous pre-built s390x images are available in ICR. Content \u00b6 Folder(topic) Description nlp-spaCy spaCy library for natural language processing use cases License \u00b6 If you would like to see the detailed LICENSE click here . # # Copyright 2020- IBM Inc. All rights reserved # SPDX-License-Identifier: Apache2.0 #","title":"Index"},{"location":"ai-on-z-containers/#ai-on-z-containers","text":"","title":"ai-on-z-containers"},{"location":"ai-on-z-containers/#scope","text":"The purpose of this project is to provide container build files for AI software that can be utilized in s390x environments. These container files (i.e., dockerfiles or containerfiles) are provided as examples that can be used directly or built upon. They build open-source based (not proprietary) images.","title":"Scope"},{"location":"ai-on-z-containers/#usage","text":"These build files commonly rely on base images from the IBM Z and LinuxONE Container Image Registry (ICR) . This will require free basic authentication. Details can be found at the ICR link above. Additionally, note that numerous pre-built s390x images are available in ICR.","title":"Usage"},{"location":"ai-on-z-containers/#content","text":"Folder(topic) Description nlp-spaCy spaCy library for natural language processing use cases","title":"Content"},{"location":"ai-on-z-containers/#license","text":"If you would like to see the detailed LICENSE click here . # # Copyright 2020- IBM Inc. All rights reserved # SPDX-License-Identifier: Apache2.0 #","title":"License"},{"location":"ai-on-z-containers/CONTRIBUTING/","text":"Contributing In General \u00b6 Our project welcomes external contributions. If you have an itch, please feel free to scratch it. To contribute code or documentation, please submit a FIXME pull request . A good way to familiarize yourself with the codebase and contribution process is to look for and tackle low-hanging fruit in the FIXME issue tracker . Before embarking on a more ambitious contribution, please quickly get in touch with us. Note: We appreciate your effort, and want to avoid a situation where a contribution requires extensive rework (by you or by us), sits in backlog for a long time, or cannot be accepted at all! Proposing new features \u00b6 If you would like to implement a new feature, please FIXME raise an issue before sending a pull request so the feature can be discussed. This is to avoid you wasting your valuable time working on a feature that the project developers are not interested in accepting into the code base. Fixing bugs \u00b6 If you would like to fix a bug, please FIXME raise an issue before sending a pull request so it can be tracked. Merge approval \u00b6 The project maintainers use LGTM (Looks Good To Me) in comments on the code review to indicate acceptance. A change requires LGTMs from two of the maintainers of each component affected. For a list of the maintainers, see the MAINTAINERS.md page. Legal \u00b6 Each source file must include a license header for the Apache Software License 2.0. Using the SPDX format is the simplest approach. e.g. /* Copyright <holder> All Rights Reserved. SPDX-License-Identifier: Apache-2.0 */ We have tried to make it as easy as possible to make contributions. This applies to how we handle the legal aspects of contribution. We use the same approach - the Developer's Certificate of Origin 1.1 (DCO) - that the Linux\u00ae Kernel community uses to manage code contributions. We simply ask that when submitting a patch for review, the developer must include a sign-off statement in the commit message. Here is an example Signed-off-by line, which indicates that the submitter accepts the DCO: Signed-off-by: John Doe <john.doe@example.com> You can include this automatically when you commit a change to your local git repository using the following command: git commit -s Communication \u00b6 FIXME Please feel free to connect with us on our Slack channel . Setup \u00b6 FIXME Please add any special setup instructions for your project to help the developer become productive quickly. Testing \u00b6 FIXME Please provide information that helps the developer test any changes they make before submitting. Coding style guidelines \u00b6 FIXME Optional, but recommended: please share any specific style guidelines you might have for your project.","title":"CONTRIBUTING"},{"location":"ai-on-z-containers/CONTRIBUTING/#contributing-in-general","text":"Our project welcomes external contributions. If you have an itch, please feel free to scratch it. To contribute code or documentation, please submit a FIXME pull request . A good way to familiarize yourself with the codebase and contribution process is to look for and tackle low-hanging fruit in the FIXME issue tracker . Before embarking on a more ambitious contribution, please quickly get in touch with us. Note: We appreciate your effort, and want to avoid a situation where a contribution requires extensive rework (by you or by us), sits in backlog for a long time, or cannot be accepted at all!","title":"Contributing In General"},{"location":"ai-on-z-containers/CONTRIBUTING/#proposing-new-features","text":"If you would like to implement a new feature, please FIXME raise an issue before sending a pull request so the feature can be discussed. This is to avoid you wasting your valuable time working on a feature that the project developers are not interested in accepting into the code base.","title":"Proposing new features"},{"location":"ai-on-z-containers/CONTRIBUTING/#fixing-bugs","text":"If you would like to fix a bug, please FIXME raise an issue before sending a pull request so it can be tracked.","title":"Fixing bugs"},{"location":"ai-on-z-containers/CONTRIBUTING/#merge-approval","text":"The project maintainers use LGTM (Looks Good To Me) in comments on the code review to indicate acceptance. A change requires LGTMs from two of the maintainers of each component affected. For a list of the maintainers, see the MAINTAINERS.md page.","title":"Merge approval"},{"location":"ai-on-z-containers/CONTRIBUTING/#legal","text":"Each source file must include a license header for the Apache Software License 2.0. Using the SPDX format is the simplest approach. e.g. /* Copyright <holder> All Rights Reserved. SPDX-License-Identifier: Apache-2.0 */ We have tried to make it as easy as possible to make contributions. This applies to how we handle the legal aspects of contribution. We use the same approach - the Developer's Certificate of Origin 1.1 (DCO) - that the Linux\u00ae Kernel community uses to manage code contributions. We simply ask that when submitting a patch for review, the developer must include a sign-off statement in the commit message. Here is an example Signed-off-by line, which indicates that the submitter accepts the DCO: Signed-off-by: John Doe <john.doe@example.com> You can include this automatically when you commit a change to your local git repository using the following command: git commit -s","title":"Legal"},{"location":"ai-on-z-containers/CONTRIBUTING/#communication","text":"FIXME Please feel free to connect with us on our Slack channel .","title":"Communication"},{"location":"ai-on-z-containers/CONTRIBUTING/#setup","text":"FIXME Please add any special setup instructions for your project to help the developer become productive quickly.","title":"Setup"},{"location":"ai-on-z-containers/CONTRIBUTING/#testing","text":"FIXME Please provide information that helps the developer test any changes they make before submitting.","title":"Testing"},{"location":"ai-on-z-containers/CONTRIBUTING/#coding-style-guidelines","text":"FIXME Optional, but recommended: please share any specific style guidelines you might have for your project.","title":"Coding style guidelines"},{"location":"ai-on-z-containers/MAINTAINERS/","text":"MAINTAINERS \u00b6 Christopher Ferris - chrisfer@us.ibm.com","title":"MAINTAINERS"},{"location":"ai-on-z-containers/MAINTAINERS/#maintainers","text":"Christopher Ferris - chrisfer@us.ibm.com","title":"MAINTAINERS"},{"location":"ai-on-z-containers/nlp-spaCy/","text":"spaCy, a natural language processing library. \u00b6 Overview \u00b6 spaCy.io spaCy github from the spaCy github project: spaCy is a library for advanced Natural Language Processing in Python and Cython. It's built on the very latest research, and was designed from day one to be used in real products. spaCy comes with pretrained pipelines and currently supports tokenization and training for 60+ languages. It features state-of-the-art speed and neural network models for tagging, parsing, named entity recognition, text classification and more, multi-task learning with pretrained transformers like BERT, as well as a production-ready training system and easy model packaging, deployment and workflow management. spaCy is commercial open-source software, released under the MIT license. Usage \u00b6 This image can be built using the podman or docker build command. e.g., docker build -t 'spacy_s390x' . Note that this docker files relies on base images from the IBM Z and LinuxONE Container Image Registry (ICR) . This build file includes jupyter and an example notebook to demonstrate basic syntax analysis with spaCy. Once this image is built, you can start a container using a command like this: docker run -d --rm -p 8571:8888 <image_id> This will start a container which exposing jupyter port 8888 on host system port 8571. If you specify -d (as above) you will need to display the jupyter token; this can be found by issuing docker logs <container_id> You can then direct your web browser to <host_ip_addr>:<exposed_port>/?token=<jupyter_token>","title":"Index"},{"location":"ai-on-z-containers/nlp-spaCy/#spacy-a-natural-language-processing-library","text":"","title":"spaCy, a natural language processing library."},{"location":"ai-on-z-containers/nlp-spaCy/#overview","text":"spaCy.io spaCy github from the spaCy github project: spaCy is a library for advanced Natural Language Processing in Python and Cython. It's built on the very latest research, and was designed from day one to be used in real products. spaCy comes with pretrained pipelines and currently supports tokenization and training for 60+ languages. It features state-of-the-art speed and neural network models for tagging, parsing, named entity recognition, text classification and more, multi-task learning with pretrained transformers like BERT, as well as a production-ready training system and easy model packaging, deployment and workflow management. spaCy is commercial open-source software, released under the MIT license.","title":"Overview"},{"location":"ai-on-z-containers/nlp-spaCy/#usage","text":"This image can be built using the podman or docker build command. e.g., docker build -t 'spacy_s390x' . Note that this docker files relies on base images from the IBM Z and LinuxONE Container Image Registry (ICR) . This build file includes jupyter and an example notebook to demonstrate basic syntax analysis with spaCy. Once this image is built, you can start a container using a command like this: docker run -d --rm -p 8571:8888 <image_id> This will start a container which exposing jupyter port 8888 on host system port 8571. If you specify -d (as above) you will need to display the jupyter token; this can be found by issuing docker logs <container_id> You can then direct your web browser to <host_ip_addr>:<exposed_port>/?token=<jupyter_token>","title":"Usage"},{"location":"ai-on-z-fraud-detection/","text":"Scope \u00b6 This repository provides TensorFlow source code for building and training credit card fraud models using an LSTM and a GRU. Summary \u00b6 The models included in this repository are multi-layer LSTM or GRU models that analyze time series data to predict whether a credit card transaction is fraudulent. The models consist of a recurrent neural network (RNN) with 2 layers of long short-term memory (LSTM) or gated recurrent unit (GRU), 200 units in each layer, followed by a dense layer. There is one output, which is Fraud/Non-fraud. A sequence of 7 transactions is used as the input to model. In a transactional environment such as z/OS CICS, new data is generated from card terminal transactions. The transaction is received by a z/OS application that then must process it. As part of this processing, validation occurs. This can include the use of AI to provide insight on whether the transaction is potentially fraudulent. The TensorFlow saved models were converted to the ONNX format using the tf2onnx 1.10.0 library and are also included in this repo. The models were converted using the following template: import tf2onnx spec = (tf.TensorSpec((7, 16, 220), tf.float32, name=\"input\"),) output_path = new_model.name + \".onnx\" onnx_model = tf2onnx.convert.from_keras(new_model, spec, output_path=output_path) Environment: \u00b6 s390x python version 3.6.9 pandas version 1.0.1 numpy version 1.16.2 scikit-learn version 0.22.1 sklearn-pandas version 1.8.0 TensorFlow version 2.1.0 The dataset used in this repo can be found here: \u00b6 https://github.com/IBM/TabFormer/tree/main/data/credit_card License \u00b6 If you would like to see the detailed LICENSE click here .","title":"Index"},{"location":"ai-on-z-fraud-detection/#scope","text":"This repository provides TensorFlow source code for building and training credit card fraud models using an LSTM and a GRU.","title":"Scope"},{"location":"ai-on-z-fraud-detection/#summary","text":"The models included in this repository are multi-layer LSTM or GRU models that analyze time series data to predict whether a credit card transaction is fraudulent. The models consist of a recurrent neural network (RNN) with 2 layers of long short-term memory (LSTM) or gated recurrent unit (GRU), 200 units in each layer, followed by a dense layer. There is one output, which is Fraud/Non-fraud. A sequence of 7 transactions is used as the input to model. In a transactional environment such as z/OS CICS, new data is generated from card terminal transactions. The transaction is received by a z/OS application that then must process it. As part of this processing, validation occurs. This can include the use of AI to provide insight on whether the transaction is potentially fraudulent. The TensorFlow saved models were converted to the ONNX format using the tf2onnx 1.10.0 library and are also included in this repo. The models were converted using the following template: import tf2onnx spec = (tf.TensorSpec((7, 16, 220), tf.float32, name=\"input\"),) output_path = new_model.name + \".onnx\" onnx_model = tf2onnx.convert.from_keras(new_model, spec, output_path=output_path)","title":"Summary"},{"location":"ai-on-z-fraud-detection/#environment","text":"s390x python version 3.6.9 pandas version 1.0.1 numpy version 1.16.2 scikit-learn version 0.22.1 sklearn-pandas version 1.8.0 TensorFlow version 2.1.0","title":"Environment:"},{"location":"ai-on-z-fraud-detection/#the-dataset-used-in-this-repo-can-be-found-here","text":"https://github.com/IBM/TabFormer/tree/main/data/credit_card","title":"The dataset used in this repo can be found here:"},{"location":"ai-on-z-fraud-detection/#license","text":"If you would like to see the detailed LICENSE click here .","title":"License"},{"location":"ai-on-z-samples/","text":"ai-on-z-samples \u00b6 Scope \u00b6 This repository contains small, useful examples that serve to demonstrate some of the interesting technologies available for use on IBM Z and LinuxONE systems. Samples in this project: \u00b6 TensorFlow Serving on zCX and z/OS simple app example. ONNX model export and conversion examples Notes \u00b6 If you have any questions or issues you can create a new [issue here][issues]. If you have created a sample that you would like to share, please do so - pull requests are very welcome! Ideally create a topic branch for every contribution or change you would like to suggest. For example: Fork the repo Create your feature branch ( git checkout -b my-new-feature ) Commit your changes ( git commit -am 'Added some feature' ) Push to the branch ( git push origin my-new-feature ) Create new Pull Request License \u00b6 If you would like to see the detailed LICENSE click here . # # Copyright 2020- IBM Inc. All rights reserved # SPDX-License-Identifier: Apache2.0 #","title":"Index"},{"location":"ai-on-z-samples/#ai-on-z-samples","text":"","title":"ai-on-z-samples"},{"location":"ai-on-z-samples/#scope","text":"This repository contains small, useful examples that serve to demonstrate some of the interesting technologies available for use on IBM Z and LinuxONE systems.","title":"Scope"},{"location":"ai-on-z-samples/#samples-in-this-project","text":"TensorFlow Serving on zCX and z/OS simple app example. ONNX model export and conversion examples","title":"Samples in this project:"},{"location":"ai-on-z-samples/#notes","text":"If you have any questions or issues you can create a new [issue here][issues]. If you have created a sample that you would like to share, please do so - pull requests are very welcome! Ideally create a topic branch for every contribution or change you would like to suggest. For example: Fork the repo Create your feature branch ( git checkout -b my-new-feature ) Commit your changes ( git commit -am 'Added some feature' ) Push to the branch ( git push origin my-new-feature ) Create new Pull Request","title":"Notes"},{"location":"ai-on-z-samples/#license","text":"If you would like to see the detailed LICENSE click here . # # Copyright 2020- IBM Inc. All rights reserved # SPDX-License-Identifier: Apache2.0 #","title":"License"},{"location":"ai-on-z-samples/CONTRIBUTING/","text":"Contributing In General \u00b6 Our project welcomes external contributions. If you have an itch, please feel free to scratch it. To contribute code or documentation, please submit a pull request . A good way to familiarize yourself with the codebase and contribution process is to look for and tackle low-hanging fruit in the issue tracker . /* Copyright <holder> All Rights Reserved. SPDX-License-Identifier: Apache-2.0 */","title":"CONTRIBUTING"},{"location":"ai-on-z-samples/CONTRIBUTING/#contributing-in-general","text":"Our project welcomes external contributions. If you have an itch, please feel free to scratch it. To contribute code or documentation, please submit a pull request . A good way to familiarize yourself with the codebase and contribution process is to look for and tackle low-hanging fruit in the issue tracker . /* Copyright <holder> All Rights Reserved. SPDX-License-Identifier: Apache-2.0 */","title":"Contributing In General"},{"location":"ai-on-z-samples/MAINTAINERS/","text":"MAINTAINERS \u00b6 Andrew M. Sica - andrewsi@us.ibm.com Steve Lafalce - slafalce@us.ibm.com","title":"MAINTAINERS"},{"location":"ai-on-z-samples/MAINTAINERS/#maintainers","text":"Andrew M. Sica - andrewsi@us.ibm.com Steve Lafalce - slafalce@us.ibm.com","title":"MAINTAINERS"},{"location":"ai-on-z-samples/onnx-conversion/","text":"Exporting or converting a model to the ONNX format \u00b6 This project contains some simple jupyter notebook examples demonstrating ONNX model conversion. This includes: - Exporting a simple model from Pytorch to ONNX format. - Converting a tensorflow model to ONNX, using tensorflow-onnx . These examples will require you install needed packages. This is not done as part of the notebook. There are numerous additional examples and guidance available, not only for Pytorch and TensorFlow, but for other frameworks as well. This includes: - Building, exporting or converting a model here - tensorflow-onnx examples - pytorch guidance and examples On IBM Z and LinuxONE, you can run these models using ONNX-MLIR . For z/OS users, we recommend you try Watson Machine Learning for z/OS Trial edition, available here .","title":"Exporting or converting a model to the ONNX format"},{"location":"ai-on-z-samples/onnx-conversion/#exporting-or-converting-a-model-to-the-onnx-format","text":"This project contains some simple jupyter notebook examples demonstrating ONNX model conversion. This includes: - Exporting a simple model from Pytorch to ONNX format. - Converting a tensorflow model to ONNX, using tensorflow-onnx . These examples will require you install needed packages. This is not done as part of the notebook. There are numerous additional examples and guidance available, not only for Pytorch and TensorFlow, but for other frameworks as well. This includes: - Building, exporting or converting a model here - tensorflow-onnx examples - pytorch guidance and examples On IBM Z and LinuxONE, you can run these models using ONNX-MLIR . For z/OS users, we recommend you try Watson Machine Learning for z/OS Trial edition, available here .","title":"Exporting or converting a model to the ONNX format"},{"location":"ai-on-z-samples/tf-zcx-zos/","text":"Demonstrating interaction between z/OS and TensorFlow Serving \u00b6 This project intends to demonstrate a call to TensorFlow Serving using REST API from a simple z/OS Java app. The purpose is to create a simple and easily deployable scenario that can be used on z/OS to understand serving concepts. This model performns a matrix multiplication of a [1,5] input tensor by a [5,1] weights tensor, where all weights are defined with a value of 1. This results in an output tensor shape of [1,1]. For example, with this model an input tensor of [[1,2,3,4,5]] is multiplied by a weights tensor of [[1],[1],[1],[1],[1]], resulting in a value of [[15.]] Note that since this project is intended for deployment to z/OS, we are avoiding managing dependecies through sub-moduling or Maven/Ant. The intent is to quickly try this project out without installing additional software. Required Jar files can be pulled from the references below. Deploying TensorFlow Serving on z/OS Container Extensions \u00b6 TensorFlow Serving can be obtained from the IBM Container Image Repository or built from source for Linux on Z IBM Container Image Repository Source Details on the TFServing API can be found here: https://www.tensorflow.org/tfx/serving/api_rest To deploy the example model, you can follow this procedure: SFTP the TensorFlow saved model to zCX. This should be the model folder and all subfolders. The saved model can be found in the model subdirectory of this project. The notebook used to create the model is simplemm.ipynb Create a new docker volume. e.g., docker volume create tfmodels tfmodels is the volume name we create to use in subsequent steps Copy the model directory into the docker volume. One approach is to create a simple container using the volume to allow a docker cp: docker container create --name tfsimple -v tfmodels:/models simple_image docker cp <host_model_dir> tfsimple:/models tfsimple is the container name we create to facilitate the copy via docker CP. simple_image can be any base image, and it can be deleted after this copy. models is a directory we choose to copy the model into. Run the TFServing image: - docker run -d --rm -p 8507:8501 -v tfmodels:/models -e MODEL_NAME=<model_name> <image id> - 8501 is the default TFServing REST port. Here it is mapped to zCX port 8507. - model_name is the TensorFlow model name; this is commonly the directory name that holds the saved_model.pb file Updating and deploying the z/OS application \u00b6 First, deploy the project to your host system. This program is intended for Unix environments. Suggestion on how to get github projects to z/OS can be found here: https://github.com/IBM/IBM-Z-zOS The following Jar files must be in the project root directory; Apache Commons Logging: commons-logging-1.1.3.jar Apache HttpClient: httpclient-4.5.13.jar Apache Httpcore: httpcore-4.4.14.jar Json Processing API javax.json-1.0.jar We suggest using SFTP to transmit the jars to the z/OS environment. Note: If different versions are used, update the Makefile to reference the correect version. run make to build compile the .java files issue the following command to try a TensorFlow Serving request: make run HOSTIP=tf-serve-ip PORT=tf-serv-port MODEL_DIR=model-dir PAYLOAD=input-tensor tf-serve-ip is the IP address of the server or instance hosting TensorFlow Serving tf-serv-port is the TF Serving REST port model-dir is the model path, which should typically be /v1/models/simplemm for the sample model. input-tensor consists of 5 comma separated decimal values. For example, if we mapped the TFServing REST port to 8507, we would use something like this (changing the IP address to one in use by zCX): make run HOSTIP=127.0.0.1 PORT=8507 MODEL_DIR=/v1/models/simplemm PAYLOAD=1.0,2.0,3.0,4.0,5.0 In addition to verbose messages, the result for test would show: { \"predictions\": [[15.0] ] }","title":"Demonstrating interaction between z/OS and TensorFlow Serving"},{"location":"ai-on-z-samples/tf-zcx-zos/#demonstrating-interaction-between-zos-and-tensorflow-serving","text":"This project intends to demonstrate a call to TensorFlow Serving using REST API from a simple z/OS Java app. The purpose is to create a simple and easily deployable scenario that can be used on z/OS to understand serving concepts. This model performns a matrix multiplication of a [1,5] input tensor by a [5,1] weights tensor, where all weights are defined with a value of 1. This results in an output tensor shape of [1,1]. For example, with this model an input tensor of [[1,2,3,4,5]] is multiplied by a weights tensor of [[1],[1],[1],[1],[1]], resulting in a value of [[15.]] Note that since this project is intended for deployment to z/OS, we are avoiding managing dependecies through sub-moduling or Maven/Ant. The intent is to quickly try this project out without installing additional software. Required Jar files can be pulled from the references below.","title":"Demonstrating interaction between z/OS and TensorFlow Serving"},{"location":"ai-on-z-samples/tf-zcx-zos/#deploying-tensorflow-serving-on-zos-container-extensions","text":"TensorFlow Serving can be obtained from the IBM Container Image Repository or built from source for Linux on Z IBM Container Image Repository Source Details on the TFServing API can be found here: https://www.tensorflow.org/tfx/serving/api_rest To deploy the example model, you can follow this procedure: SFTP the TensorFlow saved model to zCX. This should be the model folder and all subfolders. The saved model can be found in the model subdirectory of this project. The notebook used to create the model is simplemm.ipynb Create a new docker volume. e.g., docker volume create tfmodels tfmodels is the volume name we create to use in subsequent steps Copy the model directory into the docker volume. One approach is to create a simple container using the volume to allow a docker cp: docker container create --name tfsimple -v tfmodels:/models simple_image docker cp <host_model_dir> tfsimple:/models tfsimple is the container name we create to facilitate the copy via docker CP. simple_image can be any base image, and it can be deleted after this copy. models is a directory we choose to copy the model into. Run the TFServing image: - docker run -d --rm -p 8507:8501 -v tfmodels:/models -e MODEL_NAME=<model_name> <image id> - 8501 is the default TFServing REST port. Here it is mapped to zCX port 8507. - model_name is the TensorFlow model name; this is commonly the directory name that holds the saved_model.pb file","title":"Deploying TensorFlow Serving on z/OS Container Extensions"},{"location":"ai-on-z-samples/tf-zcx-zos/#updating-and-deploying-the-zos-application","text":"First, deploy the project to your host system. This program is intended for Unix environments. Suggestion on how to get github projects to z/OS can be found here: https://github.com/IBM/IBM-Z-zOS The following Jar files must be in the project root directory; Apache Commons Logging: commons-logging-1.1.3.jar Apache HttpClient: httpclient-4.5.13.jar Apache Httpcore: httpcore-4.4.14.jar Json Processing API javax.json-1.0.jar We suggest using SFTP to transmit the jars to the z/OS environment. Note: If different versions are used, update the Makefile to reference the correect version. run make to build compile the .java files issue the following command to try a TensorFlow Serving request: make run HOSTIP=tf-serve-ip PORT=tf-serv-port MODEL_DIR=model-dir PAYLOAD=input-tensor tf-serve-ip is the IP address of the server or instance hosting TensorFlow Serving tf-serv-port is the TF Serving REST port model-dir is the model path, which should typically be /v1/models/simplemm for the sample model. input-tensor consists of 5 comma separated decimal values. For example, if we mapped the TFServing REST port to 8507, we would use something like this (changing the IP address to one in use by zCX): make run HOSTIP=127.0.0.1 PORT=8507 MODEL_DIR=/v1/models/simplemm PAYLOAD=1.0,2.0,3.0,4.0,5.0 In addition to verbose messages, the result for test would show: { \"predictions\": [[15.0] ] }","title":"Updating and deploying the z/OS application"},{"location":"zDNN/","text":"zDNN API Reference \u00b6 Contacts \u00b6 Nicholas Marion (nmarion@us.ibm.com) Andreas Krebbel (krebbel@linux.ibm.com) Version \u00b6 0.4.0 Table of Contents \u00b6 Overview Environment Common Data Types and Structs Version Information zDNN zTensor General zTensor Requirements Concatenated zTensor Requirements zDNN Tensor Descriptors zDNN Data Layouts zDNN Data Formats zDNN Data Types zDNN Statuses Runtime Environment Variables API Reference Support Functions Data Transformation Operations Element-wise Activation Normalization Matmul with Operation Matmul Broadcast with Operation LSTM GRU Average Pool 2D Max Pool 2D Convolution 2D Convenience Functions Usage Examples Overview \u00b6 Deep Learning Library - the deep learning library support (zDNN) is the SW enablement technology provided by IBM to meet the following requirements: Specialized-function-assist instructions are intended to provide performance improvements for specific operations used in software libraries, utilities, and operating system (OS) services. The facilities and instructions described as specialized-function-assist instructions may be replaced or removed in the future. As such, the IBM recommendation for these instructions is that a software library or operating system function be used instead of directly accessing the instructions. This is the function provided by zDNN. zAIU has very complex data layout requirements; these requirements arrange the tensor to enhance the performance characteristics of the operations. zDNN will format the tensor appropriately on behalf of the caller, and it will do so using an optimized approach. For deep learning operations, zAIU requires the use of an internal data type (DLFLOAT16). This is a 2-byte data type, similar in concept to Brain float (BFLOAT); that is, it is an AI optimized format that is used to speed up training and inference (from 4-byte formats) while minimizing the loss of accuracy at inference time. The zDNN library will provide a set of APIs that an exploiter will utilize to drive the desired request. zDNN will be available on both z/OS and Linux on Z; the inclusion of Linux on Z provides particular benefit, as it will allow us to enable acceleration in frameworks for z/OS via z/OS Container Extensions (zCX). Environment \u00b6 z/OS: Problem state AMODE64 XPLINK Alignment requirements \u00b6 AIU Op Limits \u00b6 This implies a zDNN limitation as well at this point. For all ops: Number of elements in any dimension must not exceed the value returned by zdnn_get_nnpa_max_dim_idx_size() Total number of bytes required for storing a transformed tensor must not exceed the value returned by zdnn_get_nnpa_max_tensor_size() Application interfaces for zAIU Enterprise Neural Network Inference \u00b6 zDNN General \u00b6 The zDNN deep learning library provides the standard IBM Z software interface to the zAIU. This IBM-provided C library provides a set of functions that handle the data transformation requirements of the AIU and provide wrapper functions for the NNPA instruction primitives. The zDNN functions use the following criteria to determine if zAIU can be used to accelerate a deep learning primitive: Neural Network Processing Assist (NNPA) facility indicator in the system STFLE output. Output of the NNPA-QAF (Query Available Functions) request. Using zDNN \u00b6 To use the IBM-provided zDNN C library for the NNPA instruction, follow these steps: Link or re-link applications to use the IBM-provided zDNN. The IBM-provided zDNN is a library file in the z/OS UNIX System Services file system and can be statically or dynamically linked into your applications. The paths for the zDNN archive file and the zDNN header files are: z/OS (LE required): Path for 64-bit dynamic library files: /lib/libzdnn.so /lib/libzdnn.x Path for the zDNN header files: /usr/include/ The XL C/C++ compiler and the z/OS Language Environment provide various environment variables to control processing, in addition to the variables provided by the zDNN library itself. Use the environment variable _CEE_RUNOPTS to specify invocation Language Environment runtime options. For more information about using the environment variable _CEE_RUNOPTS and other C and LE variables, see z/OS XL C/C++ Programming Guide. For environment variables accepted by the zDNN library, see Runtime Environment Variables . Linux on Z: On Linux on Z we expect to ship source as well a package-installable library and header. The library installation will conform to the standards of the packaging method chosen. Common Types and Structs \u00b6 Include Files: zdnn.h Version Information \u00b6 Back to Table of Contents #define ZDNN_VERSION \"0.4.0\" #define ZDNN_VERNUM 0x000400 // 0x[major][minor][patch] #define ZDNN_VER_MAJOR 0 #define ZDNN_VER_MINOR 4 #define ZDNN_VER_PATCH 0 zDNN major version ( ZDNN_VER_MAJOR ) will be incremented if any backwards incompatible changes are introduced to the API. It may also include minor and patch level changes. Patch and minor version will be reset to 0 when major version is incremented. zDNN minor version ( ZDNN_VER_MINOR ) will be incremented if new, backwards compatible functionalities are introduced to the API or if any API functionalities are marked as deprecated. It may also include patch level changes. Patch version will be reset to 0 when minor version is incremented. zDNN patch version ( ZDNN_VER_PATCH ) will be incremented if only backwards compatible bug fixes are introduced. A bug fix being defined as an internal change that fixes incorrect behavior. Functions for checking version incompatibility with the zDNN load library are provided and described in the Support Functions section. zDNN zTensor \u00b6 Back to Table of Contents typedef struct zdnn_ztensor { zdnn_tensor_desc *pre_transformed_desc; // tensor's shape information before transformation zdnn_tensor_desc *transformed_desc; // transformed tensor's shape information uint64_t buffer_size; // tensor size in bytes void *buffer; // pointer to the tensor in memory bool is_transformed; // indicator if data in buffer has been transformed char reserved[31]; // not currently used, should contain zeros. } zdnn_ztensor; General zTensor Requirements \u00b6 Back to Table of Contents buffer requirements: Calling zdnn_init_ztensor_with_malloc automatically allocates and sets a valid buffer for a tensor. buffer field must point to storage allocated of sufficient size to contain the transformed tensor data described by the its transformed_desc field. Calling zdnn_getsize_ztensor with the tensor's transformed_desc returns the required size. Start of buffer field must be 4k aligned. reserved should contain zeros, otherwise the program may not operate compatibly in the future. Calling zdnn_init_ztensor or zdnn_init_ztensor_with_malloc will set reserved to zeros. Concatenated zTensor Requirements \u00b6 Back to Table of Contents For use with weights/biases/hidden-weights/hidden-biases RNN-gates tensors. You must use zdnn_generate_transformed_desc_concatenated with the appropriate concatenation info Do not use zdnn_generate_transformed_desc with concatenated tensors The pre-transformed shape dimensions should not include the concatenation. Thus, the pre-transformed shape should be that of a single gate, not the shape of the combined gates Afterward transform with zdnn_transform_ztensor as normal Must follow general tensor requirements zDNN Tensor Descriptors \u00b6 Back to Table of Contents typedef struct zdnn_tensor_desc { zdnn_data_layouts layout; // data layout zdnn_data_formats format; // internal use only zdnn_data_types type; // data type uint32_t dim4; // number of elements in outermost dimension uint32_t dim3; // ... outer dimension uint32_t dim2; // ... inner dimension uint32_t dim1; // number of elements in innermost dimension } zdnn_tensor_desc; Programming Notes \u00b6 Helper methods zdnn_init_pre_transformed_desc and zdnn_generate_transformed_desc or zdnn_generate_transformed_desc_concatenated will set the correct dims based on the layout and format. The layout of the tensor descriptor affects the expected order of the dims. For example: For tensors with less than 4 dimensions, unspecified dims: In the pre_transformed_desc are ignored. For example a ZDNN_3D expects values in dim4, dim3, and dim2. In the transformed_desc \"unused\" dims must be 1. A ZDNN_NCHW expects dims such that dim4 = N, dim3 = H, dim2 = W, dim1 = C A ZDNN_HWCK expects dims such that dim4 = W, dim3 = W, dim2 = C, dim1 = K The format changes the expected dims order for ZDNN_4D tensors layouts ZDNN_FORMAT_4DFEATURE expects dims such that dim4 = N, dim3 = H, dim2 = W, dim1 = C ZDNN_FORMAT_4DKERNEL expects dims such that dim4 = H, dim3 = W, dim2 = C, dim1 = K zDNN Data Layouts \u00b6 Back to Table of Contents The following are layouts for zDNN ztensor descriptors. These indicate the number and order of dimensions to expect for the ztensor data. typedef enum zdnn_data_layouts { ZDNN_1D, // 1d tensor ZDNN_2D, // 2d tensor ZDNN_2DS, // represents special 2D tensors required by LSTM/GRU ZDNN_3D, // 3d tensor ZDNN_3DS, // represents special 3D tensors required by // LSTM/GRU/Softmax/Matmul ZDNN_ZRH, // represents (update, reset, hidden) used by GRU ZDNN_4D, // 4d tensor ZDNN_4DS, // represents special 4D tensors required by LSTM/GRU output ZDNN_NHWC, // 4d feature tensor in NHWC ZDNN_NCHW, // 4d feature tensor in NCHW ZDNN_FICO, // represents (forget, input, cell, output) used by LSTM ZDNN_HWCK, // 4d kernel CNN tensor ZDNN_BIDIR_ZRH, // ZRH variant to work with bidirectional LSTM/GRU output ZDNN_BIDIR_FICO // FICO variant to work with bidirectional LSTM/GRU output } zdnn_data_layouts; Some layouts also indicate special re-arrangement of the data during ztensor transformation. ZDNN_2DS - The outermost dimension of the original shape is promoted to dim4 during transformation. For example, a shape of (a, b) becomes [a, 1, 1, b] (dim4, dim3, dim2, dim1) in the transformed_desc ZDNN_3DS - The outermost dimension of the original shape is promoted to dim4 during transformation. For example, a shape of (a, b, c) becomes [a, 1, b, c] (dim4, dim3, dim2, dim1) in the transformed_desc ZDNN_4DS - Arrangement for RNN output tensor The followings are set automatically in transformed_desc based on info when calling zdnn_generate_transformed_desc_concatenated() : ZDNN_ZRH/FICO - During transformation, the RNN input gates data are concatenated on the innermost dimension. Supported with pre_transformed_layout of ZDNN_2DS or ZDNN_3DS . ZDNN_BIDIR_ZRH/FICO - Similar to ZDNN_ZRH/FICO , used when: transforming RNN input weight gate data, and the input tensor for the current RNN layer is a bidirectional RNN output from a previous RNN layer zDNN Data Formats \u00b6 Back to Table of Contents typedef enum zdnn_data_formats { ZDNN_FORMAT_4DFEATURE, // tensor in AIU data layout format 0 ZDNN_FORMAT_4DKERNEL, // tensor in AIU data layout format 1 } zdnn_data_formats; zDNN Data Types \u00b6 Back to Table of Contents typedef enum zdnn_data_types { ZDNN_DLFLOAT16, // 16-bit deep learning format BFLOAT, // Brain floating point format FP16, // 16-bit IEEE-754 floating point format FP32, // 32-bit IEEE-754 floating point format } zdnn_data_types; zDNN Statuses \u00b6 Back to Table of Contents Mnemonic Constant Value Meaning ZDNN_OK 0x00000000 Success. Warning Statuses \u00b6 Mnemonic Constant Value Meaning ZDNN_ELEMENT_RANGE_VIOLATION 0x00020001 AIU operation resulted in data that was out of the normal range. Note: ZDNN_ELEMENT_RANGE_VIOLATION indicates a range violation occurred for the AIU operation based on the data in the tensors. This usually indicates an overflow of the NNPA internal data type, but can also be associated with operation specific errors, such as \"divide by zero\". See the \"z/Architecture Principles of Operation\" for information about range violation on the operation that encountered the violation. General Failing Statuses \u00b6 Mnemonic Constant Value Meaning ZDNN_INVALID_SHAPE* 0x00040001 Invalid shape information in one (or more) of the input/output tensor(s). ZDNN_INVALID_LAYOUT 0x00040002 Invalid layout information in one (or more) of the input/output tensor(s). ZDNN_INVALID_TYPE* 0x00040003 Invalid type information in one (or more) of the input/output tensor(s). ZDNN_INVALID_FORMAT* 0x00040004 Invalid format information in one (or more) of the input/output tensor(s). ZDNN_INVALID_DIRECTION 0x00040005 Invalid RNN direction. ZDNN_INVALID_CONCAT_INFO 0x00040006 Invalid concatenation info. ZDNN_INVALID_STRIDE_PADDING* 0x00040007 Invalid padding type parameter for current strides. ZDNN_INVALID_STRIDES* 0x00040008 Invalid stride height or width parameter. ZDNN_MISALIGNED_PARMBLOCK* 0x00040009 NNPA parameter block is not on double word boundary. ZDNN_INVALID_CLIPPING_VALUE 0x0004000A Invalid clipping for the specified operation. ZDNN_ALLOCATION_FAILURE 0x00100001 Can not allocate storage. ZDNN_INVALID_BUFFER 0x00100002 Buffer address is NULL or not on 4K-byte boundary or insufficient buffer size. ZDNN_CONVERT_FAILURE 0x00100003 Floating point data conversion failure. ZDNN_INVALID_STATE 0x00100004 Invalid zTensor state. ZDNN_UNSUPPORTED_AIU_EXCEPTION 0x00100005 AIU operation returned an unexpected exception. Note: *In certain scenarios, these statuses are returned only if ZDNN_ENABLE_PRECHECK is enabled. When not enabled, these scenarios will lead to abnormal program termination. Hardware Statuses \u00b6 The following statuses indicate issues returned from the hardware. Mnemonic Constant Value Meaning ZDNN_UNSUPPORTED_PARMBLOCK 0x000C0001 NNPA parameter block format is not supported by the model. ZDNN_UNAVAILABLE_FUNCTION 0x000C0002 Specified NNPA function is not defined or installed on the machine. ZDNN_UNSUPPORTED_FORMAT 0x000C0010 Specified tensor data layout format is not supported. ZDNN_UNSUPPORTED_TYPE 0x000C0011 Specified tensor data type is not supported. ZDNN_EXCEEDS_MDIS 0x000C0012 Tensor dimension exceeds maximum dimension index size (MDIS). ZDNN_EXCEEDS_MTS 0x000C0013 Total number of bytes in tensor exceeds maximum tensor size. (MTS). ZDNN_MISALIGNED_TENSOR 0x000C0014 Tensor address is not on 4K-byte boundary. ZDNN_MISALIGNED_SAVEAREA 0x000C0015 Function specific save area address is not on 4K-byte boundary. The meaning of the following hardware statuses vary based on operation. See the operation that returned the status for the specific meaning. Mnemonic Constant Value Meaning ZDNN_FUNC_RC_F000 0x000CF000 Function specific response code (F000). ZDNN_FUNC_RC_F001 0x000CF001 Function specific response code (F001). ZDNN_FUNC_RC_F002 0x000CF002 Function specific response code (F002). ZDNN_FUNC_RC_F003 0x000CF003 Function specific response code (F003). ZDNN_FUNC_RC_F004 0x000CF004 Function specific response code (F004). ZDNN_FUNC_RC_F005 0x000CF005 Function specific response code (F005). ZDNN_FUNC_RC_F006 0x000CF006 Function specific response code (F006). ZDNN_FUNC_RC_F007 0x000CF007 Function specific response code (F007). ZDNN_FUNC_RC_F008 0x000CF008 Function specific response code (F008). ZDNN_FUNC_RC_F009 0x000CF009 Function specific response code (F009). Runtime Environment Variables \u00b6 Back to Table of Contents ZDNN_ENABLE_PRECHECK : true/false If set to true , tensor integrity prechecks are run before issuing NNPA operations. Enabling precheck may impact performance. Enable to debug issues which cause hardware exceptions that otherwise would result in abnormal program termination. ZDNN_STATUS_DIAG : nnnnnnnn (decimal) or 0xnnnnnnnn (hexadecimal) Prints or produces diagnostic information whenever zDNN status code is equal to the specified value. Only one status value can be specified. The following are only available when the zDNN library was built with ZDNN_CONFIG_DEBUG enabled. ZDNN_LOGLEVEL : off/fatal/error/warn/info/debug/trace Sets logging facility's output level ZDNN_LOGMODULE : module name(s) Produces log output only when the issuer's module name is in the list. You may specify multiple module names by separating them with either commas or spaces. Programming Notes \u00b6 Environment variables settings are checked during initial library load by zdnn_init . To change environment variable settings afterward, zdnn_init must be called again manually. API Reference \u00b6 Back to Table of Contents Support Functions Data Transformation Operations Convenience Functions Support Functions \u00b6 Back to Table of Contents Initialization Query Get Size Initialize pre-transformed tensor descriptor Generate transformed tensor descriptor Generate concatenated transformed tensor descriptor Initialize zTensor Initialize zTensor with memory allocate Reset zTensor Allocate memory for zTensor De-allocate memory for zTensor Retrieve status message of the status code Reshape zTensor Check if version is runnable Get maximum runnable version zdnn_init \u00b6 Description \u00b6 Initialize the zDNN library. This sends an NNPA_QAF to query the NNPA and loads the current environment variable settings. This needs to be invoked at least once if zDNN library is statically-linked. It is automatically invoked if zDNN library is dynamically loaded. Format \u00b6 void zdnn_init(); Parameters \u00b6 None Returns \u00b6 None zdnn_get_nnpa_max_dim_idx_size \u00b6 Description \u00b6 Retrieve the maximum dimension index size value currently supported by the AIU from zDNN's internal memory. Format \u00b6 uint32_t zdnn_get_nnpa_max_dim_idx_size(); Parameters \u00b6 None Returns \u00b6 Maximum dimension index size supported by the AIU zdnn_get_nnpa_max_tensor_size \u00b6 Description \u00b6 Retrieve the maximum tensor size value (number of bytes required for storing a transformed tensor) currently supported by the AIU from zDNN's internal memory. Format \u00b6 uint64_t zdnn_get_nnpa_max_tensor_size(); Parameters \u00b6 None Returns \u00b6 Maximum tensor size supported by the AIU zdnn_is_nnpa_installed \u00b6 Description \u00b6 Interrogates the hardware to determine if the NNPA and NNP-internal data type (DLFLOAT16) conversion instructions are installed. Use this function during application initialization to determine whether the AIU hardware is available. Format \u00b6 bool zdnn_is_nnpa_installed(); Parameters \u00b6 None. Returns \u00b6 true if NNPA and zdnn conversion instructions are installed, false otherwise. zdnn_is_nnpa_function_installed \u00b6 Description \u00b6 Query, from zDNN internal memory, if requested NNPA functions are available. Format \u00b6 bool zdnn_is_nnpa_function_installed(int count, ...); Parameters \u00b6 int count number of NNPA functions to check ... (additional arguments) Function names separated by commas, e.g., NNPA_MUL, NNPA_MIN NNPA_QAF NNPA_ADD NNPA_SUB NNPA_MUL NNPA_DIV NNPA_MIN NNPA_MAX NNPA_LOG NNPA_EXP NNPA_RELU NNPA_TANH NNPA_SIGMOID NNPA_SOFTMAX NNPA_BATCHNORMALIZATION NNPA_MAXPOOL2D NNPA_AVGPOOL2D NNPA_LSTMACT NNPA_GRUACT NNPA_CONVOLUTION NNPA_MATMUL_OP NNPA_MATMUL_OP_BCAST23 Returns \u00b6 true if all queried formats are installed or if count is zero, false otherwise. zdnn_is_nnpa_parmblk_fmt_installed \u00b6 Description \u00b6 Query, from zDNN internal memory, if requested parameter block formats are installed. Format \u00b6 bool zdnn_is_nnpa_parmblk_fmt_installed(int count, ...); Parameters \u00b6 int count number of NNPA parameter block formats to check ... (additional arguments) NNPA parameter block formats separated by commas NNPA_PARMBLKFORMAT_0 Returns \u00b6 true if all queried formats are installed or if count is zero, false otherwise. zdnn_is_nnpa_datatype_installed \u00b6 Description \u00b6 Query, from zDNN internal memory, if requested NNPA data type are installed. Format \u00b6 bool zdnn_is_nnpa_datatype_installed(uint16_t types_bitmask); Parameters \u00b6 uint16_t types_bitmask OR'd type bitmasks as defined in zdnn_query_datatypes enum QUERY_DATATYPE_INTERNAL1 Returns \u00b6 true if all queried data types are installed, false otherwise. zdnn_is_nnpa_layout_fmt_installed \u00b6 Description \u00b6 Query, from zDNN internal memory, if requested NNPA data layout format are installed. Format \u00b6 bool zdnn_is_nnpa_layout_fmt_installed(uint32_t layout_bitmask); Parameters \u00b6 uint32_t layout_bitmask OR'd layout bitmasks as defined in zdnn_query_layoutfmts enum QUERY_LAYOUTFMT_4DFEATURE QUERY_LAYOUTFMT_4DKERNEL Returns \u00b6 true if all queried data layouts are installed, false otherwise. zdnn_is_nnpa_conversion_installed \u00b6 Description \u00b6 Query, from zDNN internal memory, if requested NNPA data-type to/from BFP format conversions are installed. Format \u00b6 bool zdnn_is_nnpa_conversion_installed(nnpa_data_type type, uint16_t format_bitmask); Parameters \u00b6 nnpa_data_type type NNPA data-type number as defined in nnpa_data_type enum NNPA_DATATYPE_1 uint16_t format_bitmask OR'd BFP format bitmasks as defined in zdnn_query_bfpfmts enum QUERY_BFPFMT_TINY (FP16) QUERY_BFPFMT_SHORT (FP32/BFLOAT) Returns \u00b6 true if all queried conversions are installed, false otherwise. zdnn_get_library_version \u00b6 Description \u00b6 Retrieve library version number as a 32-bit hex value ( 0x00[major][minor][patch] ). Format \u00b6 uint32_t zdnn_get_library_version(); Returns \u00b6 Library version number in 0x00[major][minor][patch] format. zdnn_get_library_version_str \u00b6 Description \u00b6 Retrieve the library version number and build information as a string. Format \u00b6 char *zdnn_get_library_version_str(); Returns \u00b6 Library version number and build information as a string. zdnn_refresh_nnpa_query_result \u00b6 Description \u00b6 Refresh zDNN in-memory query result from zAIU. Format \u00b6 zdnn_status zdnn_refresh_nnpa_query_result(); Parameters \u00b6 None Programming Notes \u00b6 This is called automatically as a part of zdnn_init and should not need to be called directly. Manually refreshing query results before making other zdnn_query_* calls may noticeably impact performance. Returns zdnn_status indications \u00b6 ZDNN_OK ZDNN_UNAVAILABLE_FUNCTION zdnn_getsize_ztensor \u00b6 Description \u00b6 Used to determine the buffer size required for the transformed tensor (including concatenated) in zDNN transformed format. Requires tensor descriptor ( zdnn_tensor_desc ) with transformed shape information. Format \u00b6 uint64_t zdnn_getsize_ztensor(const zdnn_tensor_desc *tfrmd_desc); Parameters \u00b6 zdnn_tensor_desc *tfrmd_desc Contains transformed information about the shape, layout and data type. Returns zdnn_status indications \u00b6 required buffer size in bytes zdnn_init_pre_transformed_desc \u00b6 Description \u00b6 Initialize tensor descriptor ( zdnn_tensor_desc ) struct with pre-transformed (original) shape information. Format \u00b6 void zdnn_init_pre_transformed_desc(zdnn_data_layouts layout, zdnn_data_types type, zdnn_tensor_desc *pre_tfrmd_desc, ...); Parameters \u00b6 zdnn_data_layouts layout data layout zdnn_data_types type data type zdnn_tensor_desc *pre_tfrmd_desc output zdnn_tensor_desc struct ... (additional arguments) Variadic: number of elements in each dimension in accordance to the layout, in outermost to innermost order Returns \u00b6 None zdnn_generate_transformed_desc \u00b6 Description \u00b6 Generate transformed tensor descriptor information based on supplied pre-transformed tensor descriptor. Format \u00b6 zdnn_status zdnn_generate_transformed_desc( const zdnn_tensor_desc *pre_tfrmd_desc, zdnn_tensor_desc *tfrmd_desc); Parameters \u00b6 zdnn_tensor_desc *pre_tfrmd_desc input tensor descriptor with pre-transformed shape information zdnn_tensor_desc *tfrmd_desc output zdnn_tensor_desc struct zdnn_status indications \u00b6 ZDNN_OK ZDNN_INVALID_LAYOUT - pre-transformed layout is not recognized or is a layout only used for concatenated tensors. zdnn_generate_transformed_desc_concatenated \u00b6 Description \u00b6 Generate concatenated transformed tensor descriptor information for RNN input-gates tensors based on a supplied pre-transformed tensor descriptor. Format \u00b6 zdnn_status zdnn_generate_transformed_desc_concatenated( const zdnn_tensor_desc *pre_tfrmd_desc, zdnn_concat_info info, zdnn_tensor_desc *tfrmd_desc); Parameters \u00b6 zdnn_tensor_desc *pre_tfrmd_desc input tensor descriptor with pre-transformed shape information zdnn_concat_info info Information about how the tensors will be concatenated, consists of the RNN_TYPE, PREV_LAYER and USAGE flags OR'd together: RNN_TYPE flags: RNN_TYPE_LSTM - For LSTM RNN_TYPE_GRU - For GRU PREV_LAYER flags: PREV_LAYER_UNI - Previous RNN layer is uni-directional PREV_LAYER_NONE - Previous layer is not a RNN layer PREV_LAYER_BIDIR - Previous RNN layer is bi-directional USAGE flags: USAGE_WEIGHTS - Concatenate as input weights USAGE_HIDDEN_WEIGHTS - Concatenate as input hidden-weights USAGE_BIASES - Concatenate as input biases USAGE_HIDDEN_BIASES - Concatenate as input hidden-biases zdnn_tensor_desc *tfrmd_desc output zdnn_tensor_desc struct zdnn_status indications \u00b6 ZDNN_OK ZDNN_INVALID_LAYOUT - pre-transformed layout is not recognized or is not supported for concatenated tensors. ZDNN_INVALID_CONCAT_INFO - invalid concatenation information. zdnn_init_ztensor \u00b6 Description \u00b6 Initialize a zdnn_ztensor struct using the pre-transformed and transformed tensor shape information Format \u00b6 void zdnn_init_ztensor(zdnn_tensor_desc *pre_tfrmd_desc, zdnn_tensor_desc *tfrmd_desc, zdnn_ztensor *output); Parameters \u00b6 zdnn_tensor_desc *pre_tfrmd_desc input tensor descriptor with pre-transformed shape information zdnn_tensor_desc *tfrmd_desc input tensor descriptor with transformed shape information zdnn_ztensor *output The zdnn_ztensor struct being initialized. Returns \u00b6 None zdnn_init_ztensor_with_malloc \u00b6 Description \u00b6 Same functionality as zdnn_init_ztensor , and computes the size required for the tensor in the zDNN transformed format and allocates the storage for it. Sets buffer and buffer_size fields within output . Format \u00b6 zdnn_status zdnn_init_ztensor_with_malloc(zdnn_tensor_desc *pre_tfrmd_desc, zdnn_tensor_desc *tfrmd_desc, zdnn_ztensor *output); Parameters \u00b6 zdnn_tensor_desc *pre_tfrmd_desc input tensor descriptor with pre-transformed shape information zdnn_tensor_desc *tfrmd_desc input tensor descriptor with transformed shape information zdnn_ztensor *output The zdnn_ztensor struct being initialized. Returns zdnn_status indications \u00b6 ZDNN_OK ZDNN_INVALID_FORMAT - tfrmd_desc->format is not recognized. ZDNN_INVALID_TYPE - tfrmd_desc->type is not recognized or is a pre_tfrmd_desc type. ZDNN_INVALID_SHAPE - (if any of the following are true) One of tfrmd_desc->dim* dimensions is 0. One of tfrmd_desc->dim* dimensions is greater than zdnn_get_nnpa_max_dim_idx_size . Note: concatenation dimensions have a smaller maximum size. See LSTM or GRU . The total number of tfrmd_desc elements is larger than zdnn_get_nnpa_max_tensor_size . ZDNN_ALLOCATION_FAILURE - Unable to allocate required memory on a 4K boundary. zdnn_reset_ztensor \u00b6 Description \u00b6 Reset a zdnn_ztensor struct for reuse. Note this operation does not set or reset the buffer and buffer_size fields nor free the transformed area storage. Format \u00b6 void zdnn_reset_ztensor(zdnn_ztensor *ztensor); Parameters \u00b6 zdnn_ztensor *output The zdnn_ztensor struct being reset. Returns \u00b6 None zdnn_allochelper_ztensor \u00b6 Description \u00b6 Calculate the size required for the tensor in the zDNN transformed format and allocate the needed storage, satisfying alignment requirements. Sets buffer and buffer_size fields within ztensor . Note that the calling application assumes ownership of this storage and is responsible for freeing it. Format \u00b6 zdnn_status zdnn_allochelper_ztensor(zdnn_ztensor *ztensor); Parameters \u00b6 zdnn_ztensor *ztensor A zdnn_ztensor struct that contains the transformed shape information in the transformed_desc field. Returns zdnn_status indications \u00b6 ZDNN_OK ZDNN_INVALID_FORMAT - ztensor->transformed_desc->format is not recognized. ZDNN_INVALID_TYPE - ztensor->transformed_desc->type is not recognized or is a pre_transformed_desc type. ZDNN_INVALID_SHAPE - (if any of the following are true) One of ztensor->transformed_desc->dim* dimensions is 0. One of ztensor->transformed_desc->dim* dimensions is greater than zdnn_get_nnpa_max_dim_idx_size . Note: concatenation dimensions have a smaller maximum size. See LSTM or GRU . The total number of transformed_desc elements is larger than zdnn_get_nnpa_max_tensor_size . ZDNN_ALLOCATION_FAILURE - Unable to allocate required memory on a 4K boundary. zdnn_free_ztensor_buffer \u00b6 Description \u00b6 Given an input zdnn_ztensor, zdnn_free_ztensor_buffer will free the transformed area storage associated with it. Note that the routine does not free the storage allocated for the zdnn_ztensor struct itself. Format \u00b6 zdnn_status zdnn_free_ztensor_buffer(const zdnn_ztensor *ztensor); Parameters \u00b6 zdnn_ztensor *tensor A zdnn_ztensor struct with field buffer pointing to storage allocated. Returns zdnn_status indications \u00b6 ZDNN_OK ZDNN_INVALID_BUFFER - tensor->buffer is NULL zdnn_get_status_message \u00b6 Description \u00b6 Retrieve status message of the status code Format \u00b6 const char *zdnn_get_status_message(zdnn_status status); Parameters \u00b6 zdnn_status status Status code Returns \u00b6 Pointer to the description string or \"(Status string is not defined.)\" if status is not defined. zdnn_reshape_ztensor \u00b6 Description \u00b6 Reshape and copy buffer content from source zTensor's buffer to destination zTensor's in accordance to destination zTensor's shape. The following conditions must be satisfied: Both tensor's transformed_desc must be fully initialized dest->buffer must be pre-allocated src must be transformed dest must be not already transformed Both transformed_desc->layout must be the same and either NHWC or HWCK Both zTensors must contain equal number of elements Format \u00b6 zdnn_status zdnn_reshape_ztensor(const zdnn_ztensor *src, zdnn_ztensor *dest); Parameters \u00b6 src Source zTensor to copy from dest Destination zTensor to copy to Programming Notes \u00b6 If src and dest have the same transformed_desc->dim1 dimension size, the transformed data is directly copied to the destination without untransformation. If src and dest have different transformed_desc->dim1 dimension sizes, reshaping will internally un-transform the source and then re-transform the values into the destination. Returns \u00b6 ZDNN_OK ZDNN_INVALID_SHAPE - (if any of the following are true) src 's and dest 's transformed_desc->dim* total to different numbers of elements. One of dest->transformed_desc->dim* dimensions is 0. One of dest->transformed_desc->dim* dimensions is greater than zdnn_get_nnpa_max_dim_idx_size . Note: concatenation dimensions have a smaller maximum size. See LSTM or GRU . The total number of dest->transformed_desc-dim* elements is larger than zdnn_get_nnpa_max_tensor_size . ZDNN_INVALID_LAYOUT - (if any of the following are true) src 's and dest 's transformed_desc->layout are not the same. transformed_desc->layout is not ZDNN_NHWC nor ZDNN_HWCK . src->pre_transformed_desc->layout is not recognized or is not a valid pre_transformed_desc layout. dest->pre_transformed_desc->layout is not recognized or is not a valid pre_transformed_desc layout. ZDNN_INVALID_STATE - (if any of the following are true) src is not already transformed. dest is already transformed. ZDNN_INVALID_FORMAT - src->transformed_desc->format is not ZDNN_FORMAT_4DFEATURE . ZDNN_INVALID_TYPE (if any of the following are true) src->pre_transformed_desc->type is not recognized or is a transformed_desc type. dest->pre_transformed_desc->type is not recognized or is a transformed_desc type. dest->transformed_desc->type is not recognized or is a pre_transformed_desc type. ZDNN_INVALID_BUFFER (if any of the following are true) src->buffer is NULL . src->buffer is not on a 4K boundary. dest->buffer is NULL . dest->buffer is not on a 4K boundary. dest->buffer_size is too small to hold transformed values. ZDNN_CONVERT_FAILURE - Values failed to un-transform or transform. zdnn_is_version_runnable \u00b6 Description \u00b6 Check if application built for zDNN version ver_num can be run on the current AIU hardware with the installed zDNN library Format \u00b6 bool zdnn_is_version_runnable(uint32_t ver_num); Parameters \u00b6 ver_num zDNN version number from the application in 0x00[major][minor][patch] form. Typically this is ZDNN_VERNUM used to compile the application Returns \u00b6 true/false zdnn_get_max_runnable_version \u00b6 Description \u00b6 Returns the maximum zDNN version number that the current hardware and installed zDNN library can run together. The returned value means the current runtime environment fully supports zDNN APIs set of that major . minor version and below. Format \u00b6 uint32_t zdnn_get_max_runnable_version(); Parameters \u00b6 None Returns \u00b6 A 32-bit zDNN version number in 0x00[major][minor]FF form. Data Transformation \u00b6 Back to Table of Contents Transform to zTensor Transform to Original zAIU requires the tensor data to be arranged in a format that enhances the performance characteristics of the operations. In this documentation, it is referred to as \"transformed format\". In addition, data conversions are necessary from the common formats (FP32, FP16, BFLOAT) to the internal format (DLFLOAT16) supported by the AIU. Two functions are provided: ' zdnn_transform_ztensor zdnn_transform_ztensor will transform the input tensor and convert the input data to the format required by the AIU. The resulting transformed ztensor can be reused as many times as necessary. See zdnn_transform_ztensor for details on transforming an input tensor to the internal format. zdnn_transform_origtensor zdnn_transform_origtensor transforms a ztensor (usually output from an operation or network) to the format and data types that are usable by the application. See zdnn_transform_origtensor for details on transforming an input tensor to the internal format. zdnn_transform_ztensor \u00b6 Description \u00b6 Converts the input tensor to the supported transformed format for execution by zdnn operations. If transformation is successful the is_transformed field within ztensor will be set to true otherwise it is set to false . Transformation will fail if is_transformed was already true . Note that the tensor layout in memory, once in transformed format, is dependent on the content of the input tensor's descriptors ( zdnn_tensor_desc fields). Once converted, a zdnn_ztensor should only be manipulated by zDNN API functions. Format \u00b6 zdnn_status zdnn_transform_ztensor(zdnn_ztensor *ztensor, ...); Parameters \u00b6 zdnn_ztensor *tensor The input zdnn_ztensor struct. pre_transformed_desc and transformed_desc must be set, is_transformed must be false . A 4k-aligned tensor storage must be pre-allocated by the caller (directly or by calling the zDNN allocation helper function) and field buffer must point to the storage. ... (additional arguments) Variadic: list of pointers for input data to be transformed: Non-concatenated: 1 data pointer LSTM concatenated: 4 data pointers, one for each input gate in Forget, Input, Cell, Output (FICO) order GRU concatenated: 3 data pointers, one for each input gate in (Z)update, Reset, Hidden, (ZRH) gate order Programming Notes \u00b6 This function clears the pre-thread floating-point exception flags at entry, and may set FE_UNDERFLOW / FE_INVALID / FE_INEXACT / FE_OVERFLOW when it encounters errors during data conversion. Returns zdnn_status indications \u00b6 ZDNN_OK ZDNN_INVALID_FORMAT - zdnn_ztensor->transformed_desc->format is not recognized. ZDNN_INVALID_LAYOUT - (if any of the following are true) zdnn_ztensor->pre_transformed_desc->layout is not recognized or is not a valid pre_transformed_desc layout. zdnn_ztensor->transformed_desc->layout is not recognized or is not a valid transformed_desc layout. ZDNN_INVALID_TYPE - (if any of the following are true) zdnn_ztensor->pre_transformed_desc->type is not recognized or is a transformed_desc type. zdnn_ztensor->transformed_desc->type is not recognized or is a pre_transformed_desc type. ZDNN_INVALID_BUFFER (if any of the following are true) buffer is NULL . buffer is not on a 4K boundary. buffer_size is too small to hold transformed values. ZDNN_INVALID_SHAPE - (if any of the following are true) One of zdnn_ztensor->transformed_desc->dim* dimensions is 0. One of zdnn_ztensor->transformed_desc->dim* dimensions is greater than zdnn_get_nnpa_max_dim_idx_size . Note: concatenation dimensions have a smaller maximum size. See LSTM or GRU . The total number of transformed_desc elements is larger than zdnn_get_nnpa_max_tensor_size . ZDNN_INVALID_STATE - Tensor is already transformed. ZDNN_CONVERT_FAILURE - Values failed to transform. zdnn_transform_origtensor \u00b6 Description \u00b6 Converts the input tensor from the zDNN transformed format back to a standard non-transformed layout. The is_transformed field within ztensor must be true . All stick format tensors are supported, except: Kernel tensors Concatenated RNN input-gates tensors Format \u00b6 zdnn_status zdnn_transform_origtensor(const zdnn_ztensor *ztensor, void *out_buf); Parameters \u00b6 zdnn_ztensor *ztensor The input zdnn_ztensor struct. pre_transformed_desc , transformed_desc and buffer must be set, is_transformed must be true . void *out_buf The buffer for storing the standard non-transformed tensor data. Must be pre-allocated by the caller. Programming Notes \u00b6 This function clears the pre-thread floating-point exception flags at entry, and may set FE_UNDERFLOW / FE_INVALID / FE_INEXACT / FE_OVERFLOW when it encounters errors during data conversion. Returns zdnn_status indications \u00b6 ZDNN_OK ZDNN_INVALID_FORMAT - ztensor->transformed_desc->format is not ZDNN_FORMAT_4DFEATURE . ZDNN_INVALID_LAYOUT - (if any of the following are true) zdnn_ztensor->pre_transformed_desc->layout is not recognized or is not a valid pre_transformed_desc layout. zdnn_ztensor->transformed_desc->layout is not recognized or is not a valid transformed_desc layout required by this function. ZDNN_INVALID_TYPE ztensor->pre_transformed_desc->type is not recognized or is a transformed_desc type. ztensor->transformed_desc->type is not recognized or is a pre_transformed_desc type. ZDNN_INVALID_BUFFER (if any of the following are true) ztensor->buffer is NULL . ztensor->buffer is not on a 4K boundary. ZDNN_INVALID_STATE - ztensor is not transformed. ZDNN_CONVERT_FAILURE - Values failed to un-transform. Operations \u00b6 See Table of Contents for operations list Element-wise Operations \u00b6 Back to Table of Contents Addition Subtraction Multiplication Division Minimum Maximum Natural Logarithm Exponential zdnn_add \u00b6 Back to Table of Contents Back to Element-wise Operations Description \u00b6 Given two input tensors in zDNN transformed format, performs element-wise addition and stores the result into the provided output zDNN tensor. Note that for zDNN use, broadcasting of the input tensor(s) must be performed by the caller. As such, the input tensors must be of the same shape. Format \u00b6 zdnn_status zdnn_add(const zdnn_ztensor *input_a, const zdnn_ztensor *input_b, zdnn_ztensor *output); Parameters \u00b6 zdnn_ztensor *input_a Tensor with addends to add to input_b tensor Must follow general tensor requirements zdnn_ztensor *input_b Tensor with addends to add to input_a tensor Must follow general tensor requirements zdnn_ztensor *output Tensor to hold the result of the addition Must follow general tensor requirements Returns (see zDNN Statuses for descriptions) \u00b6 ZDNN_OK warning statuses ZDNN_INVALID_SHAPE ZDNN_INVALID_TYPE ZDNN_INVALID_FORMAT hardware statuses Framework Examples \u00b6 TensorFlow Addition ONNX Addition zdnn_sub \u00b6 Back to Table of Contents Back to Element-wise Operations Description \u00b6 Given two input tensors in zDNN transformed format, performs element-wise subtraction and stores the result into the provided output zDNN tensor. Note that for zDNN use, broadcasting of the input tensor(s) must be performed by the caller. As such, the input tensors must be of the same shape. Format \u00b6 zdnn_status zdnn_sub(const zdnn_ztensor *input_a, const zdnn_ztensor *input_b, zdnn_ztensor *output); Parameters \u00b6 zdnn_ztensor *input_a Tensor with minuends that will be subtracted by input_b tensor. Must follow general tensor requirements zdnn_ztensor *input_b Tensor with subtrahends to subtract from input_a tensor. Must follow general tensor requirements zdnn_ztensor *output Tensor to hold the result of the subtraction Must follow general tensor requirements Returns (see zDNN Statuses for descriptions) \u00b6 ZDNN_OK warning statuses ZDNN_INVALID_SHAPE ZDNN_INVALID_TYPE ZDNN_INVALID_FORMAT hardware statuses Framework Examples \u00b6 TensorFlow Subtraction ONNX Subtraction zdnn_mul \u00b6 Back to Table of Contents Back to Element-wise Operations Description \u00b6 Given two input tensors in zDNN transformed format, performs element-wise multiplication and stores the result into the provided output zDNN tensor. Note that for zDNN use, broadcasting of the input tensor(s) must be performed by the caller. As such, the input tensors must be of the same shape. Format \u00b6 zdnn_status zdnn_mul(const zdnn_ztensor *input_a, const zdnn_ztensor *input_b, zdnn_ztensor *output); Parameters \u00b6 zdnn_ztensor *input_a Tensor with multiplicands that will be multiplied by input_b tensor. Must follow general tensor requirements zdnn_ztensor *input_b Tensor with multipliers for input_a tensor. Must follow general tensor requirements zdnn_ztensor *output Tensor to hold the result of the multiplication. Must follow general tensor requirements Returns (see zDNN Statuses for descriptions) \u00b6 ZDNN_OK warning statuses ZDNN_INVALID_SHAPE ZDNN_INVALID_TYPE ZDNN_INVALID_FORMAT hardware statuses Framework Examples \u00b6 TensorFlow Multiplication ONNX Multiplication zdnn_div \u00b6 Back to Table of Contents Back to Element-wise Operations Description \u00b6 Given two input tensors in zDNN transformed format, performs element-wise division and stores the result into the provided output zDNN tensor. Note that for zDNN use, broadcasting of the input tensor(s) must be performed by the caller. As such, the input tensors must be of the same shape. Format \u00b6 zdnn_status zdnn_div(const zdnn_ztensor *input_a, const zdnn_ztensor *input_b, zdnn_ztensor *output); Parameters \u00b6 zdnn_ztensor *input_a Tensor with dividends that will be divided by input_b tensor. Must follow general tensor requirements zdnn_ztensor *input_b Tensor with divisors for input_a tensor. Must follow general tensor requirements zdnn_ztensor *output Tensor to hold the result of the division. Must follow general tensor requirements Returns (see zDNN Statuses for descriptions) \u00b6 ZDNN_OK warning statuses ZDNN_INVALID_SHAPE ZDNN_INVALID_TYPE ZDNN_INVALID_FORMAT hardware statuses Framework Examples \u00b6 TensorFlow Division ONNX Division zdnn_min \u00b6 Back to Table of Contents Back to Element-wise Operations Description \u00b6 Given two input tensors in zDNN transformed format, computes the element-wise minimum and stores the result into the provided output zDNN tensor. Note that for zDNN use, broadcasting of the input tensor(s) must be performed by the caller. As such, the input tensors must be of the same shape. Format \u00b6 zdnn_status zdnn_min(const zdnn_ztensor *input_a, const zdnn_ztensor *input_b, zdnn_ztensor *output); Parameters \u00b6 zdnn_ztensor *input_a Tensor with values that will be compared with input_b tensor. Must follow general tensor requirements zdnn_ztensor *input_b Tensor with values that will be compared with input_a tensor. Must follow general tensor requirements zdnn_ztensor *output Tensor that holds the smaller value from each comparison of the inputs. Must follow general tensor requirements Returns (see zDNN Statuses for descriptions) \u00b6 ZDNN_OK warning statuses ZDNN_INVALID_SHAPE ZDNN_INVALID_TYPE ZDNN_INVALID_FORMAT hardware statuses Framework Examples \u00b6 TensorFlow Minimum ONNX Minimum zdnn_max \u00b6 Back to Table of Contents Back to Element-wise Operations Description \u00b6 Given two input tensors in zDNN transformed format, computes the element-wise maximum and stores the result into the provided output zDNN tensor. Note that for zDNN use, broadcasting of the input tensor(s) must be performed by the caller. As such, the input tensors must be of the same shape. Format \u00b6 zdnn_status zdnn_max(const zdnn_ztensor *input_a, const zdnn_ztensor *input_b, zdnn_ztensor *output); Parameters \u00b6 zdnn_ztensor *input_a Tensor with values that will be compared with input_b tensor. Must follow general tensor requirements zdnn_ztensor *input_b Tensor with values that will be compared with input_a tensor. Must follow general tensor requirements zdnn_ztensor *output Tensor that holds the larger value from each comparison of the inputs. Must follow general tensor requirements Returns (see zDNN Statuses for descriptions)s \u00b6 ZDNN_OK warning statuses ZDNN_INVALID_SHAPE ZDNN_INVALID_TYPE ZDNN_INVALID_FORMAT hardware statuses Framework Examples \u00b6 TensorFlow Maximum ONNX Maximum zdnn_log \u00b6 Back to Table of Contents Back to Element-wise Operations Description \u00b6 Given an input tensor in zDNN transformed format, computes the natural logarithm element-wise and stores the result into the provided output zDNN tensor. Format \u00b6 zdnn_status zdnn_log(const zdnn_ztensor *input, zdnn_ztensor *output); Parameters \u00b6 zdnn_ztensor *input Tensor with values to evaluate. Must follow general tensor requirements zdnn_ztensor *output Tensor that holds the calculated natural logarithm of each value from input_a Must follow general tensor requirements Returns (see zDNN Statuses for descriptions) \u00b6 ZDNN_OK warning statuses ZDNN_INVALID_SHAPE ZDNN_INVALID_TYPE ZDNN_INVALID_FORMAT hardware statuses Framework Examples \u00b6 TensorFlow Natural Logarithm ONNX Natural Logarithm zdnn_exp \u00b6 Back to Table of Contents Back to Element-wise Operations Description \u00b6 Given an input tensor in zDNN transformed format, computes the exponential element-wise and stores the result into the provided output zDNN tensor. Format \u00b6 zdnn_status zdnn_exp(const zdnn_ztensor *input, zdnn_ztensor *output); Parameters \u00b6 zdnn_ztensor *input Tensor with values to evaluate. Must follow general tensor requirements zdnn_ztensor *output Tensor that holds the calculated exponential of each value from input Must follow general tensor requirements Returns (see zDNN Statuses for descriptions) \u00b6 ZDNN_OK warning statuses ZDNN_INVALID_SHAPE ZDNN_INVALID_TYPE ZDNN_INVALID_FORMAT hardware statuses Framework Examples \u00b6 TensorFlow Exponential ONNX Exponential Activation Operations \u00b6 Back to Table of Contents Rectified Linear Hyperbolic Tangent Sigmoid Softmax zdnn_relu \u00b6 Back to Table of Contents Back to Activation Operations Description \u00b6 Given an input tensor in zDNN transformed format produce an output tensor where the rectified linear function, y = max(0, x) is applied to the input element-wise. If an optional clipping_value is provided, clipping is performed against the intermediate output where z = min(y, clipping_value). Format \u00b6 zdnn_status zdnn_relu(const zdnn_ztensor *input, const void *clipping_value, zdnn_ztensor *output); Parameters \u00b6 zdnn_ztensor *input Tensor with values to evaluate. Must follow general tensor requirements void *clipping_value A pointer to an FP32 value, used to clip input tensor's elements. If set to NULL or 0, no clipping will occur. Must not be a negative value. zdnn_ztensor *output Tensor that holds the rectified linear function result of each value from input Must follow general tensor requirements Returns (see zDNN Statuses for descriptions) \u00b6 ZDNN_OK warning statuses ZDNN_INVALID_SHAPE ZDNN_INVALID_TYPE ZDNN_INVALID_FORMAT ZDNN_INVALID_CLIPPING_VALUE hardware statuses Framework Examples \u00b6 TensorFlow Rectified Linear ONNX Rectified Linear zdnn_tanh \u00b6 Back to Table of Contents Back to Activation Operations Description \u00b6 Given an input tensor in zDNN transformed format, produces an output tensor where the hyperbolic tangent is applied to the input element-wise. Format \u00b6 zdnn_status zdnn_tanh(const zdnn_ztensor *input, zdnn_ztensor *output); Parameters \u00b6 zdnn_ztensor *input Tensor with values to evaluate. Must follow general tensor requirements zdnn_ztensor *output Tensor that holds the hyperbolic tangent result of each value from input Must follow general tensor requirements Returns (see zDNN Statuses for descriptions) \u00b6 ZDNN_OK warning statuses ZDNN_INVALID_SHAPE ZDNN_INVALID_TYPE ZDNN_INVALID_FORMAT hardware statuses Framework Examples \u00b6 TensorFlow Hyperbolic Tangent ONNX Hyperbolic Tangent zdnn_sigmoid \u00b6 Back to Table of Contents Back to Activation Operations Description \u00b6 Given an input tensor in zDNN transformed format, produces an output tensor where the sigmoid function is applied to the input element-wise. Format \u00b6 zdnn_status zdnn_sigmoid(const zdnn_ztensor *input, zdnn_ztensor *output); Parameters \u00b6 zdnn_ztensor *input Tensor with values to evaluate. Must follow general tensor requirements zdnn_ztensor *output Tensor that holds the sigmoid result of each value from input Must follow general tensor requirements Returns (see zDNN Statuses for descriptions) \u00b6 ZDNN_OK warning statuses ZDNN_INVALID_SHAPE ZDNN_INVALID_TYPE ZDNN_INVALID_FORMAT hardware statuses Framework Examples \u00b6 TensorFlow Sigmoid ONNX Sigmoid zdnn_softmax \u00b6 Back to Table of Contents Back to Activation Operations Description \u00b6 Given an input tensor in zDNN transformed format, computes the softmax (normalized exponential) for each vector formed in dimension-1, then if act_func is not SOFTMAX_ACT_NONE , the activation function is applied to the results. Finally stores the results into the provided output zDNN tensor. Note: Other parameters, such as axis, are not supported. Format \u00b6 zdnn_status zdnn_softmax(const zdnn_ztensor *input, void *save_area, zdnn_softmax_act act_func, zdnn_ztensor *output); Parameters \u00b6 zdnn_ztensor *input ZDNN_3DS tensor with pre-transformed shape [batch size, batch size, vector dimension size] or output from another operation that is of the correct shape. Must follow general tensor requirements void *save_area A preallocated memory address to use for temporary storage during internal operation processing. The preallocate memory must be at least 8K bytes in size, aligned on a 4k boundary. If set to NULL, the operation will determine, allocate and free storage automatically. zdnn_softmax_act act_func Activation function to apply to the results. SOFTMAX_ACT_NONE or SOFTMAX_ACT_LOG zdnn_ztensor *output ZDNN_3DS tensor with the same shape as input_a that holds the softmax result of each value from input_a . Must follow general tensor requirements Programming Notes \u00b6 If all elements of a dimension 1 vector are the largest magnitude negative number possible for the transformed data type, accuracy may be reduced. A ZDNN_3DS tensor is expected, where the transformed_desc dim1 describes the vector, and dim2 and dim4 are used to batch multiple vector requests together. Dim3 must always be 1. The zdnn_softmax operation is performed against the vector in dim1 repeating for each dim1 vector in the dim4 and dim2 dimensions. Tensors that cannot be processed as vectors in dim1 or as batches of dim1 vectors must be coerced or reshaped by the caller. When the entire tensor is to be processed by softmax, it can be coerced by simply creating an alternate descriptor prior to zDNN transformation. For example: A 4D tensor with pre_transformed_desc dimensions 2x2x2x2 and a data array of 16 FP32 entries could have an alternate ZDNN_3DS layout pre_transformed_desc using dimensions 1x1x16 and use the same original data array prior to zdnn_transform_ztensor . After transformation, such a tensor would be valid for zdnn_softmax . In another example, the 4D 2x2x2x2 tensor could be processed as 2 batches of 8 vectors using a ZDNN_3DS layout pre_transformed_desc with dimensions 1x2x8. Returns (see zDNN Statuses for descriptions) \u00b6 ZDNN_OK warning statuses ZDNN_INVALID_SHAPE ZDNN_INVALID_TYPE ZDNN_INVALID_FORMAT ZDNN_ALLOCATION_FAILURE - A preallocated save_area was not specified and internal allocation for the required memory failed. hardware statuses ZDNN_FUNC_RC_F000 - input tensor input->transformed_desc->dim3 was not 1. ZDNN_FUNC_RC_F001 - Invalid act_func Framework Examples \u00b6 TensorFlow Softmax ONNX Softmax Normalization Operations \u00b6 Back to Table of Contents Mean Reduce Batch Norm zdnn_meanreduce2d \u00b6 Back to Table of Contents Back to Normalization Operations Description \u00b6 Given an input tensor in zDNN transformed format, produces a downsampled tensor reducing the middle dimensions to a size of 1 based on the mean of the original values and stores the result to the provided output zDNN tensor. Format \u00b6 zdnn_status zdnn_meanreduce2d(const zdnn_ztensor *input, zdnn_ztensor *output); Parameters \u00b6 zdnn_ztensor *input Must be a ZDNN_NHWC tensor with pre_transformed shape [batch_Num, Height, Width, Channel]. Height and Width dimension must be less than or equal to 1024. Must follow general tensor requirements zdnn_ztensor *output The result tensor which will hold the result of the pooling operation in its buffer. Shape: output dimensions batch_Num and Channel must be the same as the respective input dimensions. output dimensions Height and Width must be 1. Must follow general tensor requirements Returns (see zDNN Statuses for descriptions) \u00b6 ZDNN_OK ZDNN_INVALID_SHAPE - Shape of input or output tensor is invalid based on given kernel and stride parameters ZDNN_INVALID_TYPE ZDNN_INVALID_FORMAT hardware statuses ZDNN_FUNC_RC_F001 - input tensor has a Height or Width dimension greater than allowed for zdnn_meanreduce2d . Framework Examples \u00b6 TensorFlow Reduce Mean with axis set for the Height and Width axes and keepdims set to True. ONNX Reduce Mean zdnn_batchnorm \u00b6 Back to Table of Contents Back to Normalization Operations Description \u00b6 Given three input zDNN tensors input_a , input_b , and input_c , computes the batch-normalized result for each vector formed in dimension-1 as follows: output = input_b * input_a + input_c where input_b is a precomputed elementwise divide of scale and variance tensors, and input_c is a precomputed elementwise multiply of (-1) * mean and 'input_b' + input bias tensors. Format \u00b6 zdnn_status zdnn_batchnorm(const zdnn_ztensor *input_a, const zdnn_ztensor *input_b, const zdnn_ztensor *input_c, zdnn_ztensor *output); Parameters \u00b6 zdnn_ztensor *input_a Must be a 4D ZDNN_NHWC tensor Must follow general tensor requirements zdnn_ztensor *input_b Must be a 1D ZDNN_1D tensor Must follow general tensor requirements zdnn_ztensor *input_c Must be a 1D ZDNN_1D tensor Must follow general tensor requirements zdnn_ztensor *output A zdnn_ztensor of the same size as input_a representing the computed value of the above formula Must follow general tensor requirements Returns (see zDNN Statuses for descriptions) \u00b6 ZDNN_OK warning statuses ZDNN_INVALID_SHAPE ZDNN_INVALID_TYPE ZDNN_INVALID_FORMAT hardware statuses Framework Examples \u00b6 TensorFlow Batchnorm ONNX Batchnorm zdnn_matmul_op \u00b6 Back to Table of Contents Description \u00b6 Given three input zDNN tensors input_a , input_b , and input_c , determine the matrix multiplication of input_a * input_b then perform one of the following operations, using input_c against the dot product, storing the result into the specified output zDNN tensor: Addition Compare - If dot product is greater than element. Compare - If dot product is greater or equal to element. Compare - If dot product is equal to element. Compare - If dot product is not equal to element. Compare - If dot product is less than or equal to element. Compare - If dot product is less than element. For an operation type of addition, input_c is added to the intermediate dot product. For operation types of comparison, the intermediate dot product is compared to input_c and if the comparison is true, the result is set to a value of 1; otherwise it is set to a value of 0. The outermost dimension can optionally indicate that the inputs are stacks of matrices. The results for each matrix stack is independent of other stacks but all stacks are calculated in a single call. Format \u00b6 zdnn_status zdnn_matmul_op(const zdnn_ztensor *input_a, const zdnn_ztensor *input_b, const zdnn_ztensor *input_c, zdnn_matmul_ops op_type, zdnn_ztensor *output); Input / Output matmul tensor requirements \u00b6 See table in this section for pre_transformed_desc and shape requirements for each tensor. All tensors must either be stacked or unstacked. Must follow general tensor requirements type input_a input_b input_c result unstacked ZDNN_2D (m, n) ZDNN_2D (n, p) ZDNN_1D (p) ZDNN_2D (m, p) stacked ZDNN_3DS (s, m, n) ZDNN_3DS (s, n, p) ZDNN_2DS (s, p) ZDNN_3DS (s, m, p) Parameters \u00b6 zdnn_ztensor *input_a Input tensor with the first matrix for multiplication pre_transformed shape and layout must match matmul tensor requirements zdnn_ztensor *input_b Input tensor with the second matrix for multiplication pre_transformed shape and layout must match matmul tensor requirements zdnn_ztensor *input_c Input tensor that will have the requested operation performed against the intermediate dot product of input_a and input_b . pre_transformed shape and layout must match matmul tensor requirements zdnn_matmul_ops op_type Operation to perform on dot product. MATMUL_OP_ADDITION MATMUL_OP_GREATER MATMUL_OP_GREATER_EQUAL MATMUL_OP_EQUAL MATMUL_OP_NOT_EQUAL MATMUL_OP_LESSER_EQUAL MATMUL_OP_LESSER zdnn_ztensor *output The output tensor which will hold the result of the operation in its buffer. pre_transformed shape and layout must match matmul tensor requirements Programming Notes \u00b6 Care must be exercised when comparing values for equality or inequality since the order of operations and rounding may produce, what appear to be, slightly different values when they are essentially the same value. Returns (see zDNN Statuses for descriptions) \u00b6 ZDNN_OK ZDNN_INVALID_SHAPE ZDNN_INVALID_TYPE ZDNN_INVALID_FORMAT hardware statuses ZDNN_FUNC_RC_F000 - Invalid op_type . Framework Examples \u00b6 TensorFlow MatMul ONNX MatMul zdnn_matmul_bcast_op \u00b6 Back to Table of Contents Description \u00b6 Given three input zDNN tensors input_a , input_b , and input_c , determine the matrix multiplication of input_a * input_b , then perform one of the following operations, using input_c against the dot product, storing the result into the specified output zDNN tensor: Addition The outermost dimension for input_a can optionally indicate that the input is a stack of matrices. Each stack of input_a is then multiplied by the same input_b matrix and input_c which are broadcast over each stack of input_a . Results for each stack are returned in the corresponding stack index of output . Format \u00b6 zdnn_status zdnn_matmul_bcast_op(const zdnn_ztensor *input_a, const zdnn_ztensor *input_b, const zdnn_ztensor *input_c, zdnn_matmul_bcast_ops op_type, zdnn_ztensor *output); Input / Output matmul broadcast tensor requirements \u00b6 See table in this section for pre_transformed_desc and shape requirements for each tensor. Must follow general tensor requirements input_a input_b input_c result ZDNN_3DS (s, m, n) ZDNN_2D (n, p) ZDNN_1D (p) ZDNN_3DS (s, m, p) Parameters \u00b6 zdnn_ztensor *input_a Input tensor with the first matrix for multiplication. pre_transformed shape and layout must match matmul broadcast tensor requirements zdnn_ztensor *input_b Input tensor with the second matrix for multiplication. The same single input_b matrix is broadcast and used as the multiplier for each stack dimension of input_a pre_transformed shape and layout must match matmul broadcast tensor requirements zdnn_ztensor *input_c Input tensor that will have the requested operation performed against the intermediate dot product for each \"m\" dimension in output . pre_transformed shape and layout must match matmul broadcast tensor requirements zdnn_matmul_bcast_ops op_type Operation to perform on dot product. MATMUL_BCAST_OP_ADDITION zdnn_ztensor *output The output tensor which will hold the result of the operation in its buffer. pre_transformed shape and layout must match matmul broadcast tensor requirements Programming Notes \u00b6 zdnn_matmul_bcast_ops only supports MATMUL_BCAST_OP_ADDITION op_type, any other op_types will be ignored and may not operate compatibly in the future. Returns (see zDNN Statuses for descriptions) \u00b6 ZDNN_OK ZDNN_INVALID_SHAPE ZDNN_INVALID_TYPE ZDNN_INVALID_FORMAT hardware statuses Framework Examples \u00b6 TensorFlow MatMul ONNX MatMul zdnn_lstm \u00b6 Back to Table of Contents Description \u00b6 Implements Long-Short Term Memory layer (LSTM - Hochreiter 1997). The following formula is computed for the input tensor input(t) for all time steps: (Default: f=Sigmoid, g=Tanh, h=Tanh): - it = f(Xt*(Wi^T) + Ht-1*(Ri^T) + Wbi + Rbi) - ft = f(Xt*(Wf^T) + Ht-1*(Rf^T) + Wbf + Rbf) - ct = g(Xt*(Wc^T) + Ht-1*(Rc^T) + Wbc + Rbc) - Ct = ft (.) Ct-1 + it (.) ct - ot = f(Xt*(Wo^T) + Ht-1*(Ro^T) + Wbo + Rbo) - Ht = ot (.) h(Ct) Format \u00b6 zdnn_status zdnn_lstm(const zdnn_ztensor *input, const zdnn_ztensor *h0, const zdnn_ztensor *c0, const zdnn_ztensor *weights, const zdnn_ztensor *biases, const zdnn_ztensor *hidden_weights, const zdnn_ztensor *hidden_biases, lstm_gru_direction direction, void *work_area, zdnn_ztensor *hn_output, zdnn_ztensor *cf_output); Also see an example in the usage example section. LSTM Input / Output requirements \u00b6 num_hidden dimensions: Any num_hidden dimension must be less than or equal to 8192 elements. Parameters \u00b6 zdnn_ztensor *input Input must be a tensor with the shape (num_timesteps, num_batches, num_features) prior to transformation with the zdnn_transform_ztensor API. Expects pre_transformed_desc->layout to be ZDNN_3DS . Must follow general tensor requirements zdnn_ztensor *h0 Tensor containing the initial hidden state with shape (num_dirs, num_batches, num_hidden) prior to transformation with the zdnn_transform_ztensor API. Expects pre_transformed_desc->layout to be ZDNN_3DS . Must follow general tensor requirements Must follow num_hidden requirements zdnn_ztensor *c0 Tensor containing the initial cell state with shape (num_dirs, num_batches, num_hidden) prior to transformation with the zdnn_transform_ztensor API. Expects pre_transformed_desc->layout to be ZDNN_3DS . Must follow general tensor requirements Must follow num_hidden requirements zdnn_ztensor *weights Tensor containing the concatenated input connection weights in Forget, Input, Cell, Output (FICO) order. Prior to transformation, each gate needs to be transposed to shape (num_dirs, num_features, num_hidden) by the caller. Expects pre_transformed_desc->layout to be ZDNN_3DS . Expects zdnn_concat_info having the following flags turned on: RNN_TYPE_LSTM USAGE_WEIGHTS Appropriate PREV_LAYER flag: PREV_LAYER_NONE if input tensor is not from a previous RNN layer PREV_LAYER_UNI if input tensor is uni-directional output from a previous RNN layer PREV_LAYER_BIDIR if input tensor is bi-directional output from a previous RNN layer Must follow concatenated tensor requirements Must follow num_hidden requirements zdnn_ztensor *biases Tensor containing the concatenated input connection bias in Forget, Input, Cell, Output (FICO) order. Prior to transformation, expects each gate needs to be shape (num_dirs, num_hidden). Expects pre_transformed_desc->layout to be ZDNN_2DS . Expects zdnn_concat_info having the following flags turned on: RNN_TYPE_LSTM USAGE_HIDDEN_WEIGHTS Appropriate PREV_LAYER flag: PREV_LAYER_NONE if input tensor is not from a previous RNN layer PREV_LAYER_UNI if input tensor is uni-directional output from a previous RNN layer PREV_LAYER_BIDIR if input tensor is bi-directional output from a previous RNN layer Must follow concatenated tensor requirements Must follow num_hidden requirements zdnn_ztensor *hidden_weights Tensor containing the concatenated hidden connection weights in Forget, Input, Cell, Output (FICO) order. Prior to transformation, each gate needs to be transposed to shape (num_dirs, num_hidden, num_hidden) by the caller. Expects pre_transformed_desc->layout to be ZDNN_3DS . Expects zdnn_concat_info having the following flags turned on: RNN_TYPE_LSTM USAGE_BIASES Appropriate PREV_LAYER flag: PREV_LAYER_NONE if input tensor is not from a previous RNN layer PREV_LAYER_UNI if input tensor is uni-directional output from a previous RNN layer PREV_LAYER_BIDIR if input tensor is bi-directional output from a previous RNN layer Must follow concatenated tensor requirements Must follow num_hidden requirements zdnn_ztensor *hidden_biases Tensor containing the concatenated hidden connection bias in Forget, Input, Cell, Output (FICO) order. Prior to transformation, expects each gate needs to be shape (num_dirs, num_hidden). Expects pre_transformed_desc->layout to be ZDNN_2DS . Expects zdnn_concat_info having the following flags turned on: RNN_TYPE_LSTM USAGE_HIDDEN_BIASES Appropriate PREV_LAYER flag: PREV_LAYER_NONE if input tensor is not from a previous RNN layer PREV_LAYER_UNI if input tensor is uni-directional output from a previous RNN layer PREV_LAYER_BIDIR if input tensor is bi-directional output from a previous RNN layer Must follow concatenated tensor requirements Must follow num_hidden requirements lstm_gru_direction direction Direction indicator of lstm_gru_direction direction type. Valid values: FWD (forward) BWD (backward) BIDIR (bi-directional). For input and output shapes, the num_dirs dimension should be: 1 for unidirectional calls such as FWD or BWD 2 for bidirectional calls such that: dimension 0 contains FWD values. dimension 1 contains BWD values. void *work_area A preallocated memory address to use for temporary storage during internal operation processing. If set to NULL, the operation will determine, allocate and free storage automatically. Amount of required storage can be determined given the LSTM timestep, batch, and num_hidden values. The sample code below creates a ztensor descriptor that is an equivalent size of the required work_area . To use this sample code yourself, replace the num_timesteps , num_batches , and num_hidden variables with your own values. zdnn_tensor_desc desc; desc.dim4 = (4 * num_timesteps) + 6; desc.dim3 = 1; desc.dim2 = num_batches; desc.dim1 = num_hidden; uint64_t work_area_size = zdnn_getsize_ztensor(&desc); For bidirectional, twice the amount of contiguous storage is required. The start of the buffer must be 4k aligned. zdnn_ztensor *hn_output Output results of the hidden states Expects pre_transformed_desc->layout to be ZDNN_4DS . Must follow general tensor requirements Must follow num_hidden requirements Output pre-transformed shapes: all timesteps: (num_timesteps, num_dirs, num_batches, num_hidden) final timestep only: (1, num_dirs, num_batches, num_hidden) For bidirectional ( BIDIR ) output: Forward and backward results are concatenated on the innermost dimension. Can be used directly as input for subsequent RNN layers without needing untransformation. Can not be used directly as input for other non-RNN zDNN ops. Untransformation is supported. Note that for BWD and the backward component of BIDIR directions, the output order matches the order of the input, not the processing order. For example, the first input timestep is the last to be processed and its result is the first timestep of the output. zdnn_ztensor *cf_output Output results of the cell state for the last processed timestep Expects pre_transformed_desc->layout to be ZDNN_4DS . Must follow general tensor requirements Must follow num_hidden requirements Output pre-transformed shapes: (1, num_dirs, num_batches, num_hidden) For bidirectional ( BIDIR ): Forward and backward results are concatenated on the innermost dimension. Can not be used directly as input for other non-RNN zDNN ops. Untransformation is supported. Summary \u00b6 pre-transformed layout pre-transformed shape input ZDNN_3DS (num_timesteps, num_batches, num_features) h0 ZDNN_3DS (num_dirs, num_batches, num_hidden) c0 ZDNN_3DS (num_dirs, num_batches, num_hidden) weights ZDNN_3DS (num_dirs, num_features, num_hidden) bias ZDNN_2DS (num_dirs, num_hidden) hidden_weights ZDNN_3DS (num_dirs, num_hidden, num_hidden) hidden_biases ZDNN_2DS (num_dirs, num_hidden) hn_output ZDNN_4DS (num_timesteps, num_dirs, num_batches, num_hidden) (last timestep only when num_timesteps = 1) cf_output ZDNN_4DS (1, num_dirs, num_batches, num_hidden) create transformed descriptor via input zdnn_generate_transformed_desc h0 zdnn_generate_transformed_desc c0 zdnn_generate_transformed_desc weights zdnn_generate_transformed_desc_concatenated - RNN_TYPE_LSTM + USAGE_WEIGHTS + one of the following: PREV_LAYER_NONE / PREV_LAYER_UNI / PREV_LAYER_BIDIR bias zdnn_generate_transformed_desc_concatenated - RNN_TYPE_LSTM + USAGE_BIASES + one of the following: PREV_LAYER_NONE / PREV_LAYER_UNI / PREV_LAYER_BIDIR hidden_weights zdnn_generate_transformed_desc_concatenated - RNN_TYPE_LSTM + USAGE_HIDDEN_WEIGHTS + one of the following: PREV_LAYER_NONE / PREV_LAYER_UNI / PREV_LAYER_BIDIR hidden_biases zdnn_generate_transformed_desc_concatenated - RNN_TYPE_LSTM + USAGE_HIDDEN_BIASES + one of the following: PREV_LAYER_NONE / PREV_LAYER_UNI / PREV_LAYER_BIDIR hn_output zdnn_generate_transformed_desc cf_output zdnn_generate_transformed_desc Returns (see zDNN Statuses for descriptions) \u00b6 ZDNN_OK ZDNN_INVALID_TYPE ZDNN_INVALID_FORMAT ZDNN_INVALID_SHAPE - (if any of the following are not true) hn_output timesteps dimension must be 1 or the same size as input timestep dimension. All tensors with a direction dimension have the same direction dimension size. input timestep dimension must be greater than or equal to 1. Other general shape violations (exceeds MDIS, etc.) ZDNN_INVALID_DIRECTION - direction parameter was not a recognized lstm_gru_direction . ZDNN_ALLOCATION_FAILURE - A preallocated work_area was not specified and internal allocation for the required memory failed. hardware statuses Framework Examples \u00b6 TensorFlow LSTM ONNX LSTM zdnn_gru \u00b6 Back to Table of Contents Description \u00b6 Implements Gated Recurrent Unit (Kyunghyun Cho 2014). Supports only reset after linear. The following formula is computed for the input tensor input(t) for all time steps: (Default: f=Sigmoid, g=Tanh): - zt = f(Xt*(Wz^T) + Ht-1*(Rz^T) + Wbz + Rbz) - rt = f(Xt*(Wr^T) + Ht-1*(Rr^T) + Wbr + Rbr) - ht = g(Xt*(Wh^T) + (rt (.) (Ht-1*(Rh^T) + Rbh)) + Wbh) - Ht = (1 - zt) (.) ht + zt (.) Ht-1 Format \u00b6 zdnn_status zdnn_gru(const zdnn_ztensor *input, const zdnn_ztensor *h0, const zdnn_ztensor *weights, const zdnn_ztensor *biases, const zdnn_ztensor *hidden_weights, const zdnn_ztensor *hidden_biases, lstm_gru_direction direction, void *work_area, zdnn_ztensor *hn_output); Also see an example in the usage example section. GRU Input / Output requirements \u00b6 num_hidden dimensions: Any num_hidden dimension must be less than or equal to 10880 elements. Parameters \u00b6 zdnn_ztensor *input Input must be a tensor with the shape (num_timesteps, num_batches, num_features) prior to transformation with the zdnn_transform_ztensor API. Expects pre_transformed_desc->layout to be ZDNN_3DS . Must follow general tensor requirements zdnn_ztensor *h0 Tensor containing the initial hidden state with shape (num_dirs, num_batches, num_hidden) prior to transformation with the zdnn_transform_ztensor API. Expects pre_transformed_desc->layout to be ZDNN_3DS . Must follow general tensor requirements Must follow num_hidden requirements zdnn_ztensor *weights Tensor containing the concatenated input connection weights in (Z)update, Reset, Hidden, (ZRH) order. Prior to transformation, each gate needs to be transposed to shape (num_dirs, num_features, num_hidden) by the caller. Expects pre_transformed_desc->layout to be ZDNN_3DS . Expects zdnn_concat_info having the following flags turned on: RNN_TYPE_GRU USAGE_WEIGHTS Appropriate PREV_LAYER flag: PREV_LAYER_NONE if input tensor is not from a previous RNN layer PREV_LAYER_UNI if input tensor is uni-directional output from a previous RNN layer PREV_LAYER_BIDIR if input tensor is bi-directional output from a previous RNN layer Must follow concatenated tensor requirements Must follow num_hidden requirements zdnn_ztensor *biases Tensor containing the concatenated input connection bias in (Z)update, Reset, Hidden, (ZRH) order. Prior to transformation, expects each gate needs to be shape (num_dirs, num_hidden). Expects pre_transformed_desc->layout to be ZDNN_2DS . Expects zdnn_concat_info having the following flags turned on: RNN_TYPE_GRU USAGE_HIDDEN_WEIGHTS Appropriate PREV_LAYER flag: PREV_LAYER_NONE if input tensor is not from a previous RNN layer PREV_LAYER_UNI if input tensor is uni-directional output from a previous RNN layer PREV_LAYER_BIDIR if input tensor is bi-directional output from a previous RNN layer Must follow concatenated tensor requirements Must follow num_hidden requirements zdnn_ztensor *hidden_weights Tensor containing the concatenated hidden connection weights in (Z)update, Reset, Hidden, (ZRH) order. Prior to transformation, each gate needs to be transposed to shape (num_dirs, num_hidden, num_hidden) by the caller. Expects pre_transformed_desc->layout to be ZDNN_3DS . Expects zdnn_concat_info having the following flags turned on: RNN_TYPE_GRU USAGE_BIASES Appropriate PREV_LAYER flag: PREV_LAYER_NONE if input tensor is not from a previous RNN layer PREV_LAYER_UNI if input tensor is uni-directional output from a previous RNN layer PREV_LAYER_BIDIR if input tensor is bi-directional output from a previous RNN layer Must follow concatenated tensor requirements Must follow num_hidden requirements zdnn_ztensor *hidden_biases Tensor containing the concatenated hidden connection bias in (Z)update, Reset, Hidden, (ZRH) order. Prior to transformation, expects each gate needs to be shape (num_dirs, num_hidden). Expects pre_transformed_desc->layout to be ZDNN_2DS . Expects zdnn_concat_info having the following flags turned on: RNN_TYPE_GRU USAGE_HIDDEN_BIASES Appropriate PREV_LAYER flag: PREV_LAYER_NONE if input tensor is not from a previous RNN layer PREV_LAYER_UNI if input tensor is uni-directional output from a previous RNN layer PREV_LAYER_BIDIR if input tensor is bi-directional output from a previous RNN layer Must follow concatenated tensor requirements Must follow num_hidden requirements lstm_gru_direction direction Direction indicator of lstm_gru_direction direction type. Valid values: FWD (forward) BWD (backward) BIDIR (bi-directional). For input shapes, the num_dirs dimension should be: 1 for unidirectional calls such as FWD or BWD 2 for bidirectional calls such that: dimension 0 contains FWD values. dimension 1 contains BWD values. void *work_area A preallocated memory address to use for temporary storage during internal operation processing. If set to NULL, the operation will determine, allocate and free storage automatically. Amount of required storage can be determined given the GRU timestep, batch, and num_hidden values. The sample code below creates a ztensor descriptor that is an equivalent size of the required work_area . To use this sample code yourself, replace the num_timesteps , num_batches , and num_hidden variables with your own values. zdnn_tensor_desc desc; desc.dim4 = (3 * num_timesteps) + 5; desc.dim3 = 1; desc.dim2 = num_batches; desc.dim1 = num_hidden; uint64_t work_area_size = zdnn_getsize_ztensor(&desc); For bidirectional, twice the amount of contiguous storage is required. The start of the buffer must be 4k aligned. zdnn_ztensor *hn_output Output results of the hidden states Expects pre_transformed_desc->layout to be ZDNN_4DS . Must follow general tensor requirements Must follow num_hidden requirements Output pre-transformed shapes: all timesteps: (num_timesteps, num_dirs, num_batches, num_hidden) final timestep only: (1, num_dirs, num_batches, num_hidden) For bidirectional ( BIDIR ) output: Forward and backward results are concatenated on the innermost dimension. Can be used directly as input for subsequent RNN layers without needing untransformation. Can not be used directly as input for other non-RNN zDNN ops. Untransformation is supported. Note that for BWD and the backward component of BIDIR directions, the output order matches the order of the input, not the processing order. For example, the first input timestep is the last to be processed and its result is the first timestep of the output. Summary \u00b6 pre-transformed layout pre-transformed shape input ZDNN_3DS (num_timesteps, num_batches, num_features) h0 ZDNN_3DS (num_dirs, num_batches, num_hidden) c0 ZDNN_3DS (num_dirs, num_batches, num_hidden) weights ZDNN_3DS (num_dirs, num_features, num_hidden) bias ZDNN_2DS (num_dirs, num_hidden) hidden_weights ZDNN_3DS (num_dirs, num_hidden, num_hidden) hidden_biases ZDNN_2DS (num_dirs, num_hidden) hn_output ZDNN_4DS (num_timesteps, num_dirs, num_batches, num_hidden) (last timestep only when num_timesteps = 1) create transformed descriptor via input zdnn_generate_transformed_desc h0 zdnn_generate_transformed_desc c0 zdnn_generate_transformed_desc weights zdnn_generate_transformed_desc_concatenated - RNN_TYPE_LSTM + USAGE_WEIGHTS + one of the following: PREV_LAYER_NONE / PREV_LAYER_UNI / PREV_LAYER_BIDIR bias zdnn_generate_transformed_desc_concatenated - RNN_TYPE_LSTM + USAGE_BIASES + one of the following: PREV_LAYER_NONE / PREV_LAYER_UNI / PREV_LAYER_BIDIR hidden_weights zdnn_generate_transformed_desc_concatenated - RNN_TYPE_LSTM + USAGE_HIDDEN_WEIGHTS + one of the following: PREV_LAYER_NONE / PREV_LAYER_UNI / PREV_LAYER_BIDIR hidden_biases zdnn_generate_transformed_desc_concatenated - RNN_TYPE_LSTM + USAGE_HIDDEN_BIASES + one of the following: PREV_LAYER_NONE / PREV_LAYER_UNI / PREV_LAYER_BIDIR hn_output zdnn_generate_transformed_desc Returns (see zDNN Statuses for descriptions) \u00b6 ZDNN_OK ZDNN_INVALID_TYPE ZDNN_INVALID_FORMAT ZDNN_INVALID_SHAPE - (if any of the following are not true) hn_output timesteps dimension must be 1 or the same size as input timestep dimension. All tensors with a direction dimension have the same direction dimension size. input timestep dimension must be greater than or equal to 1. Other general shape violations (exceeds MDIS, etc.) ZDNN_INVALID_DIRECTION - direction parameter was not a recognized lstm_gru_direction . ZDNN_ALLOCATION_FAILURE - A preallocated work_area was not specified and internal allocation for the required memory failed. hardware statuses Framework Examples \u00b6 TensorFlow GRU ONNX GRU zdnn_avgpool2d \u00b6 Back to Table of Contents Description \u00b6 Given an input tensor in zDNN transformed format, padding type, kernel size and kernel stride, produces a downsampled tensor reducing the middle dimensions based on the mean values within the kernel window at each step and stores the results into the provided output zDNN tensor. Format \u00b6 zdnn_status zdnn_avgpool2d(const zdnn_ztensor *input, zdnn_pool_padding padding_type, uint32_t kernel_height, uint32_t kernel_width, uint32_t stride_height, uint32_t stride_width, zdnn_ztensor *output); Parameters \u00b6 zdnn_ztensor *input Tensor with original values to be downsampled in the output tensor. Must be a ZDNN_NHWC tensor with pre_transformed shape [batch_Num, Height, Width, Channel]. See Parameter Restrictions below for information on the expected shape of the input tensor. Must follow general tensor requirements padding_type The type of padding to use for the pooling operations. Valid values: are SAME_PADDING or VALID_PADDING . See Parameter Restrictions below for information on the expected value of padding_type. For information on \"same\" vs \"valid\" padding see: https://www.pico.net/kb/what-is-the-difference-between-same-and-valid-padding-in-tf-nn-max-pool-of-tensorflow . kernel_height Size of the kernel window that passes over the input's height dimension. See Parameter Restrictions below for information on the expected value of kerneL_height. kernel_width Size of the kernel window that passes over the input's width dimension. See Parameter Restrictions below for information on the expected value of kerneL_width. stride_height Number of positions the kernel moves over input's height dimension at each step. If stride_height is 0 then stride_width must also be 0. If strides are greater than 0 then stride_height must be less than or equal to 30. stride_width Number of positions the kernel moves over the input's width dimension at each step. If stride_height is 0 then stride_width must also be 0. If strides are greater than 0 then stride_width must be less than or equal to 30. zdnn_ztensor *output The result tensor which will hold the result of the pooling operation its buffer. Must be a ZDNN_NHWC tensor with pre_transformed shape [batch_Num, Height, Width, Channel]. See Parameter Restrictions below for information on the expected shape of the output tensor. Must follow general tensor requirements AvgPool2D Parameter Restrictions \u00b6 Parameter restrictions may vary based on provided strides and padding_type. Input tensor batch_Num and Channel dimensions must always match the output tensor's respective dimensions. If strides are 0: Both input tensor's Height dimension and the kernel_height must match and be less than or equal to 1024. Both input tensor's Width dimension and the kernel_width must match and be less than or equal to 1024. Output tensor's height and width dimensions must be 1. padding_type must be VALID_PADDING . If strides are greater than zero: kernel_width and kernel_height must be less than or equal to 64. input tensor's height or weight dimension must not be greater than 1024. If padding_type is SAME_PADDING : Output tensor's height dimension must equal ceil((float)input's height / stride_height) . Output tensor's width dimension must equal ceil((float)input's width / stride_width) . If padding_type is VALID_PADDING : Output tensor's height dimension must equal ceil((float)(input's height - kernel_height + 1) / stride_height) . Output tensor's width dimension must equal ceil((float)(input's width - kernel_width + 1) / stride_width) . Programming Notes \u00b6 If the magnitude of difference between elements of input is large (greater than 10), accuracy may be reduced. Returns (see zDNN Statuses for descriptions) \u00b6 ZDNN_OK ZDNN_INVALID_SHAPE Shape of input or output tensor is invalid based on given kernel and stride parameters Other general shape violations (exceeds MDIS, etc.) ZDNN_INVALID_TYPE ZDNN_INVALID_FORMAT ZDNN_INVALID_STRIDE_PADDING ZDNN_INVALID_STRIDES - One stride was non-zero, but not the other. hardware statuses ZDNN_EXCEEDS_MDIS will also occur if any of the following conditions occur: stride_height is larger than zdnn_get_nnpa_max_dim_idx_size . stride_width is larger than zdnn_get_nnpa_max_dim_idx_size . kernel_height is 0 or is larger than zdnn_get_nnpa_max_dim_idx_size . kernel_width is 0 or is larger than zdnn_get_nnpa_max_dim_idx_size . ZDNN_FUNC_RC_F000 - Invalid padding_type ZDNN_FUNC_RC_F001 - stride_height = 0 and stride_width = 0, but a kernel parameter is greater than allowed (see kernel_height or kernel_width above) ZDNN_FUNC_RC_F002 - stride_height > 0 and stride_width > 0, but a kernel parameter is greater than allowed (see kernel_height or kernel_width above) ZDNN_FUNC_RC_F003 - stride_height > 0 and stride_width > 0, but a stride parameter is greater than allowed (see stride_height or stride_width above) ZDNN_FUNC_RC_F004 - stride_height > 0 and stride_width > 0, but either input tensor's height or weight dimension is greater than 1024. Framework Examples \u00b6 TensorFlow AvgPool ONNX AvgPool zdnn_maxpool2d \u00b6 Back to Table of Contents Description \u00b6 Given an input tensor in zDNN transformed format, padding type, kernel size and kernel stride, produces a downsampled tensor reducing the middle dimensions based on the maximum values within the kernel window at each step and stores the results into the provided output zDNN tensor. Format \u00b6 zdnn_status zdnn_maxpool2d(const zdnn_ztensor *input, zdnn_pool_padding padding_type, uint32_t kernel_height, uint32_t kernel_width, uint32_t stride_height, uint32_t stride_width, zdnn_ztensor *output); Parameters \u00b6 zdnn_ztensor *input Tensor with original values to be downsampled in the output tensor. Must be a ZDNN_NHWC tensor with pre_transformed shape [batch_Num, Height, Width, Channel]. See Parameter Restrictions below for information on the expected shape of the input tensor. Must follow general tensor requirements padding_type The type of padding to use for the pooling operations. Valid values: are SAME_PADDING or VALID_PADDING . See Parameter Restrictions below for information on the expected value of padding_type. For information on \"same\" vs \"valid\" padding see: https://www.pico.net/kb/what-is-the-difference-between-same-and-valid-padding-in-tf-nn-max-pool-of-tensorflow . kernel_height Size of the kernel window that passes over the input's height dimension. See Parameter Restrictions below for information on the expected value of kerneL_height. kernel_width Size of the kernel window that passes over the input's width dimension. See Parameter Restrictions below for information on the expected value of kerneL_width. stride_height Number of positions the kernel moves over input's height dimension at each step. If stride_height is 0 then stride_width must also be 0. If strides are greater than 0 then stride_height must be less than or equal to 30. stride_width Number of positions the kernel moves over the input's width dimension at each step. If stride_height is 0 then stride_width must also be 0. If strides are greater than 0 then stride_width must be less than or equal to 30. zdnn_ztensor *output The result tensor which will hold the result of the pooling operation its buffer. Must be a ZDNN_NHWC tensor with pre_transformed shape [batch_Num, Height, Width, Channel]. See Parameter Restrictions below for information on the expected shape of the output tensor. Must follow general tensor requirements MaxPool2D Parameter Restrictions \u00b6 Parameter restrictions may vary based on provided strides and padding_type. Input tensor batch_Num and Channel dimensions must always match the output tensor's respective dimensions. If strides are 0: Both input tensor's Height dimension and the kernel_height must match and be less than or equal to 1024. Both input tensor's Width dimension and the kernel_width must match and be less than or equal to 1024. Output tensor's height and width dimensions must be 1. padding_type must be VALID_PADDING . If strides are greater than zero: kernel_width and kernel_height must be less than or equal to 64. input tensor's height or weight dimension must not be greater than 1024. If padding_type is SAME_PADDING : Output tensor's height dimension must equal ceil((float)input's height / stride_height) . Output tensor's width dimension must equal ceil((float)input's width / stride_width) . If padding_type is VALID_PADDING : Output tensor's height dimension must equal ceil((float)(input's height - kernel_height + 1) / stride_height) . Output tensor's width dimension must equal ceil((float)(input's width - kernel_width + 1) / stride_width) . Programming Notes \u00b6 If the magnitude of difference between elements of input is large (greater than 10), accuracy may be reduced. Returns (see zDNN Statuses for descriptions) \u00b6 ZDNN_OK ZDNN_INVALID_SHAPE Shape of input or output tensor is invalid based on given kernel and stride parameters Other general shape violations (exceeds MDIS, etc.) ZDNN_INVALID_TYPE ZDNN_INVALID_FORMAT ZDNN_INVALID_STRIDE_PADDING ZDNN_INVALID_STRIDES - One stride was non-zero, but not the other. hardware statuses ZDNN_EXCEEDS_MDIS will also occur if any of the following conditions occur: stride_height is larger than zdnn_get_nnpa_max_dim_idx_size . stride_width is larger than zdnn_get_nnpa_max_dim_idx_size . kernel_height is 0 or is larger than zdnn_get_nnpa_max_dim_idx_size . kernel_width is 0 or is larger than zdnn_get_nnpa_max_dim_idx_size . ZDNN_FUNC_RC_F000 - Invalid padding_type ZDNN_FUNC_RC_F001 - stride_height = 0 and stride_width = 0, but a kernel parameter is greater than allowed (see kernel_height or kernel_width above) ZDNN_FUNC_RC_F002 - stride_height > 0 and stride_width > 0, but a kernel parameter is greater than allowed (see kernel_height or kernel_width above) ZDNN_FUNC_RC_F003 - stride_height > 0 and stride_width > 0, but a stride parameter is greater than allowed (see stride_height or stride_width above) ZDNN_FUNC_RC_F004 - stride_height > 0 and stride_width > 0, but either input tensor's height or weight dimension is greater than 1024. Framework Examples \u00b6 TensorFlow MaxPool ONNX MaxPool zdnn_conv2d \u00b6 Back to Table of Contents Description \u00b6 Perform 2D convolution over an input tensor in zDNN transformed format. First the input tensor is convolved with the kernel tensor. Then the bias tensor is added to the results. Then if act_func is not CONV2D_ACT_NONE , the activation function is applied to the results. Then if act_func is set to CONV2D_ACT_RELU , and clipping_value is not NULL or 0 , clipping is performed against the intermediate result where z = min(intermediate_result, clipping_value). Finally the results are stored into the provided output zDNN tensor. Format \u00b6 zdnn_status zdnn_conv2d(const zdnn_ztensor *input, const zdnn_ztensor *kernel, const zdnn_ztensor *bias, zdnn_pool_padding padding_type, uint32_t stride_height, uint32_t stride_width, zdnn_conv2d_act act_func, const void *clipping_value, zdnn_ztensor *output); Parameters \u00b6 zdnn_ztensor *input Tensor with original values to be downsampled in the output tensor. Must be a ZDNN_NHWC tensor with pre_transformed shape [num_batches, height_in, width_in, channels_in]. See Convolution 2D Requirements for requirements. Must follow general tensor requirements zdnn_ztensor *kernel The kernel tensor to convolute with the input tensor. Must be a ZDNN_HWCK tensor with pre_transformed shape [kernel_height, kernel_width, channels_in, channels_out]. See Convolution 2D Requirements for requirements. Must follow general tensor requirements zdnn_ztensor *bias The bias tensor to add to the convoluted results. Must be a ZDNN_1D tensor with pre_transformed shape [channels_out]. See Convolution 2D Requirements for requirements. Must follow general tensor requirements zdnn_pool_padding padding_type The type of padding to use for the pooling operations. Valid values: are SAME_PADDING or VALID_PADDING . For information on \"same\" vs \"valid\" padding see: https://www.pico.net/kb/what-is-the-difference-between-same-and-valid-padding-in-tf-nn-max-pool-of-tensorflow . uint32_t stride_height Number of positions the kernel moves over the input's dim3 dimension at each step. See Convolution 2D Requirements for requirements. uint32_t stride_width Number of positions the kernel moves over the input's dim2 dimension at each step. See Convolution 2D Requirements for requirements. zdnn_conv2d_act act_func Activation function to apply to the results. CONV2D_ACT_NONE or CONV2D_ACT_RELU void *clipping_value A pointer to an FP32 value, used to clip input tensor's elements. If set to NULL or 0, no clipping will occur. Must not be a negative value. Value is ignored if act_func is not set to CONV2D_ACT_RELU . zdnn_ztensor *output The result tensor which will hold the results. Must be a ZDNN_NHWC tensor with pre_transformed shape [num_batches, height_out, width_out, channels_out]. See Convolution 2D Requirements for requirements. Must follow general tensor requirements Convolution 2D Requirements \u00b6 strides and padding input (num_batches, height_in, width_in, channels_in) kernel (kernel_height, kernel_width, channels_in, channels_out) bias (channels_out) output (num_batches, height_out, width_out, channels_out) both strides > 0 and =< 13, SAME padding both kernel_height and kernel_width must be =< 64 height_out = ceil(kernel_height/stride_height) width_out = ceil(kernel_width/stride_width) both strides > 0 and =< 13, VALID padding height_in must be > kernel_height width_in must be > kernel_width both kernel_height and kernel_width must be =< 64 height_out = ceil((height_in - kernel_height + 1)/stride_height) width_out = ceil((width_in - kernel_width + 1)/stride_width) both strides = 0, VALID padding height_in must be = kernel_height width_in must be = kernel_width both kernel_height and kernel_width must be =< 448 both height_out and width_out must be 1 Returns (see zDNN Statuses for descriptions) \u00b6 ZDNN_OK warning statuses ZDNN_INVALID_SHAPE Shape of input or output tensor is invalid based on given kernel and stride parameters Other general shape violations (exceeds MDIS, etc.) ZDNN_INVALID_TYPE ZDNN_INVALID_FORMAT ZDNN_INVALID_STRIDE_PADDING ZDNN_INVALID_STRIDES ZDNN_INVALID_CLIPPING_VALUE hardware statuses ZDNN_FUNC_RC_F000 - Invalid padding_type ZDNN_FUNC_RC_F001 - Invalid act_func ZDNN_FUNC_RC_F002 - stride_height = 0 and stride_width = 0, but either kernel_height or kernel_width > 448 ZDNN_FUNC_RC_F003 - stride_height > 0 and stride_width > 0, but either kernel_height or kernel_width > 64 ZDNN_FUNC_RC_F004 - Either stride_height or stride_width > 13 Framework Examples \u00b6 TensorFlow Conv2D ONNX Conv2D Convenience Functions \u00b6 Back to Table of Contents None Usage Examples \u00b6 Example flow of an application calling the zDNN APIs \u00b6 Back to Table of Contents #include <assert.h> #include <stdint.h> #include <stdio.h> #include <stdlib.h> #include <string.h> #include \"zdnn.h\" // *************************************************************************** // Sample: // // Create 2 zTensors a and b, and add them together via zdnn_add() // *************************************************************************** int main(int argc, char *argv[]) { zdnn_tensor_desc pre_tfrmd_desc, tfrmd_desc; zdnn_ztensor ztensor_a; zdnn_ztensor ztensor_b; zdnn_ztensor ztensor_out; zdnn_status status; uint32_t dim_n = 1, dim_h = 32, dim_w = 32, dim_c = 3; zdnn_data_types type = FP32; short element_size = 4; // size of each element in bytes uint64_t num_elements = dim_n * dim_h * dim_w * dim_c; // allocate tensor data storage void *data1 = malloc(num_elements * element_size); void *data2 = malloc(num_elements * element_size); void *data_out = malloc(num_elements * element_size); // read input_data // check status for AIU availability, supported ops, etc. here // status = zdnn_query(\u2026); // set input tensor data to 0 to 127 sequentially and repeat for (uint64_t i = 0; i < num_elements; i++) { ((float *)data1)[i] = (float)(i & 0x7f); ((float *)data2)[i] = (float)(i & 0x7f); } zdnn_init_pre_transformed_desc(ZDNN_NHWC, type, &pre_tfrmd_desc, dim_n, dim_h, dim_w, dim_c); // generate transformed shape information status = zdnn_generate_transformed_desc(&pre_tfrmd_desc, &tfrmd_desc); assert(status == ZDNN_OK); // initialize zTensors and allocate 4k-aligned storage via helper function status = zdnn_init_ztensor_with_malloc(&pre_tfrmd_desc, &tfrmd_desc, &ztensor_a); assert(status == ZDNN_OK); status = zdnn_init_ztensor_with_malloc(&pre_tfrmd_desc, &tfrmd_desc, &ztensor_b); assert(status == ZDNN_OK); status = zdnn_init_ztensor_with_malloc(&pre_tfrmd_desc, &tfrmd_desc, &ztensor_out); assert(status == ZDNN_OK); // transform the feature tensor status = zdnn_transform_ztensor(&ztensor_a, data1); assert(status == ZDNN_OK); status = zdnn_transform_ztensor(&ztensor_b, data2); assert(status == ZDNN_OK); // perform element-wise add between the two input tensors status = zdnn_add(&ztensor_a, &ztensor_b, &ztensor_out); assert(status == ZDNN_OK); // transform resultant zTensor back to original data format status = zdnn_transform_origtensor(&ztensor_out, data_out); assert(status == ZDNN_OK); for (uint64_t i = 0; i < num_elements; i++) { printf(\"out element %\" PRIu64 \" %f\\n\", i, ((float *)data_out)[i]); } free(data1); free(data2); free(data_out); } Example of an application calling the zdnn_lstm API (forward) \u00b6 Back to Table of Contents // SPDX-License-Identifier: Apache-2.0 /* * Copyright IBM Corp. 2021 * * Licensed under the Apache License, Version 2.0 (the \"License\"); * you may not use this file except in compliance with the License. * You may obtain a copy of the License at * * http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an \"AS IS\" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ #include <assert.h> #include <stdio.h> #include <stdlib.h> #include <string.h> #include \"zdnn.h\" // Sample: LSTM int main(int argc, char *argv[]) { zdnn_status status; #ifdef STATIC_LIB zdnn_init(); #endif /*********************************************************************** * * LSTM (FWD/BWD): * * INPUTS -------------------------------------------------------------- * input | ZDNN_3DS | (num_timesteps, num_batches, num_features) * h0 | ZDNN_3DS | (1, num_batches, num_hidden) * c0 | ZDNN_3DS | (1, num_batches, num_hidden) * weights | ZDNN_3DS | (1, num_features, num_hidden) * biases | ZDNN_2DS | (1, num_hidden) * hidden_weights | ZDNN_3DS | (1, num_hidden, num_hidden) * hidden_biases | ZDNN_2DS | (1, num_hidden) * * OUTPUTS ------------------------------------------------------------- * hn_output | ZDNN_4DS | (num_timesteps, 1, num_batches, num_hidden) * | | or (1, 1, num_batches, num_hidden) * cf_output | ZDNN_4DS | (1, 1, num_batches, num_hidden) ***********************************************************************/ /*********************************************************************** * Create input zTensor ***********************************************************************/ zdnn_tensor_desc input_pre_tfrmd_desc, input_tfrmd_desc; zdnn_ztensor input; uint32_t num_timesteps = 5; uint32_t num_batches = 3; uint32_t num_features = 32; uint32_t num_hidden = 5; zdnn_data_types type = FP32; short element_size = 4; // size of each element in bytes lstm_gru_direction dir = FWD; uint8_t num_dirs = 1; zdnn_init_pre_transformed_desc(ZDNN_3DS, type, &input_pre_tfrmd_desc, num_timesteps, num_batches, num_features); status = zdnn_generate_transformed_desc(&input_pre_tfrmd_desc, &input_tfrmd_desc); assert(status == ZDNN_OK); status = zdnn_init_ztensor_with_malloc(&input_pre_tfrmd_desc, &input_tfrmd_desc, &input); assert(status == ZDNN_OK); uint64_t input_data_size = num_timesteps * num_batches * num_features * element_size; void *input_data = malloc(input_data_size); status = zdnn_transform_ztensor(&input, input_data); assert(status == ZDNN_OK); /*********************************************************************** * Create initial hidden and cell state zTensors ***********************************************************************/ zdnn_tensor_desc h0c0_pre_tfrmd_desc, h0c0_tfrmd_desc; zdnn_ztensor h0, c0; zdnn_init_pre_transformed_desc(ZDNN_3DS, type, &h0c0_pre_tfrmd_desc, num_dirs, num_batches, num_hidden); status = zdnn_generate_transformed_desc(&h0c0_pre_tfrmd_desc, &h0c0_tfrmd_desc); assert(status == ZDNN_OK); status = zdnn_init_ztensor_with_malloc(&h0c0_pre_tfrmd_desc, &h0c0_tfrmd_desc, &h0); assert(status == ZDNN_OK); status = zdnn_init_ztensor_with_malloc(&h0c0_pre_tfrmd_desc, &h0c0_tfrmd_desc, &c0); assert(status == ZDNN_OK); uint64_t h0c0_data_size = num_batches * num_hidden * element_size; void *hidden_state_data = malloc(h0c0_data_size); void *cell_state_data = malloc(h0c0_data_size); status = zdnn_transform_ztensor(&h0, hidden_state_data); assert(status == ZDNN_OK); status = zdnn_transform_ztensor(&c0, cell_state_data); assert(status == ZDNN_OK); /*********************************************************************** * Create input weights zTensor * Resultant zTensor is concatenated ***********************************************************************/ zdnn_tensor_desc weights_pre_tfrmd_desc, weights_tfrmd_desc; zdnn_ztensor weights; zdnn_init_pre_transformed_desc(ZDNN_3DS, type, &weights_pre_tfrmd_desc, num_dirs, num_features, num_hidden); status = zdnn_generate_transformed_desc_concatenated( &weights_pre_tfrmd_desc, RNN_TYPE_LSTM | USAGE_WEIGHTS | PREV_LAYER_NONE, &weights_tfrmd_desc); assert(status == ZDNN_OK); status = zdnn_init_ztensor_with_malloc(&weights_pre_tfrmd_desc, &weights_tfrmd_desc, &weights); assert(status == ZDNN_OK); uint64_t weights_data_size = num_features * num_hidden * element_size; void *weights_data_f = malloc(weights_data_size); void *weights_data_i = malloc(weights_data_size); void *weights_data_c = malloc(weights_data_size); void *weights_data_o = malloc(weights_data_size); status = zdnn_transform_ztensor(&weights, weights_data_f, weights_data_i, weights_data_c, weights_data_o); assert(status == ZDNN_OK); /*********************************************************************** * Create biases zTensors * Resultant zTensors are concatenated ***********************************************************************/ zdnn_tensor_desc biases_pre_tfrmd_desc, biases_tfrmd_desc; zdnn_ztensor biases; zdnn_init_pre_transformed_desc(ZDNN_2DS, type, &biases_pre_tfrmd_desc, num_dirs, num_hidden); status = zdnn_generate_transformed_desc_concatenated( &biases_pre_tfrmd_desc, RNN_TYPE_LSTM | USAGE_BIASES | PREV_LAYER_NONE, &biases_tfrmd_desc); assert(status == ZDNN_OK); status = zdnn_init_ztensor_with_malloc(&biases_pre_tfrmd_desc, &biases_tfrmd_desc, &biases); assert(status == ZDNN_OK); uint64_t biases_data_size = num_hidden * element_size; void *biases_data_f = malloc(biases_data_size); void *biases_data_i = malloc(biases_data_size); void *biases_data_c = malloc(biases_data_size); void *biases_data_o = malloc(biases_data_size); status = zdnn_transform_ztensor(&biases, biases_data_f, biases_data_i, biases_data_c, biases_data_o); assert(status == ZDNN_OK); /*********************************************************************** * Create hidden weights zTensor * Resultant zTensor is concatenated ***********************************************************************/ zdnn_tensor_desc hidden_weights_pre_tfrmd_desc, hidden_weights_tfrmd_desc; zdnn_ztensor hidden_weights; zdnn_init_pre_transformed_desc(ZDNN_3DS, type, &hidden_weights_pre_tfrmd_desc, num_dirs, num_hidden, num_hidden); status = zdnn_generate_transformed_desc_concatenated( &hidden_weights_pre_tfrmd_desc, RNN_TYPE_LSTM | USAGE_HIDDEN_WEIGHTS | PREV_LAYER_NONE, &hidden_weights_tfrmd_desc); assert(status == ZDNN_OK); status = zdnn_init_ztensor_with_malloc(&hidden_weights_pre_tfrmd_desc, &hidden_weights_tfrmd_desc, &hidden_weights); assert(status == ZDNN_OK); uint64_t hidden_weights_data_size = num_hidden * num_hidden * element_size; void *hidden_weights_data_f = malloc(hidden_weights_data_size); void *hidden_weights_data_i = malloc(hidden_weights_data_size); void *hidden_weights_data_c = malloc(hidden_weights_data_size); void *hidden_weights_data_o = malloc(hidden_weights_data_size); status = zdnn_transform_ztensor(&hidden_weights, hidden_weights_data_f, hidden_weights_data_i, hidden_weights_data_c, hidden_weights_data_o); assert(status == ZDNN_OK); /*********************************************************************** * Create hidden biases zTensors * Resultant zTensors are concatenated ***********************************************************************/ zdnn_tensor_desc hidden_biases_pre_tfrmd_desc, hidden_biases_tfrmd_desc; zdnn_ztensor hidden_biases; zdnn_init_pre_transformed_desc(ZDNN_2DS, type, &hidden_biases_pre_tfrmd_desc, num_dirs, num_hidden); status = zdnn_generate_transformed_desc_concatenated( &hidden_biases_pre_tfrmd_desc, RNN_TYPE_LSTM | USAGE_HIDDEN_BIASES | PREV_LAYER_NONE, &hidden_biases_tfrmd_desc); assert(status == ZDNN_OK); status = zdnn_init_ztensor_with_malloc( &hidden_biases_pre_tfrmd_desc, &hidden_biases_tfrmd_desc, &hidden_biases); assert(status == ZDNN_OK); uint64_t hidden_biases_data_size = num_hidden * element_size; void *hidden_biases_data_f = malloc(hidden_biases_data_size); void *hidden_biases_data_i = malloc(hidden_biases_data_size); void *hidden_biases_data_c = malloc(hidden_biases_data_size); void *hidden_biases_data_o = malloc(hidden_biases_data_size); status = zdnn_transform_ztensor(&hidden_biases, hidden_biases_data_f, hidden_biases_data_i, hidden_biases_data_c, hidden_biases_data_o); assert(status == ZDNN_OK); /*********************************************************************** * Create output zTensor ***********************************************************************/ // get only the last timestep, thus hn and cf can share descriptor zdnn_tensor_desc hncf_pre_tfrmd_desc, hncf_tfrmd_desc; zdnn_ztensor hn_output_ztensor, cf_output_ztensor; zdnn_init_pre_transformed_desc(ZDNN_4DS, type, &hncf_pre_tfrmd_desc, 1, 1, num_batches, num_hidden); status = zdnn_generate_transformed_desc(&hncf_pre_tfrmd_desc, &hncf_tfrmd_desc); assert(status == ZDNN_OK); status = zdnn_init_ztensor_with_malloc(&hncf_pre_tfrmd_desc, &hncf_tfrmd_desc, &hn_output_ztensor); assert(status == ZDNN_OK); status = zdnn_init_ztensor_with_malloc(&hncf_pre_tfrmd_desc, &hncf_tfrmd_desc, &cf_output_ztensor); assert(status == ZDNN_OK); /*********************************************************************** * Call the AIU ***********************************************************************/ void *work_area = NULL; status = zdnn_lstm(&input, &h0, &c0, &weights, &biases, &hidden_weights, &hidden_biases, dir, work_area, &hn_output_ztensor, &cf_output_ztensor); assert(status == ZDNN_OK); /*********************************************************************** * Output and Cleanup ***********************************************************************/ uint64_t hncf_data_size = num_batches * num_hidden * element_size; void *hn_output_data = malloc(hncf_data_size); void *cf_output_data = malloc(hncf_data_size); status = zdnn_transform_origtensor(&hn_output_ztensor, hn_output_data); assert(status == ZDNN_OK); status = zdnn_transform_origtensor(&cf_output_ztensor, cf_output_data); assert(status == ZDNN_OK); status = zdnn_free_ztensor_buffer(&input); assert(status == ZDNN_OK); status = zdnn_free_ztensor_buffer(&h0); assert(status == ZDNN_OK); status = zdnn_free_ztensor_buffer(&c0); assert(status == ZDNN_OK); status = zdnn_free_ztensor_buffer(&weights); assert(status == ZDNN_OK); status = zdnn_free_ztensor_buffer(&biases); assert(status == ZDNN_OK); status = zdnn_free_ztensor_buffer(&hidden_weights); assert(status == ZDNN_OK); status = zdnn_free_ztensor_buffer(&hidden_biases); assert(status == ZDNN_OK); status = zdnn_free_ztensor_buffer(&hn_output_ztensor); assert(status == ZDNN_OK); status = zdnn_free_ztensor_buffer(&cf_output_ztensor); assert(status == ZDNN_OK); free(input_data); free(hidden_state_data); free(cell_state_data); free(weights_data_f); free(weights_data_i); free(weights_data_c); free(weights_data_o); free(hidden_weights_data_f); free(hidden_weights_data_i); free(hidden_weights_data_c); free(hidden_weights_data_o); free(biases_data_f); free(biases_data_i); free(biases_data_c); free(biases_data_o); free(hidden_biases_data_f); free(hidden_biases_data_i); free(hidden_biases_data_c); free(hidden_biases_data_o); free(hn_output_data); free(cf_output_data); } Example of an application calling the zdnn_lstm API (bi-directional) \u00b6 Back to Table of Contents // SPDX-License-Identifier: Apache-2.0 /* * Copyright IBM Corp. 2021 * * Licensed under the Apache License, Version 2.0 (the \"License\"); * you may not use this file except in compliance with the License. * You may obtain a copy of the License at * * http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an \"AS IS\" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ #include <assert.h> #include <stdio.h> #include <stdlib.h> #include <string.h> #include \"zdnn.h\" // Sample: LSTM BI-DIR int main(int argc, char *argv[]) { zdnn_status status; #ifdef STATIC_LIB zdnn_init(); #endif /*********************************************************************** * * LSTM (BI-DIR): * * INPUTS -------------------------------------------------------------- * input | ZDNN_3DS | (num_timesteps, num_batches, num_features) * h0 | ZDNN_3DS | (2, num_batches, num_hidden) * c0 | ZDNN_3DS | (2, num_batches, num_hidden) * weights | ZDNN_3DS | (2, num_features, num_hidden) * biases | ZDNN_2DS | (2, num_hidden) * hidden_weights | ZDNN_3DS | (2, num_hidden, num_hidden) * hidden_biases | ZDNN_2DS | (2, num_hidden) * * OUTPUTS ------------------------------------------------------------- * hn_output | ZDNN_4DS | (num_timesteps, 2, num_batches, num_hidden) * | | or (1, 2, num_batches, num_hidden) * cf_output | ZDNN_4DS | (1, 2, num_batches, num_hidden) ***********************************************************************/ /*********************************************************************** * Create input zTensor ***********************************************************************/ zdnn_tensor_desc input_pre_tfrmd_desc, input_tfrmd_desc; zdnn_ztensor input; uint32_t num_timesteps = 5; uint32_t num_batches = 3; uint32_t num_features = 32; uint32_t num_hidden = 5; zdnn_data_types type = FP32; short element_size = 4; // size of each element in bytes lstm_gru_direction dir = BIDIR; uint8_t num_dirs = 2; zdnn_init_pre_transformed_desc(ZDNN_3DS, type, &input_pre_tfrmd_desc, num_timesteps, num_batches, num_features); status = zdnn_generate_transformed_desc(&input_pre_tfrmd_desc, &input_tfrmd_desc); assert(status == ZDNN_OK); status = zdnn_init_ztensor_with_malloc(&input_pre_tfrmd_desc, &input_tfrmd_desc, &input); assert(status == ZDNN_OK); uint64_t input_data_size = num_timesteps * num_batches * num_features * element_size; void *input_data = malloc(input_data_size); status = zdnn_transform_ztensor(&input, input_data); assert(status == ZDNN_OK); /*********************************************************************** * Create initial hidden and cell state zTensors ***********************************************************************/ zdnn_tensor_desc h0c0_pre_tfrmd_desc, h0c0_tfrmd_desc; zdnn_ztensor h0, c0; zdnn_init_pre_transformed_desc(ZDNN_3DS, type, &h0c0_pre_tfrmd_desc, num_dirs, num_batches, num_hidden); status = zdnn_generate_transformed_desc(&h0c0_pre_tfrmd_desc, &h0c0_tfrmd_desc); assert(status == ZDNN_OK); status = zdnn_init_ztensor_with_malloc(&h0c0_pre_tfrmd_desc, &h0c0_tfrmd_desc, &h0); assert(status == ZDNN_OK); status = zdnn_init_ztensor_with_malloc(&h0c0_pre_tfrmd_desc, &h0c0_tfrmd_desc, &c0); assert(status == ZDNN_OK); uint64_t h0c0_data_size = num_batches * num_hidden * element_size; void *hidden_state_data = malloc(h0c0_data_size); void *cell_state_data = malloc(h0c0_data_size); status = zdnn_transform_ztensor(&h0, hidden_state_data); assert(status == ZDNN_OK); status = zdnn_transform_ztensor(&c0, cell_state_data); assert(status == ZDNN_OK); /*********************************************************************** * Create input weights zTensor * Resultant zTensor is concatenated ***********************************************************************/ zdnn_tensor_desc weights_pre_tfrmd_desc, weights_tfrmd_desc; zdnn_ztensor weights; zdnn_init_pre_transformed_desc(ZDNN_3DS, type, &weights_pre_tfrmd_desc, num_dirs, num_features, num_hidden); status = zdnn_generate_transformed_desc_concatenated( &weights_pre_tfrmd_desc, RNN_TYPE_LSTM | USAGE_WEIGHTS | PREV_LAYER_NONE, &weights_tfrmd_desc); assert(status == ZDNN_OK); status = zdnn_init_ztensor_with_malloc(&weights_pre_tfrmd_desc, &weights_tfrmd_desc, &weights); assert(status == ZDNN_OK); uint64_t weights_data_size = num_features * num_hidden * element_size; void *weights_data_f = malloc(weights_data_size); void *weights_data_i = malloc(weights_data_size); void *weights_data_c = malloc(weights_data_size); void *weights_data_o = malloc(weights_data_size); status = zdnn_transform_ztensor(&weights, weights_data_f, weights_data_i, weights_data_c, weights_data_o); assert(status == ZDNN_OK); /*********************************************************************** * Create biases zTensors * Resultant zTensors are concatenated ***********************************************************************/ zdnn_tensor_desc biases_pre_tfrmd_desc, biases_tfrmd_desc; zdnn_ztensor biases; zdnn_init_pre_transformed_desc(ZDNN_2DS, type, &biases_pre_tfrmd_desc, num_dirs, num_hidden); status = zdnn_generate_transformed_desc_concatenated( &biases_pre_tfrmd_desc, RNN_TYPE_LSTM | USAGE_BIASES | PREV_LAYER_NONE, &biases_tfrmd_desc); assert(status == ZDNN_OK); status = zdnn_init_ztensor_with_malloc(&biases_pre_tfrmd_desc, &biases_tfrmd_desc, &biases); assert(status == ZDNN_OK); uint64_t biases_data_size = num_hidden * element_size; void *biases_data_f = malloc(biases_data_size); void *biases_data_i = malloc(biases_data_size); void *biases_data_c = malloc(biases_data_size); void *biases_data_o = malloc(biases_data_size); status = zdnn_transform_ztensor(&biases, biases_data_f, biases_data_i, biases_data_c, biases_data_o); assert(status == ZDNN_OK); /*********************************************************************** * Create hidden weights zTensor * Resultant zTensor is concatenated ***********************************************************************/ zdnn_tensor_desc hidden_weights_pre_tfrmd_desc, hidden_weights_tfrmd_desc; zdnn_ztensor hidden_weights; zdnn_init_pre_transformed_desc(ZDNN_3DS, type, &hidden_weights_pre_tfrmd_desc, num_dirs, num_hidden, num_hidden); status = zdnn_generate_transformed_desc_concatenated( &hidden_weights_pre_tfrmd_desc, RNN_TYPE_LSTM | USAGE_HIDDEN_WEIGHTS | PREV_LAYER_NONE, &hidden_weights_tfrmd_desc); assert(status == ZDNN_OK); status = zdnn_init_ztensor_with_malloc(&hidden_weights_pre_tfrmd_desc, &hidden_weights_tfrmd_desc, &hidden_weights); assert(status == ZDNN_OK); uint64_t hidden_weights_data_size = num_hidden * num_hidden * element_size; void *hidden_weights_data_f = malloc(hidden_weights_data_size); void *hidden_weights_data_i = malloc(hidden_weights_data_size); void *hidden_weights_data_c = malloc(hidden_weights_data_size); void *hidden_weights_data_o = malloc(hidden_weights_data_size); status = zdnn_transform_ztensor(&hidden_weights, hidden_weights_data_f, hidden_weights_data_i, hidden_weights_data_c, hidden_weights_data_o); assert(status == ZDNN_OK); /*********************************************************************** * Create hidden biases zTensors * Resultant zTensors are concatenated ***********************************************************************/ zdnn_tensor_desc hidden_biases_pre_tfrmd_desc, hidden_biases_tfrmd_desc; zdnn_ztensor hidden_biases; zdnn_init_pre_transformed_desc(ZDNN_2DS, type, &hidden_biases_pre_tfrmd_desc, num_dirs, num_hidden); status = zdnn_generate_transformed_desc_concatenated( &hidden_biases_pre_tfrmd_desc, RNN_TYPE_LSTM | USAGE_HIDDEN_BIASES | PREV_LAYER_NONE, &hidden_biases_tfrmd_desc); assert(status == ZDNN_OK); status = zdnn_init_ztensor_with_malloc( &hidden_biases_pre_tfrmd_desc, &hidden_biases_tfrmd_desc, &hidden_biases); assert(status == ZDNN_OK); uint64_t hidden_biases_data_size = num_hidden * element_size; void *hidden_biases_data_f = malloc(hidden_biases_data_size); void *hidden_biases_data_i = malloc(hidden_biases_data_size); void *hidden_biases_data_c = malloc(hidden_biases_data_size); void *hidden_biases_data_o = malloc(hidden_biases_data_size); status = zdnn_transform_ztensor(&hidden_biases, hidden_biases_data_f, hidden_biases_data_i, hidden_biases_data_c, hidden_biases_data_o); assert(status == ZDNN_OK); /*********************************************************************** * Create output zTensor ***********************************************************************/ zdnn_tensor_desc hn_pre_tfrmd_desc, hn_tfrmd_desc, cf_pre_tfrmd_desc, cf_tfrmd_desc; zdnn_ztensor hn_output_ztensor, cf_output_ztensor; zdnn_init_pre_transformed_desc(ZDNN_4DS, type, &hn_pre_tfrmd_desc, num_timesteps, 2, num_batches, num_hidden); status = zdnn_generate_transformed_desc(&hn_pre_tfrmd_desc, &hn_tfrmd_desc); assert(status == ZDNN_OK); zdnn_init_pre_transformed_desc(ZDNN_3DS, type, &cf_pre_tfrmd_desc, 1, 2, num_batches, num_hidden); status = zdnn_generate_transformed_desc(&cf_pre_tfrmd_desc, &cf_tfrmd_desc); assert(status == ZDNN_OK); status = zdnn_init_ztensor_with_malloc(&hn_pre_tfrmd_desc, &hn_tfrmd_desc, &hn_output_ztensor); assert(status == ZDNN_OK); status = zdnn_init_ztensor_with_malloc(&cf_pre_tfrmd_desc, &cf_tfrmd_desc, &cf_output_ztensor); assert(status == ZDNN_OK); /*********************************************************************** * Call the AIU ***********************************************************************/ void *work_area = NULL; status = zdnn_lstm(&input, &h0, &c0, &weights, &biases, &hidden_weights, &hidden_biases, dir, work_area, &hn_output_ztensor, &cf_output_ztensor); assert(status == ZDNN_OK); /*********************************************************************** * Output and Cleanup ***********************************************************************/ uint64_t hn_data_size = num_timesteps * 2 * num_batches * num_hidden * element_size; uint64_t cf_data_size = 2 * num_batches * num_hidden * element_size; void *hn_output_data = malloc(hn_data_size); void *cf_output_data = malloc(cf_data_size); status = zdnn_transform_origtensor(&hn_output_ztensor, hn_output_data); assert(status == ZDNN_OK); status = zdnn_transform_origtensor(&cf_output_ztensor, cf_output_data); assert(status == ZDNN_OK); status = zdnn_free_ztensor_buffer(&input); assert(status == ZDNN_OK); status = zdnn_free_ztensor_buffer(&h0); assert(status == ZDNN_OK); status = zdnn_free_ztensor_buffer(&c0); assert(status == ZDNN_OK); status = zdnn_free_ztensor_buffer(&weights); assert(status == ZDNN_OK); status = zdnn_free_ztensor_buffer(&biases); assert(status == ZDNN_OK); status = zdnn_free_ztensor_buffer(&hidden_weights); assert(status == ZDNN_OK); status = zdnn_free_ztensor_buffer(&hidden_biases); assert(status == ZDNN_OK); status = zdnn_free_ztensor_buffer(&hn_output_ztensor); assert(status == ZDNN_OK); status = zdnn_free_ztensor_buffer(&cf_output_ztensor); assert(status == ZDNN_OK); free(input_data); free(hidden_state_data); free(cell_state_data); free(weights_data_f); free(weights_data_i); free(weights_data_c); free(weights_data_o); free(hidden_weights_data_f); free(hidden_weights_data_i); free(hidden_weights_data_c); free(hidden_weights_data_o); free(biases_data_f); free(biases_data_i); free(biases_data_c); free(biases_data_o); free(hidden_biases_data_f); free(hidden_biases_data_i); free(hidden_biases_data_c); free(hidden_biases_data_o); free(hn_output_data); free(cf_output_data); } Example of an application calling the zdnn_lstm API (multi-layer bi-directional) \u00b6 Back to Table of Contents // SPDX-License-Identifier: Apache-2.0 /* * Copyright IBM Corp. 2021 * * Licensed under the Apache License, Version 2.0 (the \"License\"); * you may not use this file except in compliance with the License. * You may obtain a copy of the License at * * http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an \"AS IS\" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ #include <assert.h> #include <stdio.h> #include <stdlib.h> #include <string.h> #include \"zdnn.h\" void do_bidir_layer(zdnn_ztensor *input, uint32_t num_hidden, zdnn_ztensor *hn_output, bool is_prev_layer_bidir) { zdnn_status status; uint32_t num_batches = input->pre_transformed_desc->dim2; // if input is bidir output from previous layer then number of features for // this layer is 2x of hidden-state size (dim1) of the previous layer uint32_t num_features = input->pre_transformed_desc->dim1 * (is_prev_layer_bidir ? 2 : 1); zdnn_data_types type = FP32; short element_size = 4; // size of each element in bytes lstm_gru_direction dir = BIDIR; uint8_t num_dirs = 2; /*********************************************************************** * Create initial hidden and cell state zTensors ***********************************************************************/ zdnn_tensor_desc h0c0_pre_tfrmd_desc, h0c0_tfrmd_desc; zdnn_ztensor h0, c0; zdnn_init_pre_transformed_desc(ZDNN_3DS, type, &h0c0_pre_tfrmd_desc, num_dirs, num_batches, num_hidden); status = zdnn_generate_transformed_desc(&h0c0_pre_tfrmd_desc, &h0c0_tfrmd_desc); assert(status == ZDNN_OK); status = zdnn_init_ztensor_with_malloc(&h0c0_pre_tfrmd_desc, &h0c0_tfrmd_desc, &h0); assert(status == ZDNN_OK); status = zdnn_init_ztensor_with_malloc(&h0c0_pre_tfrmd_desc, &h0c0_tfrmd_desc, &c0); assert(status == ZDNN_OK); uint64_t h0c0_data_size = num_batches * num_hidden * element_size; void *hidden_state_data = malloc(h0c0_data_size); void *cell_state_data = malloc(h0c0_data_size); status = zdnn_transform_ztensor(&h0, hidden_state_data); assert(status == ZDNN_OK); status = zdnn_transform_ztensor(&c0, cell_state_data); assert(status == ZDNN_OK); /*********************************************************************** * Create input weights zTensor * Resultant zTensor is concatenated ***********************************************************************/ zdnn_tensor_desc weights_pre_tfrmd_desc, weights_tfrmd_desc; zdnn_ztensor weights; // if using previous layer bidir output as input then number of features of // this layer is zdnn_init_pre_transformed_desc(ZDNN_3DS, type, &weights_pre_tfrmd_desc, num_dirs, num_features, num_hidden); status = zdnn_generate_transformed_desc_concatenated( &weights_pre_tfrmd_desc, RNN_TYPE_LSTM | USAGE_WEIGHTS | (is_prev_layer_bidir ? PREV_LAYER_BIDIR : PREV_LAYER_UNI), &weights_tfrmd_desc); assert(status == ZDNN_OK); status = zdnn_init_ztensor_with_malloc(&weights_pre_tfrmd_desc, &weights_tfrmd_desc, &weights); assert(status == ZDNN_OK); uint64_t weights_data_size = num_features * num_hidden * element_size; void *weights_data_f = malloc(weights_data_size); void *weights_data_i = malloc(weights_data_size); void *weights_data_c = malloc(weights_data_size); void *weights_data_o = malloc(weights_data_size); status = zdnn_transform_ztensor(&weights, weights_data_f, weights_data_i, weights_data_c, weights_data_o); assert(status == ZDNN_OK); /*********************************************************************** * Create biases zTensors * Resultant zTensors are concatenated ***********************************************************************/ zdnn_tensor_desc biases_pre_tfrmd_desc, biases_tfrmd_desc; zdnn_ztensor biases; zdnn_init_pre_transformed_desc(ZDNN_2DS, type, &biases_pre_tfrmd_desc, num_dirs, num_hidden); status = zdnn_generate_transformed_desc_concatenated( &biases_pre_tfrmd_desc, RNN_TYPE_LSTM | USAGE_BIASES | (is_prev_layer_bidir ? PREV_LAYER_BIDIR : PREV_LAYER_UNI), &biases_tfrmd_desc); assert(status == ZDNN_OK); status = zdnn_init_ztensor_with_malloc(&biases_pre_tfrmd_desc, &biases_tfrmd_desc, &biases); assert(status == ZDNN_OK); uint64_t biases_data_size = num_hidden * element_size; void *biases_data_f = malloc(biases_data_size); void *biases_data_i = malloc(biases_data_size); void *biases_data_c = malloc(biases_data_size); void *biases_data_o = malloc(biases_data_size); status = zdnn_transform_ztensor(&biases, biases_data_f, biases_data_i, biases_data_c, biases_data_o); assert(status == ZDNN_OK); /*********************************************************************** * Create hidden weights zTensor * Resultant zTensor is concatenated ***********************************************************************/ zdnn_tensor_desc hidden_weights_pre_tfrmd_desc, hidden_weights_tfrmd_desc; zdnn_ztensor hidden_weights; zdnn_init_pre_transformed_desc(ZDNN_3DS, type, &hidden_weights_pre_tfrmd_desc, num_dirs, num_hidden, num_hidden); status = zdnn_generate_transformed_desc_concatenated( &hidden_weights_pre_tfrmd_desc, RNN_TYPE_LSTM | USAGE_HIDDEN_WEIGHTS | (is_prev_layer_bidir ? PREV_LAYER_BIDIR : PREV_LAYER_UNI), &hidden_weights_tfrmd_desc); assert(status == ZDNN_OK); status = zdnn_init_ztensor_with_malloc(&hidden_weights_pre_tfrmd_desc, &hidden_weights_tfrmd_desc, &hidden_weights); assert(status == ZDNN_OK); uint64_t hidden_weights_data_size = num_hidden * num_hidden * element_size; void *hidden_weights_data_f = malloc(hidden_weights_data_size); void *hidden_weights_data_i = malloc(hidden_weights_data_size); void *hidden_weights_data_c = malloc(hidden_weights_data_size); void *hidden_weights_data_o = malloc(hidden_weights_data_size); status = zdnn_transform_ztensor(&hidden_weights, hidden_weights_data_f, hidden_weights_data_i, hidden_weights_data_c, hidden_weights_data_o); assert(status == ZDNN_OK); /*********************************************************************** * Create hidden biases zTensors * Resultant zTensors are concatenated ***********************************************************************/ zdnn_tensor_desc hidden_biases_pre_tfrmd_desc, hidden_biases_tfrmd_desc; zdnn_ztensor hidden_biases; zdnn_init_pre_transformed_desc(ZDNN_2DS, type, &hidden_biases_pre_tfrmd_desc, num_dirs, num_hidden); status = zdnn_generate_transformed_desc_concatenated( &hidden_biases_pre_tfrmd_desc, RNN_TYPE_LSTM | USAGE_HIDDEN_BIASES | (is_prev_layer_bidir ? PREV_LAYER_BIDIR : PREV_LAYER_UNI), &hidden_biases_tfrmd_desc); assert(status == ZDNN_OK); status = zdnn_init_ztensor_with_malloc( &hidden_biases_pre_tfrmd_desc, &hidden_biases_tfrmd_desc, &hidden_biases); assert(status == ZDNN_OK); uint64_t hidden_biases_data_size = num_hidden * element_size; void *hidden_biases_data_f = malloc(hidden_biases_data_size); void *hidden_biases_data_i = malloc(hidden_biases_data_size); void *hidden_biases_data_c = malloc(hidden_biases_data_size); void *hidden_biases_data_o = malloc(hidden_biases_data_size); status = zdnn_transform_ztensor(&hidden_biases, hidden_biases_data_f, hidden_biases_data_i, hidden_biases_data_c, hidden_biases_data_o); assert(status == ZDNN_OK); /*********************************************************************** * Create cf output zTensor ***********************************************************************/ zdnn_tensor_desc cf_pre_tfrmd_desc, cf_tfrmd_desc; zdnn_ztensor cf_output_ztensor; zdnn_init_pre_transformed_desc(ZDNN_4DS, type, &cf_pre_tfrmd_desc, 1, 2, num_batches, num_hidden); status = zdnn_generate_transformed_desc(&cf_pre_tfrmd_desc, &cf_tfrmd_desc); assert(status == ZDNN_OK); status = zdnn_init_ztensor_with_malloc(&cf_pre_tfrmd_desc, &cf_tfrmd_desc, &cf_output_ztensor); assert(status == ZDNN_OK); /*********************************************************************** * Call the AIU ***********************************************************************/ void *work_area = NULL; status = zdnn_lstm(input, &h0, &c0, &weights, &biases, &hidden_weights, &hidden_biases, dir, work_area, hn_output, &cf_output_ztensor); assert(status == ZDNN_OK); /*********************************************************************** * Cleanup and Return ***********************************************************************/ status = zdnn_free_ztensor_buffer(&h0); assert(status == ZDNN_OK); status = zdnn_free_ztensor_buffer(&c0); assert(status == ZDNN_OK); status = zdnn_free_ztensor_buffer(&weights); assert(status == ZDNN_OK); status = zdnn_free_ztensor_buffer(&biases); assert(status == ZDNN_OK); status = zdnn_free_ztensor_buffer(&hidden_weights); assert(status == ZDNN_OK); status = zdnn_free_ztensor_buffer(&hidden_biases); assert(status == ZDNN_OK); status = zdnn_free_ztensor_buffer(&cf_output_ztensor); assert(status == ZDNN_OK); free(hidden_state_data); free(cell_state_data); free(weights_data_f); free(weights_data_i); free(weights_data_c); free(weights_data_o); free(hidden_weights_data_f); free(hidden_weights_data_i); free(hidden_weights_data_c); free(hidden_weights_data_o); free(biases_data_f); free(biases_data_i); free(biases_data_c); free(biases_data_o); free(hidden_biases_data_f); free(hidden_biases_data_i); free(hidden_biases_data_c); free(hidden_biases_data_o); } // Sample: LSTM multi-layer BIDIR int main(int argc, char *argv[]) { zdnn_status status; #ifdef STATIC_LIB zdnn_init(); #endif uint32_t num_hidden[2] = {5, 4}; /*********************************************************************** * Create input zTensor ***********************************************************************/ zdnn_tensor_desc input_pre_tfrmd_desc, input_tfrmd_desc; zdnn_ztensor input; uint32_t num_timesteps = 5; uint32_t num_batches = 3; uint32_t num_features = 32; zdnn_data_types type = FP32; short element_size = 4; // size of each element in bytes zdnn_init_pre_transformed_desc(ZDNN_3DS, type, &input_pre_tfrmd_desc, num_timesteps, num_batches, num_features); status = zdnn_generate_transformed_desc(&input_pre_tfrmd_desc, &input_tfrmd_desc); assert(status == ZDNN_OK); status = zdnn_init_ztensor_with_malloc(&input_pre_tfrmd_desc, &input_tfrmd_desc, &input); assert(status == ZDNN_OK); uint64_t input_data_size = num_timesteps * num_batches * num_features * element_size; void *input_data = malloc(input_data_size); status = zdnn_transform_ztensor(&input, input_data); assert(status == ZDNN_OK); /*********************************************************************** * Create 2 hn output zTensors ***********************************************************************/ zdnn_tensor_desc hn_pre_tfrmd_desc[2], hn_tfrmd_desc[2]; zdnn_ztensor hn_output[2]; for (int i = 0; i < 2; i++) { zdnn_init_pre_transformed_desc(ZDNN_4DS, type, &hn_pre_tfrmd_desc[i], num_timesteps, 2, num_batches, num_hidden[i]); status = zdnn_generate_transformed_desc(&hn_pre_tfrmd_desc[i], &hn_tfrmd_desc[i]); assert(status == ZDNN_OK); status = zdnn_init_ztensor_with_malloc(&hn_pre_tfrmd_desc[i], &hn_tfrmd_desc[i], &hn_output[i]); assert(status == ZDNN_OK); } /*********************************************************************** * Do the layers ***********************************************************************/ // call the first layer with input, previous layer bidir = false, output goes // to hn_output[0] do_bidir_layer(&input, num_hidden[0], &hn_output[0], false); // call the second layer with hn_output[0] from layer 1, previous layer bidir // = true, output goes to hn_output[1] do_bidir_layer(&hn_output[0], num_hidden[1], &hn_output[1], true); /*********************************************************************** * Output and Cleanup ***********************************************************************/ void *hn_output_data[2]; for (int i = 0; i < 2; i++) { uint64_t hn_output_data_size = (uint64_t)num_timesteps * num_batches * num_hidden[i] * 2 * element_size; hn_output_data[i] = malloc(hn_output_data_size); status = zdnn_transform_origtensor(&hn_output[i], hn_output_data[i]); assert(status == ZDNN_OK); } status = zdnn_free_ztensor_buffer(&input); assert(status == ZDNN_OK); status = zdnn_free_ztensor_buffer(&hn_output[0]); assert(status == ZDNN_OK); status = zdnn_free_ztensor_buffer(&hn_output[1]); assert(status == ZDNN_OK); free(input_data); free(hn_output_data[0]); free(hn_output_data[1]); } Example of an application calling the zdnn_gru API (forward) \u00b6 Back to Table of Contents // SPDX-License-Identifier: Apache-2.0 /* * Copyright IBM Corp. 2021 * * Licensed under the Apache License, Version 2.0 (the \"License\"); * you may not use this file except in compliance with the License. * You may obtain a copy of the License at * * http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an \"AS IS\" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ #include <assert.h> #include <stdio.h> #include <stdlib.h> #include <string.h> #include \"zdnn.h\" // Sample: GRU int main(int argc, char *argv[]) { zdnn_status status; #ifdef STATIC_LIB zdnn_init(); #endif /*********************************************************************** * * GRU (FWD/BWD): * * INPUTS -------------------------------------------------------------- * input | ZDNN_3DS | (num_timesteps, num_batches, num_features) * h0 | ZDNN_3DS | (1, num_batches, num_hidden) * weights | ZDNN_3DS | (1, num_features, num_hidden) * input_biases | ZDNN_2DS | (1, num_hidden) * hidden_weights | ZDNN_3DS | (1, num_hidden, num_hidden) * hidden_biases | ZDNN_2DS | (1, num_hidden) * * OUTPUTS ------------------------------------------------------------- * hn_output | ZDNN_4DS | (num_timesteps, 1, num_batches, num_hidden) * | | or (1, 1, num_batches, num_hidden) ***********************************************************************/ /*********************************************************************** * Create input zTensor ***********************************************************************/ zdnn_tensor_desc input_pre_tfrmd_desc, input_tfrmd_desc; zdnn_ztensor input; uint32_t num_timesteps = 5; uint32_t num_batches = 3; uint32_t num_features = 32; uint32_t num_hidden = 5; zdnn_data_types type = FP32; short element_size = 4; // size of each element in bytes lstm_gru_direction dir = FWD; uint8_t num_dirs = 1; zdnn_init_pre_transformed_desc(ZDNN_3DS, type, &input_pre_tfrmd_desc, num_timesteps, num_batches, num_features); status = zdnn_generate_transformed_desc(&input_pre_tfrmd_desc, &input_tfrmd_desc); assert(status == ZDNN_OK); status = zdnn_init_ztensor_with_malloc(&input_pre_tfrmd_desc, &input_tfrmd_desc, &input); assert(status == ZDNN_OK); uint64_t input_data_size = num_timesteps * num_batches * num_features * element_size; void *input_data = malloc(input_data_size); status = zdnn_transform_ztensor(&input, input_data); assert(status == ZDNN_OK); /*********************************************************************** * Create initial hidden zTensor ***********************************************************************/ zdnn_tensor_desc h0_pre_tfrmd_desc, h0_tfrmd_desc; zdnn_ztensor h0; zdnn_init_pre_transformed_desc(ZDNN_3DS, type, &h0_pre_tfrmd_desc, num_dirs, num_batches, num_hidden); status = zdnn_generate_transformed_desc(&h0_pre_tfrmd_desc, &h0_tfrmd_desc); assert(status == ZDNN_OK); status = zdnn_init_ztensor_with_malloc(&h0_pre_tfrmd_desc, &h0_tfrmd_desc, &h0); assert(status == ZDNN_OK); uint64_t h0_data_size = num_batches * num_hidden * element_size; void *hidden_state_data = malloc(h0_data_size); status = zdnn_transform_ztensor(&h0, hidden_state_data); assert(status == ZDNN_OK); /*********************************************************************** * Create input weights zTensor * Resultant zTensor is concatenated ***********************************************************************/ zdnn_tensor_desc weights_pre_tfrmd_desc, weights_tfrmd_desc; zdnn_ztensor weights; zdnn_init_pre_transformed_desc(ZDNN_3DS, type, &weights_pre_tfrmd_desc, num_dirs, num_features, num_hidden); status = zdnn_generate_transformed_desc_concatenated( &weights_pre_tfrmd_desc, RNN_TYPE_GRU | USAGE_WEIGHTS | PREV_LAYER_NONE, &weights_tfrmd_desc); assert(status == ZDNN_OK); status = zdnn_init_ztensor_with_malloc(&weights_pre_tfrmd_desc, &weights_tfrmd_desc, &weights); assert(status == ZDNN_OK); uint64_t weights_data_size = num_features * num_hidden * element_size; void *weights_data_z = malloc(weights_data_size); void *weights_data_r = malloc(weights_data_size); void *weights_data_h = malloc(weights_data_size); status = zdnn_transform_ztensor(&weights, weights_data_z, weights_data_r, weights_data_h); assert(status == ZDNN_OK); /*********************************************************************** * Create biases zTensors * Resultant zTensors are concatenated ***********************************************************************/ zdnn_tensor_desc biases_pre_tfrmd_desc, biases_tfrmd_desc; zdnn_ztensor biases; zdnn_init_pre_transformed_desc(ZDNN_2DS, type, &biases_pre_tfrmd_desc, num_dirs, num_hidden); status = zdnn_generate_transformed_desc_concatenated( &biases_pre_tfrmd_desc, RNN_TYPE_GRU | USAGE_BIASES | PREV_LAYER_NONE, &biases_tfrmd_desc); assert(status == ZDNN_OK); status = zdnn_init_ztensor_with_malloc(&biases_pre_tfrmd_desc, &biases_tfrmd_desc, &biases); assert(status == ZDNN_OK); uint64_t biases_data_size = num_hidden * element_size; void *biases_data_z = malloc(biases_data_size); void *biases_data_r = malloc(biases_data_size); void *biases_data_h = malloc(biases_data_size); status = zdnn_transform_ztensor(&biases, biases_data_z, biases_data_r, biases_data_h); assert(status == ZDNN_OK); /*********************************************************************** * Create hidden weights zTensor * Resultant zTensor is concatenated ***********************************************************************/ zdnn_tensor_desc hidden_weights_pre_tfrmd_desc, hidden_weights_tfrmd_desc; zdnn_ztensor hidden_weights; zdnn_init_pre_transformed_desc(ZDNN_3DS, type, &hidden_weights_pre_tfrmd_desc, num_dirs, num_hidden, num_hidden); status = zdnn_generate_transformed_desc_concatenated( &hidden_weights_pre_tfrmd_desc, RNN_TYPE_GRU | USAGE_HIDDEN_WEIGHTS | PREV_LAYER_NONE, &hidden_weights_tfrmd_desc); assert(status == ZDNN_OK); status = zdnn_init_ztensor_with_malloc(&hidden_weights_pre_tfrmd_desc, &hidden_weights_tfrmd_desc, &hidden_weights); assert(status == ZDNN_OK); uint64_t hidden_weights_data_size = num_hidden * num_hidden * element_size; void *hidden_weights_data_z = malloc(hidden_weights_data_size); void *hidden_weights_data_r = malloc(hidden_weights_data_size); void *hidden_weights_data_h = malloc(hidden_weights_data_size); status = zdnn_transform_ztensor(&hidden_weights, hidden_weights_data_z, hidden_weights_data_r, hidden_weights_data_h); assert(status == ZDNN_OK); /*********************************************************************** * Create hidden biases zTensors * Resultant zTensors are concatenated ***********************************************************************/ zdnn_tensor_desc hidden_biases_pre_tfrmd_desc, hidden_biases_tfrmd_desc; zdnn_ztensor hidden_biases; zdnn_init_pre_transformed_desc(ZDNN_2DS, type, &hidden_biases_pre_tfrmd_desc, num_dirs, num_hidden); status = zdnn_generate_transformed_desc_concatenated( &hidden_biases_pre_tfrmd_desc, RNN_TYPE_GRU | USAGE_HIDDEN_BIASES | PREV_LAYER_NONE, &hidden_biases_tfrmd_desc); assert(status == ZDNN_OK); status = zdnn_init_ztensor_with_malloc( &hidden_biases_pre_tfrmd_desc, &hidden_biases_tfrmd_desc, &hidden_biases); assert(status == ZDNN_OK); uint64_t hidden_biases_data_size = num_hidden * element_size; void *hidden_biases_data_z = malloc(hidden_biases_data_size); void *hidden_biases_data_r = malloc(hidden_biases_data_size); void *hidden_biases_data_h = malloc(hidden_biases_data_size); status = zdnn_transform_ztensor(&hidden_biases, hidden_biases_data_z, hidden_biases_data_r, hidden_biases_data_h); assert(status == ZDNN_OK); /*********************************************************************** * Create output zTensor ***********************************************************************/ // get only the last timestep zdnn_tensor_desc hn_pre_tfrmd_desc, hn_tfrmd_desc; zdnn_ztensor hn_output_ztensor; zdnn_init_pre_transformed_desc(ZDNN_4DS, type, &hn_pre_tfrmd_desc, 1, 1, num_batches, num_hidden); status = zdnn_generate_transformed_desc(&hn_pre_tfrmd_desc, &hn_tfrmd_desc); assert(status == ZDNN_OK); status = zdnn_init_ztensor_with_malloc(&hn_pre_tfrmd_desc, &hn_tfrmd_desc, &hn_output_ztensor); assert(status == ZDNN_OK); /*********************************************************************** * Call the AIU ***********************************************************************/ void *work_area = NULL; status = zdnn_gru(&input, &h0, &weights, &biases, &hidden_weights, &hidden_biases, dir, work_area, &hn_output_ztensor); assert(status == ZDNN_OK); /*********************************************************************** * Output and Cleanup ***********************************************************************/ uint64_t hn_data_size = num_batches * num_hidden * element_size; void *hn_output_data = malloc(hn_data_size); status = zdnn_transform_origtensor(&hn_output_ztensor, hn_output_data); assert(status == ZDNN_OK); status = zdnn_free_ztensor_buffer(&input); assert(status == ZDNN_OK); status = zdnn_free_ztensor_buffer(&h0); assert(status == ZDNN_OK); status = zdnn_free_ztensor_buffer(&weights); assert(status == ZDNN_OK); status = zdnn_free_ztensor_buffer(&biases); assert(status == ZDNN_OK); status = zdnn_free_ztensor_buffer(&hidden_weights); assert(status == ZDNN_OK); status = zdnn_free_ztensor_buffer(&hidden_biases); assert(status == ZDNN_OK); status = zdnn_free_ztensor_buffer(&hn_output_ztensor); assert(status == ZDNN_OK); free(input_data); free(hidden_state_data); free(weights_data_z); free(weights_data_r); free(weights_data_h); free(hidden_weights_data_z); free(hidden_weights_data_r); free(hidden_weights_data_h); free(biases_data_z); free(biases_data_r); free(biases_data_h); free(hidden_biases_data_z); free(hidden_biases_data_r); free(hidden_biases_data_h); free(hn_output_data); }","title":"zDNN API Reference"},{"location":"zDNN/#zdnn-api-reference","text":"","title":"zDNN API Reference"},{"location":"zDNN/#contacts","text":"Nicholas Marion (nmarion@us.ibm.com) Andreas Krebbel (krebbel@linux.ibm.com)","title":"Contacts"},{"location":"zDNN/#version","text":"0.4.0","title":"Version"},{"location":"zDNN/#table-of-contents","text":"Overview Environment Common Data Types and Structs Version Information zDNN zTensor General zTensor Requirements Concatenated zTensor Requirements zDNN Tensor Descriptors zDNN Data Layouts zDNN Data Formats zDNN Data Types zDNN Statuses Runtime Environment Variables API Reference Support Functions Data Transformation Operations Element-wise Activation Normalization Matmul with Operation Matmul Broadcast with Operation LSTM GRU Average Pool 2D Max Pool 2D Convolution 2D Convenience Functions Usage Examples","title":"Table of Contents "},{"location":"zDNN/#overview","text":"Deep Learning Library - the deep learning library support (zDNN) is the SW enablement technology provided by IBM to meet the following requirements: Specialized-function-assist instructions are intended to provide performance improvements for specific operations used in software libraries, utilities, and operating system (OS) services. The facilities and instructions described as specialized-function-assist instructions may be replaced or removed in the future. As such, the IBM recommendation for these instructions is that a software library or operating system function be used instead of directly accessing the instructions. This is the function provided by zDNN. zAIU has very complex data layout requirements; these requirements arrange the tensor to enhance the performance characteristics of the operations. zDNN will format the tensor appropriately on behalf of the caller, and it will do so using an optimized approach. For deep learning operations, zAIU requires the use of an internal data type (DLFLOAT16). This is a 2-byte data type, similar in concept to Brain float (BFLOAT); that is, it is an AI optimized format that is used to speed up training and inference (from 4-byte formats) while minimizing the loss of accuracy at inference time. The zDNN library will provide a set of APIs that an exploiter will utilize to drive the desired request. zDNN will be available on both z/OS and Linux on Z; the inclusion of Linux on Z provides particular benefit, as it will allow us to enable acceleration in frameworks for z/OS via z/OS Container Extensions (zCX).","title":"Overview"},{"location":"zDNN/#environment","text":"z/OS: Problem state AMODE64 XPLINK","title":"Environment"},{"location":"zDNN/#alignment-requirements","text":"","title":"Alignment requirements"},{"location":"zDNN/#aiu-op-limits","text":"This implies a zDNN limitation as well at this point. For all ops: Number of elements in any dimension must not exceed the value returned by zdnn_get_nnpa_max_dim_idx_size() Total number of bytes required for storing a transformed tensor must not exceed the value returned by zdnn_get_nnpa_max_tensor_size()","title":"AIU Op Limits"},{"location":"zDNN/#application-interfaces-for-zaiu-enterprise-neural-network-inference","text":"","title":"Application interfaces for zAIU Enterprise Neural Network Inference"},{"location":"zDNN/#zdnn-general","text":"The zDNN deep learning library provides the standard IBM Z software interface to the zAIU. This IBM-provided C library provides a set of functions that handle the data transformation requirements of the AIU and provide wrapper functions for the NNPA instruction primitives. The zDNN functions use the following criteria to determine if zAIU can be used to accelerate a deep learning primitive: Neural Network Processing Assist (NNPA) facility indicator in the system STFLE output. Output of the NNPA-QAF (Query Available Functions) request.","title":"zDNN General"},{"location":"zDNN/#using-zdnn","text":"To use the IBM-provided zDNN C library for the NNPA instruction, follow these steps: Link or re-link applications to use the IBM-provided zDNN. The IBM-provided zDNN is a library file in the z/OS UNIX System Services file system and can be statically or dynamically linked into your applications. The paths for the zDNN archive file and the zDNN header files are: z/OS (LE required): Path for 64-bit dynamic library files: /lib/libzdnn.so /lib/libzdnn.x Path for the zDNN header files: /usr/include/ The XL C/C++ compiler and the z/OS Language Environment provide various environment variables to control processing, in addition to the variables provided by the zDNN library itself. Use the environment variable _CEE_RUNOPTS to specify invocation Language Environment runtime options. For more information about using the environment variable _CEE_RUNOPTS and other C and LE variables, see z/OS XL C/C++ Programming Guide. For environment variables accepted by the zDNN library, see Runtime Environment Variables . Linux on Z: On Linux on Z we expect to ship source as well a package-installable library and header. The library installation will conform to the standards of the packaging method chosen.","title":"Using zDNN"},{"location":"zDNN/#common-types-and-structs","text":"Include Files: zdnn.h","title":"Common Types and Structs"},{"location":"zDNN/#version-information","text":"Back to Table of Contents #define ZDNN_VERSION \"0.4.0\" #define ZDNN_VERNUM 0x000400 // 0x[major][minor][patch] #define ZDNN_VER_MAJOR 0 #define ZDNN_VER_MINOR 4 #define ZDNN_VER_PATCH 0 zDNN major version ( ZDNN_VER_MAJOR ) will be incremented if any backwards incompatible changes are introduced to the API. It may also include minor and patch level changes. Patch and minor version will be reset to 0 when major version is incremented. zDNN minor version ( ZDNN_VER_MINOR ) will be incremented if new, backwards compatible functionalities are introduced to the API or if any API functionalities are marked as deprecated. It may also include patch level changes. Patch version will be reset to 0 when minor version is incremented. zDNN patch version ( ZDNN_VER_PATCH ) will be incremented if only backwards compatible bug fixes are introduced. A bug fix being defined as an internal change that fixes incorrect behavior. Functions for checking version incompatibility with the zDNN load library are provided and described in the Support Functions section.","title":"Version Information "},{"location":"zDNN/#zdnn-ztensor","text":"Back to Table of Contents typedef struct zdnn_ztensor { zdnn_tensor_desc *pre_transformed_desc; // tensor's shape information before transformation zdnn_tensor_desc *transformed_desc; // transformed tensor's shape information uint64_t buffer_size; // tensor size in bytes void *buffer; // pointer to the tensor in memory bool is_transformed; // indicator if data in buffer has been transformed char reserved[31]; // not currently used, should contain zeros. } zdnn_ztensor;","title":"zDNN zTensor "},{"location":"zDNN/#general-ztensor-requirements","text":"Back to Table of Contents buffer requirements: Calling zdnn_init_ztensor_with_malloc automatically allocates and sets a valid buffer for a tensor. buffer field must point to storage allocated of sufficient size to contain the transformed tensor data described by the its transformed_desc field. Calling zdnn_getsize_ztensor with the tensor's transformed_desc returns the required size. Start of buffer field must be 4k aligned. reserved should contain zeros, otherwise the program may not operate compatibly in the future. Calling zdnn_init_ztensor or zdnn_init_ztensor_with_malloc will set reserved to zeros.","title":"General zTensor Requirements "},{"location":"zDNN/#concatenated-ztensor-requirements","text":"Back to Table of Contents For use with weights/biases/hidden-weights/hidden-biases RNN-gates tensors. You must use zdnn_generate_transformed_desc_concatenated with the appropriate concatenation info Do not use zdnn_generate_transformed_desc with concatenated tensors The pre-transformed shape dimensions should not include the concatenation. Thus, the pre-transformed shape should be that of a single gate, not the shape of the combined gates Afterward transform with zdnn_transform_ztensor as normal Must follow general tensor requirements","title":"Concatenated zTensor Requirements "},{"location":"zDNN/#zdnn-tensor-descriptors","text":"Back to Table of Contents typedef struct zdnn_tensor_desc { zdnn_data_layouts layout; // data layout zdnn_data_formats format; // internal use only zdnn_data_types type; // data type uint32_t dim4; // number of elements in outermost dimension uint32_t dim3; // ... outer dimension uint32_t dim2; // ... inner dimension uint32_t dim1; // number of elements in innermost dimension } zdnn_tensor_desc;","title":"zDNN Tensor Descriptors "},{"location":"zDNN/#programming-notes","text":"Helper methods zdnn_init_pre_transformed_desc and zdnn_generate_transformed_desc or zdnn_generate_transformed_desc_concatenated will set the correct dims based on the layout and format. The layout of the tensor descriptor affects the expected order of the dims. For example: For tensors with less than 4 dimensions, unspecified dims: In the pre_transformed_desc are ignored. For example a ZDNN_3D expects values in dim4, dim3, and dim2. In the transformed_desc \"unused\" dims must be 1. A ZDNN_NCHW expects dims such that dim4 = N, dim3 = H, dim2 = W, dim1 = C A ZDNN_HWCK expects dims such that dim4 = W, dim3 = W, dim2 = C, dim1 = K The format changes the expected dims order for ZDNN_4D tensors layouts ZDNN_FORMAT_4DFEATURE expects dims such that dim4 = N, dim3 = H, dim2 = W, dim1 = C ZDNN_FORMAT_4DKERNEL expects dims such that dim4 = H, dim3 = W, dim2 = C, dim1 = K","title":"Programming Notes"},{"location":"zDNN/#zdnn-data-layouts","text":"Back to Table of Contents The following are layouts for zDNN ztensor descriptors. These indicate the number and order of dimensions to expect for the ztensor data. typedef enum zdnn_data_layouts { ZDNN_1D, // 1d tensor ZDNN_2D, // 2d tensor ZDNN_2DS, // represents special 2D tensors required by LSTM/GRU ZDNN_3D, // 3d tensor ZDNN_3DS, // represents special 3D tensors required by // LSTM/GRU/Softmax/Matmul ZDNN_ZRH, // represents (update, reset, hidden) used by GRU ZDNN_4D, // 4d tensor ZDNN_4DS, // represents special 4D tensors required by LSTM/GRU output ZDNN_NHWC, // 4d feature tensor in NHWC ZDNN_NCHW, // 4d feature tensor in NCHW ZDNN_FICO, // represents (forget, input, cell, output) used by LSTM ZDNN_HWCK, // 4d kernel CNN tensor ZDNN_BIDIR_ZRH, // ZRH variant to work with bidirectional LSTM/GRU output ZDNN_BIDIR_FICO // FICO variant to work with bidirectional LSTM/GRU output } zdnn_data_layouts; Some layouts also indicate special re-arrangement of the data during ztensor transformation. ZDNN_2DS - The outermost dimension of the original shape is promoted to dim4 during transformation. For example, a shape of (a, b) becomes [a, 1, 1, b] (dim4, dim3, dim2, dim1) in the transformed_desc ZDNN_3DS - The outermost dimension of the original shape is promoted to dim4 during transformation. For example, a shape of (a, b, c) becomes [a, 1, b, c] (dim4, dim3, dim2, dim1) in the transformed_desc ZDNN_4DS - Arrangement for RNN output tensor The followings are set automatically in transformed_desc based on info when calling zdnn_generate_transformed_desc_concatenated() : ZDNN_ZRH/FICO - During transformation, the RNN input gates data are concatenated on the innermost dimension. Supported with pre_transformed_layout of ZDNN_2DS or ZDNN_3DS . ZDNN_BIDIR_ZRH/FICO - Similar to ZDNN_ZRH/FICO , used when: transforming RNN input weight gate data, and the input tensor for the current RNN layer is a bidirectional RNN output from a previous RNN layer","title":"zDNN Data Layouts "},{"location":"zDNN/#zdnn-data-formats","text":"Back to Table of Contents typedef enum zdnn_data_formats { ZDNN_FORMAT_4DFEATURE, // tensor in AIU data layout format 0 ZDNN_FORMAT_4DKERNEL, // tensor in AIU data layout format 1 } zdnn_data_formats;","title":"zDNN Data Formats "},{"location":"zDNN/#zdnn-data-types","text":"Back to Table of Contents typedef enum zdnn_data_types { ZDNN_DLFLOAT16, // 16-bit deep learning format BFLOAT, // Brain floating point format FP16, // 16-bit IEEE-754 floating point format FP32, // 32-bit IEEE-754 floating point format } zdnn_data_types;","title":"zDNN Data Types "},{"location":"zDNN/#zdnn-statuses","text":"Back to Table of Contents Mnemonic Constant Value Meaning ZDNN_OK 0x00000000 Success.","title":"zDNN Statuses "},{"location":"zDNN/#warning-statuses","text":"Mnemonic Constant Value Meaning ZDNN_ELEMENT_RANGE_VIOLATION 0x00020001 AIU operation resulted in data that was out of the normal range. Note: ZDNN_ELEMENT_RANGE_VIOLATION indicates a range violation occurred for the AIU operation based on the data in the tensors. This usually indicates an overflow of the NNPA internal data type, but can also be associated with operation specific errors, such as \"divide by zero\". See the \"z/Architecture Principles of Operation\" for information about range violation on the operation that encountered the violation.","title":"Warning Statuses "},{"location":"zDNN/#general-failing-statuses","text":"Mnemonic Constant Value Meaning ZDNN_INVALID_SHAPE* 0x00040001 Invalid shape information in one (or more) of the input/output tensor(s). ZDNN_INVALID_LAYOUT 0x00040002 Invalid layout information in one (or more) of the input/output tensor(s). ZDNN_INVALID_TYPE* 0x00040003 Invalid type information in one (or more) of the input/output tensor(s). ZDNN_INVALID_FORMAT* 0x00040004 Invalid format information in one (or more) of the input/output tensor(s). ZDNN_INVALID_DIRECTION 0x00040005 Invalid RNN direction. ZDNN_INVALID_CONCAT_INFO 0x00040006 Invalid concatenation info. ZDNN_INVALID_STRIDE_PADDING* 0x00040007 Invalid padding type parameter for current strides. ZDNN_INVALID_STRIDES* 0x00040008 Invalid stride height or width parameter. ZDNN_MISALIGNED_PARMBLOCK* 0x00040009 NNPA parameter block is not on double word boundary. ZDNN_INVALID_CLIPPING_VALUE 0x0004000A Invalid clipping for the specified operation. ZDNN_ALLOCATION_FAILURE 0x00100001 Can not allocate storage. ZDNN_INVALID_BUFFER 0x00100002 Buffer address is NULL or not on 4K-byte boundary or insufficient buffer size. ZDNN_CONVERT_FAILURE 0x00100003 Floating point data conversion failure. ZDNN_INVALID_STATE 0x00100004 Invalid zTensor state. ZDNN_UNSUPPORTED_AIU_EXCEPTION 0x00100005 AIU operation returned an unexpected exception. Note: *In certain scenarios, these statuses are returned only if ZDNN_ENABLE_PRECHECK is enabled. When not enabled, these scenarios will lead to abnormal program termination.","title":"General Failing Statuses "},{"location":"zDNN/#hardware-statuses","text":"The following statuses indicate issues returned from the hardware. Mnemonic Constant Value Meaning ZDNN_UNSUPPORTED_PARMBLOCK 0x000C0001 NNPA parameter block format is not supported by the model. ZDNN_UNAVAILABLE_FUNCTION 0x000C0002 Specified NNPA function is not defined or installed on the machine. ZDNN_UNSUPPORTED_FORMAT 0x000C0010 Specified tensor data layout format is not supported. ZDNN_UNSUPPORTED_TYPE 0x000C0011 Specified tensor data type is not supported. ZDNN_EXCEEDS_MDIS 0x000C0012 Tensor dimension exceeds maximum dimension index size (MDIS). ZDNN_EXCEEDS_MTS 0x000C0013 Total number of bytes in tensor exceeds maximum tensor size. (MTS). ZDNN_MISALIGNED_TENSOR 0x000C0014 Tensor address is not on 4K-byte boundary. ZDNN_MISALIGNED_SAVEAREA 0x000C0015 Function specific save area address is not on 4K-byte boundary. The meaning of the following hardware statuses vary based on operation. See the operation that returned the status for the specific meaning. Mnemonic Constant Value Meaning ZDNN_FUNC_RC_F000 0x000CF000 Function specific response code (F000). ZDNN_FUNC_RC_F001 0x000CF001 Function specific response code (F001). ZDNN_FUNC_RC_F002 0x000CF002 Function specific response code (F002). ZDNN_FUNC_RC_F003 0x000CF003 Function specific response code (F003). ZDNN_FUNC_RC_F004 0x000CF004 Function specific response code (F004). ZDNN_FUNC_RC_F005 0x000CF005 Function specific response code (F005). ZDNN_FUNC_RC_F006 0x000CF006 Function specific response code (F006). ZDNN_FUNC_RC_F007 0x000CF007 Function specific response code (F007). ZDNN_FUNC_RC_F008 0x000CF008 Function specific response code (F008). ZDNN_FUNC_RC_F009 0x000CF009 Function specific response code (F009).","title":"Hardware Statuses "},{"location":"zDNN/#runtime-environment-variables","text":"Back to Table of Contents ZDNN_ENABLE_PRECHECK : true/false If set to true , tensor integrity prechecks are run before issuing NNPA operations. Enabling precheck may impact performance. Enable to debug issues which cause hardware exceptions that otherwise would result in abnormal program termination. ZDNN_STATUS_DIAG : nnnnnnnn (decimal) or 0xnnnnnnnn (hexadecimal) Prints or produces diagnostic information whenever zDNN status code is equal to the specified value. Only one status value can be specified. The following are only available when the zDNN library was built with ZDNN_CONFIG_DEBUG enabled. ZDNN_LOGLEVEL : off/fatal/error/warn/info/debug/trace Sets logging facility's output level ZDNN_LOGMODULE : module name(s) Produces log output only when the issuer's module name is in the list. You may specify multiple module names by separating them with either commas or spaces.","title":"Runtime Environment Variables "},{"location":"zDNN/#programming-notes_1","text":"Environment variables settings are checked during initial library load by zdnn_init . To change environment variable settings afterward, zdnn_init must be called again manually.","title":"Programming Notes"},{"location":"zDNN/#api-reference","text":"Back to Table of Contents Support Functions Data Transformation Operations Convenience Functions","title":"API Reference"},{"location":"zDNN/#support-functions","text":"Back to Table of Contents Initialization Query Get Size Initialize pre-transformed tensor descriptor Generate transformed tensor descriptor Generate concatenated transformed tensor descriptor Initialize zTensor Initialize zTensor with memory allocate Reset zTensor Allocate memory for zTensor De-allocate memory for zTensor Retrieve status message of the status code Reshape zTensor Check if version is runnable Get maximum runnable version","title":"Support Functions"},{"location":"zDNN/#zdnn_init","text":"","title":"zdnn_init"},{"location":"zDNN/#description","text":"Initialize the zDNN library. This sends an NNPA_QAF to query the NNPA and loads the current environment variable settings. This needs to be invoked at least once if zDNN library is statically-linked. It is automatically invoked if zDNN library is dynamically loaded.","title":"Description"},{"location":"zDNN/#format","text":"void zdnn_init();","title":"Format"},{"location":"zDNN/#parameters","text":"None","title":"Parameters"},{"location":"zDNN/#returns","text":"None","title":"Returns"},{"location":"zDNN/#zdnn_get_nnpa_max_dim_idx_size","text":"","title":"zdnn_get_nnpa_max_dim_idx_size"},{"location":"zDNN/#description_1","text":"Retrieve the maximum dimension index size value currently supported by the AIU from zDNN's internal memory.","title":"Description"},{"location":"zDNN/#format_1","text":"uint32_t zdnn_get_nnpa_max_dim_idx_size();","title":"Format"},{"location":"zDNN/#parameters_1","text":"None","title":"Parameters"},{"location":"zDNN/#returns_1","text":"Maximum dimension index size supported by the AIU","title":"Returns"},{"location":"zDNN/#zdnn_get_nnpa_max_tensor_size","text":"","title":"zdnn_get_nnpa_max_tensor_size"},{"location":"zDNN/#description_2","text":"Retrieve the maximum tensor size value (number of bytes required for storing a transformed tensor) currently supported by the AIU from zDNN's internal memory.","title":"Description"},{"location":"zDNN/#format_2","text":"uint64_t zdnn_get_nnpa_max_tensor_size();","title":"Format"},{"location":"zDNN/#parameters_2","text":"None","title":"Parameters"},{"location":"zDNN/#returns_2","text":"Maximum tensor size supported by the AIU","title":"Returns"},{"location":"zDNN/#zdnn_is_nnpa_installed","text":"","title":"zdnn_is_nnpa_installed"},{"location":"zDNN/#description_3","text":"Interrogates the hardware to determine if the NNPA and NNP-internal data type (DLFLOAT16) conversion instructions are installed. Use this function during application initialization to determine whether the AIU hardware is available.","title":"Description"},{"location":"zDNN/#format_3","text":"bool zdnn_is_nnpa_installed();","title":"Format"},{"location":"zDNN/#parameters_3","text":"None.","title":"Parameters"},{"location":"zDNN/#returns_3","text":"true if NNPA and zdnn conversion instructions are installed, false otherwise.","title":"Returns"},{"location":"zDNN/#zdnn_is_nnpa_function_installed","text":"","title":"zdnn_is_nnpa_function_installed"},{"location":"zDNN/#description_4","text":"Query, from zDNN internal memory, if requested NNPA functions are available.","title":"Description"},{"location":"zDNN/#format_4","text":"bool zdnn_is_nnpa_function_installed(int count, ...);","title":"Format"},{"location":"zDNN/#parameters_4","text":"int count number of NNPA functions to check ... (additional arguments) Function names separated by commas, e.g., NNPA_MUL, NNPA_MIN NNPA_QAF NNPA_ADD NNPA_SUB NNPA_MUL NNPA_DIV NNPA_MIN NNPA_MAX NNPA_LOG NNPA_EXP NNPA_RELU NNPA_TANH NNPA_SIGMOID NNPA_SOFTMAX NNPA_BATCHNORMALIZATION NNPA_MAXPOOL2D NNPA_AVGPOOL2D NNPA_LSTMACT NNPA_GRUACT NNPA_CONVOLUTION NNPA_MATMUL_OP NNPA_MATMUL_OP_BCAST23","title":"Parameters"},{"location":"zDNN/#returns_4","text":"true if all queried formats are installed or if count is zero, false otherwise.","title":"Returns"},{"location":"zDNN/#zdnn_is_nnpa_parmblk_fmt_installed","text":"","title":"zdnn_is_nnpa_parmblk_fmt_installed"},{"location":"zDNN/#description_5","text":"Query, from zDNN internal memory, if requested parameter block formats are installed.","title":"Description"},{"location":"zDNN/#format_5","text":"bool zdnn_is_nnpa_parmblk_fmt_installed(int count, ...);","title":"Format"},{"location":"zDNN/#parameters_5","text":"int count number of NNPA parameter block formats to check ... (additional arguments) NNPA parameter block formats separated by commas NNPA_PARMBLKFORMAT_0","title":"Parameters"},{"location":"zDNN/#returns_5","text":"true if all queried formats are installed or if count is zero, false otherwise.","title":"Returns"},{"location":"zDNN/#zdnn_is_nnpa_datatype_installed","text":"","title":"zdnn_is_nnpa_datatype_installed"},{"location":"zDNN/#description_6","text":"Query, from zDNN internal memory, if requested NNPA data type are installed.","title":"Description"},{"location":"zDNN/#format_6","text":"bool zdnn_is_nnpa_datatype_installed(uint16_t types_bitmask);","title":"Format"},{"location":"zDNN/#parameters_6","text":"uint16_t types_bitmask OR'd type bitmasks as defined in zdnn_query_datatypes enum QUERY_DATATYPE_INTERNAL1","title":"Parameters"},{"location":"zDNN/#returns_6","text":"true if all queried data types are installed, false otherwise.","title":"Returns"},{"location":"zDNN/#zdnn_is_nnpa_layout_fmt_installed","text":"","title":"zdnn_is_nnpa_layout_fmt_installed"},{"location":"zDNN/#description_7","text":"Query, from zDNN internal memory, if requested NNPA data layout format are installed.","title":"Description"},{"location":"zDNN/#format_7","text":"bool zdnn_is_nnpa_layout_fmt_installed(uint32_t layout_bitmask);","title":"Format"},{"location":"zDNN/#parameters_7","text":"uint32_t layout_bitmask OR'd layout bitmasks as defined in zdnn_query_layoutfmts enum QUERY_LAYOUTFMT_4DFEATURE QUERY_LAYOUTFMT_4DKERNEL","title":"Parameters"},{"location":"zDNN/#returns_7","text":"true if all queried data layouts are installed, false otherwise.","title":"Returns"},{"location":"zDNN/#zdnn_is_nnpa_conversion_installed","text":"","title":"zdnn_is_nnpa_conversion_installed"},{"location":"zDNN/#description_8","text":"Query, from zDNN internal memory, if requested NNPA data-type to/from BFP format conversions are installed.","title":"Description"},{"location":"zDNN/#format_8","text":"bool zdnn_is_nnpa_conversion_installed(nnpa_data_type type, uint16_t format_bitmask);","title":"Format"},{"location":"zDNN/#parameters_8","text":"nnpa_data_type type NNPA data-type number as defined in nnpa_data_type enum NNPA_DATATYPE_1 uint16_t format_bitmask OR'd BFP format bitmasks as defined in zdnn_query_bfpfmts enum QUERY_BFPFMT_TINY (FP16) QUERY_BFPFMT_SHORT (FP32/BFLOAT)","title":"Parameters"},{"location":"zDNN/#returns_8","text":"true if all queried conversions are installed, false otherwise.","title":"Returns"},{"location":"zDNN/#zdnn_get_library_version","text":"","title":"zdnn_get_library_version"},{"location":"zDNN/#description_9","text":"Retrieve library version number as a 32-bit hex value ( 0x00[major][minor][patch] ).","title":"Description"},{"location":"zDNN/#format_9","text":"uint32_t zdnn_get_library_version();","title":"Format"},{"location":"zDNN/#returns_9","text":"Library version number in 0x00[major][minor][patch] format.","title":"Returns"},{"location":"zDNN/#zdnn_get_library_version_str","text":"","title":"zdnn_get_library_version_str"},{"location":"zDNN/#description_10","text":"Retrieve the library version number and build information as a string.","title":"Description"},{"location":"zDNN/#format_10","text":"char *zdnn_get_library_version_str();","title":"Format"},{"location":"zDNN/#returns_10","text":"Library version number and build information as a string.","title":"Returns"},{"location":"zDNN/#zdnn_refresh_nnpa_query_result","text":"","title":"zdnn_refresh_nnpa_query_result"},{"location":"zDNN/#description_11","text":"Refresh zDNN in-memory query result from zAIU.","title":"Description"},{"location":"zDNN/#format_11","text":"zdnn_status zdnn_refresh_nnpa_query_result();","title":"Format"},{"location":"zDNN/#parameters_9","text":"None","title":"Parameters"},{"location":"zDNN/#programming-notes_2","text":"This is called automatically as a part of zdnn_init and should not need to be called directly. Manually refreshing query results before making other zdnn_query_* calls may noticeably impact performance.","title":"Programming Notes"},{"location":"zDNN/#returns-zdnn_status-indications","text":"ZDNN_OK ZDNN_UNAVAILABLE_FUNCTION","title":"Returns zdnn_status indications"},{"location":"zDNN/#zdnn_getsize_ztensor","text":"","title":"zdnn_getsize_ztensor"},{"location":"zDNN/#description_12","text":"Used to determine the buffer size required for the transformed tensor (including concatenated) in zDNN transformed format. Requires tensor descriptor ( zdnn_tensor_desc ) with transformed shape information.","title":"Description"},{"location":"zDNN/#format_12","text":"uint64_t zdnn_getsize_ztensor(const zdnn_tensor_desc *tfrmd_desc);","title":"Format"},{"location":"zDNN/#parameters_10","text":"zdnn_tensor_desc *tfrmd_desc Contains transformed information about the shape, layout and data type.","title":"Parameters"},{"location":"zDNN/#returns-zdnn_status-indications_1","text":"required buffer size in bytes","title":"Returns zdnn_status indications"},{"location":"zDNN/#zdnn_init_pre_transformed_desc","text":"","title":"zdnn_init_pre_transformed_desc"},{"location":"zDNN/#description_13","text":"Initialize tensor descriptor ( zdnn_tensor_desc ) struct with pre-transformed (original) shape information.","title":"Description"},{"location":"zDNN/#format_13","text":"void zdnn_init_pre_transformed_desc(zdnn_data_layouts layout, zdnn_data_types type, zdnn_tensor_desc *pre_tfrmd_desc, ...);","title":"Format"},{"location":"zDNN/#parameters_11","text":"zdnn_data_layouts layout data layout zdnn_data_types type data type zdnn_tensor_desc *pre_tfrmd_desc output zdnn_tensor_desc struct ... (additional arguments) Variadic: number of elements in each dimension in accordance to the layout, in outermost to innermost order","title":"Parameters"},{"location":"zDNN/#returns_11","text":"None","title":"Returns"},{"location":"zDNN/#zdnn_generate_transformed_desc","text":"","title":"zdnn_generate_transformed_desc"},{"location":"zDNN/#description_14","text":"Generate transformed tensor descriptor information based on supplied pre-transformed tensor descriptor.","title":"Description"},{"location":"zDNN/#format_14","text":"zdnn_status zdnn_generate_transformed_desc( const zdnn_tensor_desc *pre_tfrmd_desc, zdnn_tensor_desc *tfrmd_desc);","title":"Format"},{"location":"zDNN/#parameters_12","text":"zdnn_tensor_desc *pre_tfrmd_desc input tensor descriptor with pre-transformed shape information zdnn_tensor_desc *tfrmd_desc output zdnn_tensor_desc struct","title":"Parameters"},{"location":"zDNN/#zdnn_status-indications","text":"ZDNN_OK ZDNN_INVALID_LAYOUT - pre-transformed layout is not recognized or is a layout only used for concatenated tensors.","title":"zdnn_status indications"},{"location":"zDNN/#zdnn_generate_transformed_desc_concatenated","text":"","title":"zdnn_generate_transformed_desc_concatenated"},{"location":"zDNN/#description_15","text":"Generate concatenated transformed tensor descriptor information for RNN input-gates tensors based on a supplied pre-transformed tensor descriptor.","title":"Description"},{"location":"zDNN/#format_15","text":"zdnn_status zdnn_generate_transformed_desc_concatenated( const zdnn_tensor_desc *pre_tfrmd_desc, zdnn_concat_info info, zdnn_tensor_desc *tfrmd_desc);","title":"Format"},{"location":"zDNN/#parameters_13","text":"zdnn_tensor_desc *pre_tfrmd_desc input tensor descriptor with pre-transformed shape information zdnn_concat_info info Information about how the tensors will be concatenated, consists of the RNN_TYPE, PREV_LAYER and USAGE flags OR'd together: RNN_TYPE flags: RNN_TYPE_LSTM - For LSTM RNN_TYPE_GRU - For GRU PREV_LAYER flags: PREV_LAYER_UNI - Previous RNN layer is uni-directional PREV_LAYER_NONE - Previous layer is not a RNN layer PREV_LAYER_BIDIR - Previous RNN layer is bi-directional USAGE flags: USAGE_WEIGHTS - Concatenate as input weights USAGE_HIDDEN_WEIGHTS - Concatenate as input hidden-weights USAGE_BIASES - Concatenate as input biases USAGE_HIDDEN_BIASES - Concatenate as input hidden-biases zdnn_tensor_desc *tfrmd_desc output zdnn_tensor_desc struct","title":"Parameters"},{"location":"zDNN/#zdnn_status-indications_1","text":"ZDNN_OK ZDNN_INVALID_LAYOUT - pre-transformed layout is not recognized or is not supported for concatenated tensors. ZDNN_INVALID_CONCAT_INFO - invalid concatenation information.","title":"zdnn_status indications"},{"location":"zDNN/#zdnn_init_ztensor","text":"","title":"zdnn_init_ztensor"},{"location":"zDNN/#description_16","text":"Initialize a zdnn_ztensor struct using the pre-transformed and transformed tensor shape information","title":"Description"},{"location":"zDNN/#format_16","text":"void zdnn_init_ztensor(zdnn_tensor_desc *pre_tfrmd_desc, zdnn_tensor_desc *tfrmd_desc, zdnn_ztensor *output);","title":"Format"},{"location":"zDNN/#parameters_14","text":"zdnn_tensor_desc *pre_tfrmd_desc input tensor descriptor with pre-transformed shape information zdnn_tensor_desc *tfrmd_desc input tensor descriptor with transformed shape information zdnn_ztensor *output The zdnn_ztensor struct being initialized.","title":"Parameters"},{"location":"zDNN/#returns_12","text":"None","title":"Returns"},{"location":"zDNN/#zdnn_init_ztensor_with_malloc","text":"","title":"zdnn_init_ztensor_with_malloc"},{"location":"zDNN/#description_17","text":"Same functionality as zdnn_init_ztensor , and computes the size required for the tensor in the zDNN transformed format and allocates the storage for it. Sets buffer and buffer_size fields within output .","title":"Description"},{"location":"zDNN/#format_17","text":"zdnn_status zdnn_init_ztensor_with_malloc(zdnn_tensor_desc *pre_tfrmd_desc, zdnn_tensor_desc *tfrmd_desc, zdnn_ztensor *output);","title":"Format"},{"location":"zDNN/#parameters_15","text":"zdnn_tensor_desc *pre_tfrmd_desc input tensor descriptor with pre-transformed shape information zdnn_tensor_desc *tfrmd_desc input tensor descriptor with transformed shape information zdnn_ztensor *output The zdnn_ztensor struct being initialized.","title":"Parameters"},{"location":"zDNN/#returns-zdnn_status-indications_2","text":"ZDNN_OK ZDNN_INVALID_FORMAT - tfrmd_desc->format is not recognized. ZDNN_INVALID_TYPE - tfrmd_desc->type is not recognized or is a pre_tfrmd_desc type. ZDNN_INVALID_SHAPE - (if any of the following are true) One of tfrmd_desc->dim* dimensions is 0. One of tfrmd_desc->dim* dimensions is greater than zdnn_get_nnpa_max_dim_idx_size . Note: concatenation dimensions have a smaller maximum size. See LSTM or GRU . The total number of tfrmd_desc elements is larger than zdnn_get_nnpa_max_tensor_size . ZDNN_ALLOCATION_FAILURE - Unable to allocate required memory on a 4K boundary.","title":"Returns zdnn_status indications"},{"location":"zDNN/#zdnn_reset_ztensor","text":"","title":"zdnn_reset_ztensor"},{"location":"zDNN/#description_18","text":"Reset a zdnn_ztensor struct for reuse. Note this operation does not set or reset the buffer and buffer_size fields nor free the transformed area storage.","title":"Description"},{"location":"zDNN/#format_18","text":"void zdnn_reset_ztensor(zdnn_ztensor *ztensor);","title":"Format"},{"location":"zDNN/#parameters_16","text":"zdnn_ztensor *output The zdnn_ztensor struct being reset.","title":"Parameters"},{"location":"zDNN/#returns_13","text":"None","title":"Returns"},{"location":"zDNN/#zdnn_allochelper_ztensor","text":"","title":"zdnn_allochelper_ztensor"},{"location":"zDNN/#description_19","text":"Calculate the size required for the tensor in the zDNN transformed format and allocate the needed storage, satisfying alignment requirements. Sets buffer and buffer_size fields within ztensor . Note that the calling application assumes ownership of this storage and is responsible for freeing it.","title":"Description"},{"location":"zDNN/#format_19","text":"zdnn_status zdnn_allochelper_ztensor(zdnn_ztensor *ztensor);","title":"Format"},{"location":"zDNN/#parameters_17","text":"zdnn_ztensor *ztensor A zdnn_ztensor struct that contains the transformed shape information in the transformed_desc field.","title":"Parameters"},{"location":"zDNN/#returns-zdnn_status-indications_3","text":"ZDNN_OK ZDNN_INVALID_FORMAT - ztensor->transformed_desc->format is not recognized. ZDNN_INVALID_TYPE - ztensor->transformed_desc->type is not recognized or is a pre_transformed_desc type. ZDNN_INVALID_SHAPE - (if any of the following are true) One of ztensor->transformed_desc->dim* dimensions is 0. One of ztensor->transformed_desc->dim* dimensions is greater than zdnn_get_nnpa_max_dim_idx_size . Note: concatenation dimensions have a smaller maximum size. See LSTM or GRU . The total number of transformed_desc elements is larger than zdnn_get_nnpa_max_tensor_size . ZDNN_ALLOCATION_FAILURE - Unable to allocate required memory on a 4K boundary.","title":"Returns zdnn_status indications"},{"location":"zDNN/#zdnn_free_ztensor_buffer","text":"","title":"zdnn_free_ztensor_buffer"},{"location":"zDNN/#description_20","text":"Given an input zdnn_ztensor, zdnn_free_ztensor_buffer will free the transformed area storage associated with it. Note that the routine does not free the storage allocated for the zdnn_ztensor struct itself.","title":"Description"},{"location":"zDNN/#format_20","text":"zdnn_status zdnn_free_ztensor_buffer(const zdnn_ztensor *ztensor);","title":"Format"},{"location":"zDNN/#parameters_18","text":"zdnn_ztensor *tensor A zdnn_ztensor struct with field buffer pointing to storage allocated.","title":"Parameters"},{"location":"zDNN/#returns-zdnn_status-indications_4","text":"ZDNN_OK ZDNN_INVALID_BUFFER - tensor->buffer is NULL","title":"Returns zdnn_status indications"},{"location":"zDNN/#zdnn_get_status_message","text":"","title":"zdnn_get_status_message"},{"location":"zDNN/#description_21","text":"Retrieve status message of the status code","title":"Description"},{"location":"zDNN/#format_21","text":"const char *zdnn_get_status_message(zdnn_status status);","title":"Format"},{"location":"zDNN/#parameters_19","text":"zdnn_status status Status code","title":"Parameters"},{"location":"zDNN/#returns_14","text":"Pointer to the description string or \"(Status string is not defined.)\" if status is not defined.","title":"Returns"},{"location":"zDNN/#zdnn_reshape_ztensor","text":"","title":"zdnn_reshape_ztensor"},{"location":"zDNN/#description_22","text":"Reshape and copy buffer content from source zTensor's buffer to destination zTensor's in accordance to destination zTensor's shape. The following conditions must be satisfied: Both tensor's transformed_desc must be fully initialized dest->buffer must be pre-allocated src must be transformed dest must be not already transformed Both transformed_desc->layout must be the same and either NHWC or HWCK Both zTensors must contain equal number of elements","title":"Description"},{"location":"zDNN/#format_22","text":"zdnn_status zdnn_reshape_ztensor(const zdnn_ztensor *src, zdnn_ztensor *dest);","title":"Format"},{"location":"zDNN/#parameters_20","text":"src Source zTensor to copy from dest Destination zTensor to copy to","title":"Parameters"},{"location":"zDNN/#programming-notes_3","text":"If src and dest have the same transformed_desc->dim1 dimension size, the transformed data is directly copied to the destination without untransformation. If src and dest have different transformed_desc->dim1 dimension sizes, reshaping will internally un-transform the source and then re-transform the values into the destination.","title":"Programming Notes"},{"location":"zDNN/#returns_15","text":"ZDNN_OK ZDNN_INVALID_SHAPE - (if any of the following are true) src 's and dest 's transformed_desc->dim* total to different numbers of elements. One of dest->transformed_desc->dim* dimensions is 0. One of dest->transformed_desc->dim* dimensions is greater than zdnn_get_nnpa_max_dim_idx_size . Note: concatenation dimensions have a smaller maximum size. See LSTM or GRU . The total number of dest->transformed_desc-dim* elements is larger than zdnn_get_nnpa_max_tensor_size . ZDNN_INVALID_LAYOUT - (if any of the following are true) src 's and dest 's transformed_desc->layout are not the same. transformed_desc->layout is not ZDNN_NHWC nor ZDNN_HWCK . src->pre_transformed_desc->layout is not recognized or is not a valid pre_transformed_desc layout. dest->pre_transformed_desc->layout is not recognized or is not a valid pre_transformed_desc layout. ZDNN_INVALID_STATE - (if any of the following are true) src is not already transformed. dest is already transformed. ZDNN_INVALID_FORMAT - src->transformed_desc->format is not ZDNN_FORMAT_4DFEATURE . ZDNN_INVALID_TYPE (if any of the following are true) src->pre_transformed_desc->type is not recognized or is a transformed_desc type. dest->pre_transformed_desc->type is not recognized or is a transformed_desc type. dest->transformed_desc->type is not recognized or is a pre_transformed_desc type. ZDNN_INVALID_BUFFER (if any of the following are true) src->buffer is NULL . src->buffer is not on a 4K boundary. dest->buffer is NULL . dest->buffer is not on a 4K boundary. dest->buffer_size is too small to hold transformed values. ZDNN_CONVERT_FAILURE - Values failed to un-transform or transform.","title":"Returns"},{"location":"zDNN/#zdnn_is_version_runnable","text":"","title":"zdnn_is_version_runnable"},{"location":"zDNN/#description_23","text":"Check if application built for zDNN version ver_num can be run on the current AIU hardware with the installed zDNN library","title":"Description"},{"location":"zDNN/#format_23","text":"bool zdnn_is_version_runnable(uint32_t ver_num);","title":"Format"},{"location":"zDNN/#parameters_21","text":"ver_num zDNN version number from the application in 0x00[major][minor][patch] form. Typically this is ZDNN_VERNUM used to compile the application","title":"Parameters"},{"location":"zDNN/#returns_16","text":"true/false","title":"Returns"},{"location":"zDNN/#zdnn_get_max_runnable_version","text":"","title":"zdnn_get_max_runnable_version"},{"location":"zDNN/#description_24","text":"Returns the maximum zDNN version number that the current hardware and installed zDNN library can run together. The returned value means the current runtime environment fully supports zDNN APIs set of that major . minor version and below.","title":"Description"},{"location":"zDNN/#format_24","text":"uint32_t zdnn_get_max_runnable_version();","title":"Format"},{"location":"zDNN/#parameters_22","text":"None","title":"Parameters"},{"location":"zDNN/#returns_17","text":"A 32-bit zDNN version number in 0x00[major][minor]FF form.","title":"Returns"},{"location":"zDNN/#data-transformation","text":"Back to Table of Contents Transform to zTensor Transform to Original zAIU requires the tensor data to be arranged in a format that enhances the performance characteristics of the operations. In this documentation, it is referred to as \"transformed format\". In addition, data conversions are necessary from the common formats (FP32, FP16, BFLOAT) to the internal format (DLFLOAT16) supported by the AIU. Two functions are provided: ' zdnn_transform_ztensor zdnn_transform_ztensor will transform the input tensor and convert the input data to the format required by the AIU. The resulting transformed ztensor can be reused as many times as necessary. See zdnn_transform_ztensor for details on transforming an input tensor to the internal format. zdnn_transform_origtensor zdnn_transform_origtensor transforms a ztensor (usually output from an operation or network) to the format and data types that are usable by the application. See zdnn_transform_origtensor for details on transforming an input tensor to the internal format.","title":"Data Transformation"},{"location":"zDNN/#zdnn_transform_ztensor","text":"","title":"zdnn_transform_ztensor"},{"location":"zDNN/#description_25","text":"Converts the input tensor to the supported transformed format for execution by zdnn operations. If transformation is successful the is_transformed field within ztensor will be set to true otherwise it is set to false . Transformation will fail if is_transformed was already true . Note that the tensor layout in memory, once in transformed format, is dependent on the content of the input tensor's descriptors ( zdnn_tensor_desc fields). Once converted, a zdnn_ztensor should only be manipulated by zDNN API functions.","title":"Description"},{"location":"zDNN/#format_25","text":"zdnn_status zdnn_transform_ztensor(zdnn_ztensor *ztensor, ...);","title":"Format"},{"location":"zDNN/#parameters_23","text":"zdnn_ztensor *tensor The input zdnn_ztensor struct. pre_transformed_desc and transformed_desc must be set, is_transformed must be false . A 4k-aligned tensor storage must be pre-allocated by the caller (directly or by calling the zDNN allocation helper function) and field buffer must point to the storage. ... (additional arguments) Variadic: list of pointers for input data to be transformed: Non-concatenated: 1 data pointer LSTM concatenated: 4 data pointers, one for each input gate in Forget, Input, Cell, Output (FICO) order GRU concatenated: 3 data pointers, one for each input gate in (Z)update, Reset, Hidden, (ZRH) gate order","title":"Parameters"},{"location":"zDNN/#programming-notes_4","text":"This function clears the pre-thread floating-point exception flags at entry, and may set FE_UNDERFLOW / FE_INVALID / FE_INEXACT / FE_OVERFLOW when it encounters errors during data conversion.","title":"Programming Notes"},{"location":"zDNN/#returns-zdnn_status-indications_5","text":"ZDNN_OK ZDNN_INVALID_FORMAT - zdnn_ztensor->transformed_desc->format is not recognized. ZDNN_INVALID_LAYOUT - (if any of the following are true) zdnn_ztensor->pre_transformed_desc->layout is not recognized or is not a valid pre_transformed_desc layout. zdnn_ztensor->transformed_desc->layout is not recognized or is not a valid transformed_desc layout. ZDNN_INVALID_TYPE - (if any of the following are true) zdnn_ztensor->pre_transformed_desc->type is not recognized or is a transformed_desc type. zdnn_ztensor->transformed_desc->type is not recognized or is a pre_transformed_desc type. ZDNN_INVALID_BUFFER (if any of the following are true) buffer is NULL . buffer is not on a 4K boundary. buffer_size is too small to hold transformed values. ZDNN_INVALID_SHAPE - (if any of the following are true) One of zdnn_ztensor->transformed_desc->dim* dimensions is 0. One of zdnn_ztensor->transformed_desc->dim* dimensions is greater than zdnn_get_nnpa_max_dim_idx_size . Note: concatenation dimensions have a smaller maximum size. See LSTM or GRU . The total number of transformed_desc elements is larger than zdnn_get_nnpa_max_tensor_size . ZDNN_INVALID_STATE - Tensor is already transformed. ZDNN_CONVERT_FAILURE - Values failed to transform.","title":"Returns zdnn_status indications"},{"location":"zDNN/#zdnn_transform_origtensor","text":"","title":"zdnn_transform_origtensor"},{"location":"zDNN/#description_26","text":"Converts the input tensor from the zDNN transformed format back to a standard non-transformed layout. The is_transformed field within ztensor must be true . All stick format tensors are supported, except: Kernel tensors Concatenated RNN input-gates tensors","title":"Description"},{"location":"zDNN/#format_26","text":"zdnn_status zdnn_transform_origtensor(const zdnn_ztensor *ztensor, void *out_buf);","title":"Format"},{"location":"zDNN/#parameters_24","text":"zdnn_ztensor *ztensor The input zdnn_ztensor struct. pre_transformed_desc , transformed_desc and buffer must be set, is_transformed must be true . void *out_buf The buffer for storing the standard non-transformed tensor data. Must be pre-allocated by the caller.","title":"Parameters"},{"location":"zDNN/#programming-notes_5","text":"This function clears the pre-thread floating-point exception flags at entry, and may set FE_UNDERFLOW / FE_INVALID / FE_INEXACT / FE_OVERFLOW when it encounters errors during data conversion.","title":"Programming Notes"},{"location":"zDNN/#returns-zdnn_status-indications_6","text":"ZDNN_OK ZDNN_INVALID_FORMAT - ztensor->transformed_desc->format is not ZDNN_FORMAT_4DFEATURE . ZDNN_INVALID_LAYOUT - (if any of the following are true) zdnn_ztensor->pre_transformed_desc->layout is not recognized or is not a valid pre_transformed_desc layout. zdnn_ztensor->transformed_desc->layout is not recognized or is not a valid transformed_desc layout required by this function. ZDNN_INVALID_TYPE ztensor->pre_transformed_desc->type is not recognized or is a transformed_desc type. ztensor->transformed_desc->type is not recognized or is a pre_transformed_desc type. ZDNN_INVALID_BUFFER (if any of the following are true) ztensor->buffer is NULL . ztensor->buffer is not on a 4K boundary. ZDNN_INVALID_STATE - ztensor is not transformed. ZDNN_CONVERT_FAILURE - Values failed to un-transform.","title":"Returns zdnn_status indications"},{"location":"zDNN/#operations","text":"See Table of Contents for operations list","title":"Operations"},{"location":"zDNN/#element-wise-operations","text":"Back to Table of Contents Addition Subtraction Multiplication Division Minimum Maximum Natural Logarithm Exponential","title":"Element-wise Operations "},{"location":"zDNN/#zdnn_add","text":"Back to Table of Contents Back to Element-wise Operations","title":"zdnn_add"},{"location":"zDNN/#description_27","text":"Given two input tensors in zDNN transformed format, performs element-wise addition and stores the result into the provided output zDNN tensor. Note that for zDNN use, broadcasting of the input tensor(s) must be performed by the caller. As such, the input tensors must be of the same shape.","title":"Description"},{"location":"zDNN/#format_27","text":"zdnn_status zdnn_add(const zdnn_ztensor *input_a, const zdnn_ztensor *input_b, zdnn_ztensor *output);","title":"Format"},{"location":"zDNN/#parameters_25","text":"zdnn_ztensor *input_a Tensor with addends to add to input_b tensor Must follow general tensor requirements zdnn_ztensor *input_b Tensor with addends to add to input_a tensor Must follow general tensor requirements zdnn_ztensor *output Tensor to hold the result of the addition Must follow general tensor requirements","title":"Parameters"},{"location":"zDNN/#returns-see-zdnn-statuses-for-descriptions","text":"ZDNN_OK warning statuses ZDNN_INVALID_SHAPE ZDNN_INVALID_TYPE ZDNN_INVALID_FORMAT hardware statuses","title":"Returns (see zDNN Statuses for descriptions)"},{"location":"zDNN/#framework-examples","text":"TensorFlow Addition ONNX Addition","title":"Framework Examples"},{"location":"zDNN/#zdnn_sub","text":"Back to Table of Contents Back to Element-wise Operations","title":"zdnn_sub"},{"location":"zDNN/#description_28","text":"Given two input tensors in zDNN transformed format, performs element-wise subtraction and stores the result into the provided output zDNN tensor. Note that for zDNN use, broadcasting of the input tensor(s) must be performed by the caller. As such, the input tensors must be of the same shape.","title":"Description"},{"location":"zDNN/#format_28","text":"zdnn_status zdnn_sub(const zdnn_ztensor *input_a, const zdnn_ztensor *input_b, zdnn_ztensor *output);","title":"Format"},{"location":"zDNN/#parameters_26","text":"zdnn_ztensor *input_a Tensor with minuends that will be subtracted by input_b tensor. Must follow general tensor requirements zdnn_ztensor *input_b Tensor with subtrahends to subtract from input_a tensor. Must follow general tensor requirements zdnn_ztensor *output Tensor to hold the result of the subtraction Must follow general tensor requirements","title":"Parameters"},{"location":"zDNN/#returns-see-zdnn-statuses-for-descriptions_1","text":"ZDNN_OK warning statuses ZDNN_INVALID_SHAPE ZDNN_INVALID_TYPE ZDNN_INVALID_FORMAT hardware statuses","title":"Returns (see zDNN Statuses for descriptions)"},{"location":"zDNN/#framework-examples_1","text":"TensorFlow Subtraction ONNX Subtraction","title":"Framework Examples"},{"location":"zDNN/#zdnn_mul","text":"Back to Table of Contents Back to Element-wise Operations","title":"zdnn_mul"},{"location":"zDNN/#description_29","text":"Given two input tensors in zDNN transformed format, performs element-wise multiplication and stores the result into the provided output zDNN tensor. Note that for zDNN use, broadcasting of the input tensor(s) must be performed by the caller. As such, the input tensors must be of the same shape.","title":"Description"},{"location":"zDNN/#format_29","text":"zdnn_status zdnn_mul(const zdnn_ztensor *input_a, const zdnn_ztensor *input_b, zdnn_ztensor *output);","title":"Format"},{"location":"zDNN/#parameters_27","text":"zdnn_ztensor *input_a Tensor with multiplicands that will be multiplied by input_b tensor. Must follow general tensor requirements zdnn_ztensor *input_b Tensor with multipliers for input_a tensor. Must follow general tensor requirements zdnn_ztensor *output Tensor to hold the result of the multiplication. Must follow general tensor requirements","title":"Parameters"},{"location":"zDNN/#returns-see-zdnn-statuses-for-descriptions_2","text":"ZDNN_OK warning statuses ZDNN_INVALID_SHAPE ZDNN_INVALID_TYPE ZDNN_INVALID_FORMAT hardware statuses","title":"Returns (see zDNN Statuses for descriptions)"},{"location":"zDNN/#framework-examples_2","text":"TensorFlow Multiplication ONNX Multiplication","title":"Framework Examples"},{"location":"zDNN/#zdnn_div","text":"Back to Table of Contents Back to Element-wise Operations","title":"zdnn_div"},{"location":"zDNN/#description_30","text":"Given two input tensors in zDNN transformed format, performs element-wise division and stores the result into the provided output zDNN tensor. Note that for zDNN use, broadcasting of the input tensor(s) must be performed by the caller. As such, the input tensors must be of the same shape.","title":"Description"},{"location":"zDNN/#format_30","text":"zdnn_status zdnn_div(const zdnn_ztensor *input_a, const zdnn_ztensor *input_b, zdnn_ztensor *output);","title":"Format"},{"location":"zDNN/#parameters_28","text":"zdnn_ztensor *input_a Tensor with dividends that will be divided by input_b tensor. Must follow general tensor requirements zdnn_ztensor *input_b Tensor with divisors for input_a tensor. Must follow general tensor requirements zdnn_ztensor *output Tensor to hold the result of the division. Must follow general tensor requirements","title":"Parameters"},{"location":"zDNN/#returns-see-zdnn-statuses-for-descriptions_3","text":"ZDNN_OK warning statuses ZDNN_INVALID_SHAPE ZDNN_INVALID_TYPE ZDNN_INVALID_FORMAT hardware statuses","title":"Returns (see zDNN Statuses for descriptions)"},{"location":"zDNN/#framework-examples_3","text":"TensorFlow Division ONNX Division","title":"Framework Examples"},{"location":"zDNN/#zdnn_min","text":"Back to Table of Contents Back to Element-wise Operations","title":"zdnn_min"},{"location":"zDNN/#description_31","text":"Given two input tensors in zDNN transformed format, computes the element-wise minimum and stores the result into the provided output zDNN tensor. Note that for zDNN use, broadcasting of the input tensor(s) must be performed by the caller. As such, the input tensors must be of the same shape.","title":"Description"},{"location":"zDNN/#format_31","text":"zdnn_status zdnn_min(const zdnn_ztensor *input_a, const zdnn_ztensor *input_b, zdnn_ztensor *output);","title":"Format"},{"location":"zDNN/#parameters_29","text":"zdnn_ztensor *input_a Tensor with values that will be compared with input_b tensor. Must follow general tensor requirements zdnn_ztensor *input_b Tensor with values that will be compared with input_a tensor. Must follow general tensor requirements zdnn_ztensor *output Tensor that holds the smaller value from each comparison of the inputs. Must follow general tensor requirements","title":"Parameters"},{"location":"zDNN/#returns-see-zdnn-statuses-for-descriptions_4","text":"ZDNN_OK warning statuses ZDNN_INVALID_SHAPE ZDNN_INVALID_TYPE ZDNN_INVALID_FORMAT hardware statuses","title":"Returns (see zDNN Statuses for descriptions)"},{"location":"zDNN/#framework-examples_4","text":"TensorFlow Minimum ONNX Minimum","title":"Framework Examples"},{"location":"zDNN/#zdnn_max","text":"Back to Table of Contents Back to Element-wise Operations","title":"zdnn_max"},{"location":"zDNN/#description_32","text":"Given two input tensors in zDNN transformed format, computes the element-wise maximum and stores the result into the provided output zDNN tensor. Note that for zDNN use, broadcasting of the input tensor(s) must be performed by the caller. As such, the input tensors must be of the same shape.","title":"Description"},{"location":"zDNN/#format_32","text":"zdnn_status zdnn_max(const zdnn_ztensor *input_a, const zdnn_ztensor *input_b, zdnn_ztensor *output);","title":"Format"},{"location":"zDNN/#parameters_30","text":"zdnn_ztensor *input_a Tensor with values that will be compared with input_b tensor. Must follow general tensor requirements zdnn_ztensor *input_b Tensor with values that will be compared with input_a tensor. Must follow general tensor requirements zdnn_ztensor *output Tensor that holds the larger value from each comparison of the inputs. Must follow general tensor requirements","title":"Parameters"},{"location":"zDNN/#returns-see-zdnn-statuses-for-descriptionss","text":"ZDNN_OK warning statuses ZDNN_INVALID_SHAPE ZDNN_INVALID_TYPE ZDNN_INVALID_FORMAT hardware statuses","title":"Returns (see zDNN Statuses for descriptions)s"},{"location":"zDNN/#framework-examples_5","text":"TensorFlow Maximum ONNX Maximum","title":"Framework Examples"},{"location":"zDNN/#zdnn_log","text":"Back to Table of Contents Back to Element-wise Operations","title":"zdnn_log"},{"location":"zDNN/#description_33","text":"Given an input tensor in zDNN transformed format, computes the natural logarithm element-wise and stores the result into the provided output zDNN tensor.","title":"Description"},{"location":"zDNN/#format_33","text":"zdnn_status zdnn_log(const zdnn_ztensor *input, zdnn_ztensor *output);","title":"Format"},{"location":"zDNN/#parameters_31","text":"zdnn_ztensor *input Tensor with values to evaluate. Must follow general tensor requirements zdnn_ztensor *output Tensor that holds the calculated natural logarithm of each value from input_a Must follow general tensor requirements","title":"Parameters"},{"location":"zDNN/#returns-see-zdnn-statuses-for-descriptions_5","text":"ZDNN_OK warning statuses ZDNN_INVALID_SHAPE ZDNN_INVALID_TYPE ZDNN_INVALID_FORMAT hardware statuses","title":"Returns (see zDNN Statuses for descriptions)"},{"location":"zDNN/#framework-examples_6","text":"TensorFlow Natural Logarithm ONNX Natural Logarithm","title":"Framework Examples"},{"location":"zDNN/#zdnn_exp","text":"Back to Table of Contents Back to Element-wise Operations","title":"zdnn_exp"},{"location":"zDNN/#description_34","text":"Given an input tensor in zDNN transformed format, computes the exponential element-wise and stores the result into the provided output zDNN tensor.","title":"Description"},{"location":"zDNN/#format_34","text":"zdnn_status zdnn_exp(const zdnn_ztensor *input, zdnn_ztensor *output);","title":"Format"},{"location":"zDNN/#parameters_32","text":"zdnn_ztensor *input Tensor with values to evaluate. Must follow general tensor requirements zdnn_ztensor *output Tensor that holds the calculated exponential of each value from input Must follow general tensor requirements","title":"Parameters"},{"location":"zDNN/#returns-see-zdnn-statuses-for-descriptions_6","text":"ZDNN_OK warning statuses ZDNN_INVALID_SHAPE ZDNN_INVALID_TYPE ZDNN_INVALID_FORMAT hardware statuses","title":"Returns (see zDNN Statuses for descriptions)"},{"location":"zDNN/#framework-examples_7","text":"TensorFlow Exponential ONNX Exponential","title":"Framework Examples"},{"location":"zDNN/#activation-operations","text":"Back to Table of Contents Rectified Linear Hyperbolic Tangent Sigmoid Softmax","title":"Activation Operations "},{"location":"zDNN/#zdnn_relu","text":"Back to Table of Contents Back to Activation Operations","title":"zdnn_relu"},{"location":"zDNN/#description_35","text":"Given an input tensor in zDNN transformed format produce an output tensor where the rectified linear function, y = max(0, x) is applied to the input element-wise. If an optional clipping_value is provided, clipping is performed against the intermediate output where z = min(y, clipping_value).","title":"Description"},{"location":"zDNN/#format_35","text":"zdnn_status zdnn_relu(const zdnn_ztensor *input, const void *clipping_value, zdnn_ztensor *output);","title":"Format"},{"location":"zDNN/#parameters_33","text":"zdnn_ztensor *input Tensor with values to evaluate. Must follow general tensor requirements void *clipping_value A pointer to an FP32 value, used to clip input tensor's elements. If set to NULL or 0, no clipping will occur. Must not be a negative value. zdnn_ztensor *output Tensor that holds the rectified linear function result of each value from input Must follow general tensor requirements","title":"Parameters"},{"location":"zDNN/#returns-see-zdnn-statuses-for-descriptions_7","text":"ZDNN_OK warning statuses ZDNN_INVALID_SHAPE ZDNN_INVALID_TYPE ZDNN_INVALID_FORMAT ZDNN_INVALID_CLIPPING_VALUE hardware statuses","title":"Returns (see zDNN Statuses for descriptions)"},{"location":"zDNN/#framework-examples_8","text":"TensorFlow Rectified Linear ONNX Rectified Linear","title":"Framework Examples"},{"location":"zDNN/#zdnn_tanh","text":"Back to Table of Contents Back to Activation Operations","title":"zdnn_tanh"},{"location":"zDNN/#description_36","text":"Given an input tensor in zDNN transformed format, produces an output tensor where the hyperbolic tangent is applied to the input element-wise.","title":"Description"},{"location":"zDNN/#format_36","text":"zdnn_status zdnn_tanh(const zdnn_ztensor *input, zdnn_ztensor *output);","title":"Format"},{"location":"zDNN/#parameters_34","text":"zdnn_ztensor *input Tensor with values to evaluate. Must follow general tensor requirements zdnn_ztensor *output Tensor that holds the hyperbolic tangent result of each value from input Must follow general tensor requirements","title":"Parameters"},{"location":"zDNN/#returns-see-zdnn-statuses-for-descriptions_8","text":"ZDNN_OK warning statuses ZDNN_INVALID_SHAPE ZDNN_INVALID_TYPE ZDNN_INVALID_FORMAT hardware statuses","title":"Returns (see zDNN Statuses for descriptions)"},{"location":"zDNN/#framework-examples_9","text":"TensorFlow Hyperbolic Tangent ONNX Hyperbolic Tangent","title":"Framework Examples"},{"location":"zDNN/#zdnn_sigmoid","text":"Back to Table of Contents Back to Activation Operations","title":"zdnn_sigmoid"},{"location":"zDNN/#description_37","text":"Given an input tensor in zDNN transformed format, produces an output tensor where the sigmoid function is applied to the input element-wise.","title":"Description"},{"location":"zDNN/#format_37","text":"zdnn_status zdnn_sigmoid(const zdnn_ztensor *input, zdnn_ztensor *output);","title":"Format"},{"location":"zDNN/#parameters_35","text":"zdnn_ztensor *input Tensor with values to evaluate. Must follow general tensor requirements zdnn_ztensor *output Tensor that holds the sigmoid result of each value from input Must follow general tensor requirements","title":"Parameters"},{"location":"zDNN/#returns-see-zdnn-statuses-for-descriptions_9","text":"ZDNN_OK warning statuses ZDNN_INVALID_SHAPE ZDNN_INVALID_TYPE ZDNN_INVALID_FORMAT hardware statuses","title":"Returns (see zDNN Statuses for descriptions)"},{"location":"zDNN/#framework-examples_10","text":"TensorFlow Sigmoid ONNX Sigmoid","title":"Framework Examples"},{"location":"zDNN/#zdnn_softmax","text":"Back to Table of Contents Back to Activation Operations","title":"zdnn_softmax"},{"location":"zDNN/#description_38","text":"Given an input tensor in zDNN transformed format, computes the softmax (normalized exponential) for each vector formed in dimension-1, then if act_func is not SOFTMAX_ACT_NONE , the activation function is applied to the results. Finally stores the results into the provided output zDNN tensor. Note: Other parameters, such as axis, are not supported.","title":"Description"},{"location":"zDNN/#format_38","text":"zdnn_status zdnn_softmax(const zdnn_ztensor *input, void *save_area, zdnn_softmax_act act_func, zdnn_ztensor *output);","title":"Format"},{"location":"zDNN/#parameters_36","text":"zdnn_ztensor *input ZDNN_3DS tensor with pre-transformed shape [batch size, batch size, vector dimension size] or output from another operation that is of the correct shape. Must follow general tensor requirements void *save_area A preallocated memory address to use for temporary storage during internal operation processing. The preallocate memory must be at least 8K bytes in size, aligned on a 4k boundary. If set to NULL, the operation will determine, allocate and free storage automatically. zdnn_softmax_act act_func Activation function to apply to the results. SOFTMAX_ACT_NONE or SOFTMAX_ACT_LOG zdnn_ztensor *output ZDNN_3DS tensor with the same shape as input_a that holds the softmax result of each value from input_a . Must follow general tensor requirements","title":"Parameters"},{"location":"zDNN/#programming-notes_6","text":"If all elements of a dimension 1 vector are the largest magnitude negative number possible for the transformed data type, accuracy may be reduced. A ZDNN_3DS tensor is expected, where the transformed_desc dim1 describes the vector, and dim2 and dim4 are used to batch multiple vector requests together. Dim3 must always be 1. The zdnn_softmax operation is performed against the vector in dim1 repeating for each dim1 vector in the dim4 and dim2 dimensions. Tensors that cannot be processed as vectors in dim1 or as batches of dim1 vectors must be coerced or reshaped by the caller. When the entire tensor is to be processed by softmax, it can be coerced by simply creating an alternate descriptor prior to zDNN transformation. For example: A 4D tensor with pre_transformed_desc dimensions 2x2x2x2 and a data array of 16 FP32 entries could have an alternate ZDNN_3DS layout pre_transformed_desc using dimensions 1x1x16 and use the same original data array prior to zdnn_transform_ztensor . After transformation, such a tensor would be valid for zdnn_softmax . In another example, the 4D 2x2x2x2 tensor could be processed as 2 batches of 8 vectors using a ZDNN_3DS layout pre_transformed_desc with dimensions 1x2x8.","title":"Programming Notes"},{"location":"zDNN/#returns-see-zdnn-statuses-for-descriptions_10","text":"ZDNN_OK warning statuses ZDNN_INVALID_SHAPE ZDNN_INVALID_TYPE ZDNN_INVALID_FORMAT ZDNN_ALLOCATION_FAILURE - A preallocated save_area was not specified and internal allocation for the required memory failed. hardware statuses ZDNN_FUNC_RC_F000 - input tensor input->transformed_desc->dim3 was not 1. ZDNN_FUNC_RC_F001 - Invalid act_func","title":"Returns (see zDNN Statuses for descriptions)"},{"location":"zDNN/#framework-examples_11","text":"TensorFlow Softmax ONNX Softmax","title":"Framework Examples"},{"location":"zDNN/#normalization-operations","text":"Back to Table of Contents Mean Reduce Batch Norm","title":"Normalization Operations "},{"location":"zDNN/#zdnn_meanreduce2d","text":"Back to Table of Contents Back to Normalization Operations","title":"zdnn_meanreduce2d"},{"location":"zDNN/#description_39","text":"Given an input tensor in zDNN transformed format, produces a downsampled tensor reducing the middle dimensions to a size of 1 based on the mean of the original values and stores the result to the provided output zDNN tensor.","title":"Description"},{"location":"zDNN/#format_39","text":"zdnn_status zdnn_meanreduce2d(const zdnn_ztensor *input, zdnn_ztensor *output);","title":"Format"},{"location":"zDNN/#parameters_37","text":"zdnn_ztensor *input Must be a ZDNN_NHWC tensor with pre_transformed shape [batch_Num, Height, Width, Channel]. Height and Width dimension must be less than or equal to 1024. Must follow general tensor requirements zdnn_ztensor *output The result tensor which will hold the result of the pooling operation in its buffer. Shape: output dimensions batch_Num and Channel must be the same as the respective input dimensions. output dimensions Height and Width must be 1. Must follow general tensor requirements","title":"Parameters"},{"location":"zDNN/#returns-see-zdnn-statuses-for-descriptions_11","text":"ZDNN_OK ZDNN_INVALID_SHAPE - Shape of input or output tensor is invalid based on given kernel and stride parameters ZDNN_INVALID_TYPE ZDNN_INVALID_FORMAT hardware statuses ZDNN_FUNC_RC_F001 - input tensor has a Height or Width dimension greater than allowed for zdnn_meanreduce2d .","title":"Returns (see zDNN Statuses for descriptions)"},{"location":"zDNN/#framework-examples_12","text":"TensorFlow Reduce Mean with axis set for the Height and Width axes and keepdims set to True. ONNX Reduce Mean","title":"Framework Examples"},{"location":"zDNN/#zdnn_batchnorm","text":"Back to Table of Contents Back to Normalization Operations","title":"zdnn_batchnorm"},{"location":"zDNN/#description_40","text":"Given three input zDNN tensors input_a , input_b , and input_c , computes the batch-normalized result for each vector formed in dimension-1 as follows: output = input_b * input_a + input_c where input_b is a precomputed elementwise divide of scale and variance tensors, and input_c is a precomputed elementwise multiply of (-1) * mean and 'input_b' + input bias tensors.","title":"Description"},{"location":"zDNN/#format_40","text":"zdnn_status zdnn_batchnorm(const zdnn_ztensor *input_a, const zdnn_ztensor *input_b, const zdnn_ztensor *input_c, zdnn_ztensor *output);","title":"Format"},{"location":"zDNN/#parameters_38","text":"zdnn_ztensor *input_a Must be a 4D ZDNN_NHWC tensor Must follow general tensor requirements zdnn_ztensor *input_b Must be a 1D ZDNN_1D tensor Must follow general tensor requirements zdnn_ztensor *input_c Must be a 1D ZDNN_1D tensor Must follow general tensor requirements zdnn_ztensor *output A zdnn_ztensor of the same size as input_a representing the computed value of the above formula Must follow general tensor requirements","title":"Parameters"},{"location":"zDNN/#returns-see-zdnn-statuses-for-descriptions_12","text":"ZDNN_OK warning statuses ZDNN_INVALID_SHAPE ZDNN_INVALID_TYPE ZDNN_INVALID_FORMAT hardware statuses","title":"Returns (see zDNN Statuses for descriptions)"},{"location":"zDNN/#framework-examples_13","text":"TensorFlow Batchnorm ONNX Batchnorm","title":"Framework Examples"},{"location":"zDNN/#zdnn_matmul_op","text":"Back to Table of Contents","title":"zdnn_matmul_op"},{"location":"zDNN/#description_41","text":"Given three input zDNN tensors input_a , input_b , and input_c , determine the matrix multiplication of input_a * input_b then perform one of the following operations, using input_c against the dot product, storing the result into the specified output zDNN tensor: Addition Compare - If dot product is greater than element. Compare - If dot product is greater or equal to element. Compare - If dot product is equal to element. Compare - If dot product is not equal to element. Compare - If dot product is less than or equal to element. Compare - If dot product is less than element. For an operation type of addition, input_c is added to the intermediate dot product. For operation types of comparison, the intermediate dot product is compared to input_c and if the comparison is true, the result is set to a value of 1; otherwise it is set to a value of 0. The outermost dimension can optionally indicate that the inputs are stacks of matrices. The results for each matrix stack is independent of other stacks but all stacks are calculated in a single call.","title":"Description"},{"location":"zDNN/#format_41","text":"zdnn_status zdnn_matmul_op(const zdnn_ztensor *input_a, const zdnn_ztensor *input_b, const zdnn_ztensor *input_c, zdnn_matmul_ops op_type, zdnn_ztensor *output);","title":"Format"},{"location":"zDNN/#input-output-matmul-tensor-requirements","text":"See table in this section for pre_transformed_desc and shape requirements for each tensor. All tensors must either be stacked or unstacked. Must follow general tensor requirements type input_a input_b input_c result unstacked ZDNN_2D (m, n) ZDNN_2D (n, p) ZDNN_1D (p) ZDNN_2D (m, p) stacked ZDNN_3DS (s, m, n) ZDNN_3DS (s, n, p) ZDNN_2DS (s, p) ZDNN_3DS (s, m, p)","title":"Input / Output matmul tensor requirements "},{"location":"zDNN/#parameters_39","text":"zdnn_ztensor *input_a Input tensor with the first matrix for multiplication pre_transformed shape and layout must match matmul tensor requirements zdnn_ztensor *input_b Input tensor with the second matrix for multiplication pre_transformed shape and layout must match matmul tensor requirements zdnn_ztensor *input_c Input tensor that will have the requested operation performed against the intermediate dot product of input_a and input_b . pre_transformed shape and layout must match matmul tensor requirements zdnn_matmul_ops op_type Operation to perform on dot product. MATMUL_OP_ADDITION MATMUL_OP_GREATER MATMUL_OP_GREATER_EQUAL MATMUL_OP_EQUAL MATMUL_OP_NOT_EQUAL MATMUL_OP_LESSER_EQUAL MATMUL_OP_LESSER zdnn_ztensor *output The output tensor which will hold the result of the operation in its buffer. pre_transformed shape and layout must match matmul tensor requirements","title":"Parameters"},{"location":"zDNN/#programming-notes_7","text":"Care must be exercised when comparing values for equality or inequality since the order of operations and rounding may produce, what appear to be, slightly different values when they are essentially the same value.","title":"Programming Notes"},{"location":"zDNN/#returns-see-zdnn-statuses-for-descriptions_13","text":"ZDNN_OK ZDNN_INVALID_SHAPE ZDNN_INVALID_TYPE ZDNN_INVALID_FORMAT hardware statuses ZDNN_FUNC_RC_F000 - Invalid op_type .","title":"Returns (see zDNN Statuses for descriptions)"},{"location":"zDNN/#framework-examples_14","text":"TensorFlow MatMul ONNX MatMul","title":"Framework Examples"},{"location":"zDNN/#zdnn_matmul_bcast_op","text":"Back to Table of Contents","title":"zdnn_matmul_bcast_op"},{"location":"zDNN/#description_42","text":"Given three input zDNN tensors input_a , input_b , and input_c , determine the matrix multiplication of input_a * input_b , then perform one of the following operations, using input_c against the dot product, storing the result into the specified output zDNN tensor: Addition The outermost dimension for input_a can optionally indicate that the input is a stack of matrices. Each stack of input_a is then multiplied by the same input_b matrix and input_c which are broadcast over each stack of input_a . Results for each stack are returned in the corresponding stack index of output .","title":"Description"},{"location":"zDNN/#format_42","text":"zdnn_status zdnn_matmul_bcast_op(const zdnn_ztensor *input_a, const zdnn_ztensor *input_b, const zdnn_ztensor *input_c, zdnn_matmul_bcast_ops op_type, zdnn_ztensor *output);","title":"Format"},{"location":"zDNN/#input-output-matmul-broadcast-tensor-requirements","text":"See table in this section for pre_transformed_desc and shape requirements for each tensor. Must follow general tensor requirements input_a input_b input_c result ZDNN_3DS (s, m, n) ZDNN_2D (n, p) ZDNN_1D (p) ZDNN_3DS (s, m, p)","title":"Input / Output matmul broadcast tensor requirements "},{"location":"zDNN/#parameters_40","text":"zdnn_ztensor *input_a Input tensor with the first matrix for multiplication. pre_transformed shape and layout must match matmul broadcast tensor requirements zdnn_ztensor *input_b Input tensor with the second matrix for multiplication. The same single input_b matrix is broadcast and used as the multiplier for each stack dimension of input_a pre_transformed shape and layout must match matmul broadcast tensor requirements zdnn_ztensor *input_c Input tensor that will have the requested operation performed against the intermediate dot product for each \"m\" dimension in output . pre_transformed shape and layout must match matmul broadcast tensor requirements zdnn_matmul_bcast_ops op_type Operation to perform on dot product. MATMUL_BCAST_OP_ADDITION zdnn_ztensor *output The output tensor which will hold the result of the operation in its buffer. pre_transformed shape and layout must match matmul broadcast tensor requirements","title":"Parameters"},{"location":"zDNN/#programming-notes_8","text":"zdnn_matmul_bcast_ops only supports MATMUL_BCAST_OP_ADDITION op_type, any other op_types will be ignored and may not operate compatibly in the future.","title":"Programming Notes"},{"location":"zDNN/#returns-see-zdnn-statuses-for-descriptions_14","text":"ZDNN_OK ZDNN_INVALID_SHAPE ZDNN_INVALID_TYPE ZDNN_INVALID_FORMAT hardware statuses","title":"Returns (see zDNN Statuses for descriptions)"},{"location":"zDNN/#framework-examples_15","text":"TensorFlow MatMul ONNX MatMul","title":"Framework Examples"},{"location":"zDNN/#zdnn_lstm","text":"Back to Table of Contents","title":"zdnn_lstm"},{"location":"zDNN/#description_43","text":"Implements Long-Short Term Memory layer (LSTM - Hochreiter 1997). The following formula is computed for the input tensor input(t) for all time steps: (Default: f=Sigmoid, g=Tanh, h=Tanh): - it = f(Xt*(Wi^T) + Ht-1*(Ri^T) + Wbi + Rbi) - ft = f(Xt*(Wf^T) + Ht-1*(Rf^T) + Wbf + Rbf) - ct = g(Xt*(Wc^T) + Ht-1*(Rc^T) + Wbc + Rbc) - Ct = ft (.) Ct-1 + it (.) ct - ot = f(Xt*(Wo^T) + Ht-1*(Ro^T) + Wbo + Rbo) - Ht = ot (.) h(Ct)","title":"Description"},{"location":"zDNN/#format_43","text":"zdnn_status zdnn_lstm(const zdnn_ztensor *input, const zdnn_ztensor *h0, const zdnn_ztensor *c0, const zdnn_ztensor *weights, const zdnn_ztensor *biases, const zdnn_ztensor *hidden_weights, const zdnn_ztensor *hidden_biases, lstm_gru_direction direction, void *work_area, zdnn_ztensor *hn_output, zdnn_ztensor *cf_output); Also see an example in the usage example section.","title":"Format"},{"location":"zDNN/#lstm-input-output-requirements","text":"num_hidden dimensions: Any num_hidden dimension must be less than or equal to 8192 elements.","title":"LSTM Input / Output requirements"},{"location":"zDNN/#parameters_41","text":"zdnn_ztensor *input Input must be a tensor with the shape (num_timesteps, num_batches, num_features) prior to transformation with the zdnn_transform_ztensor API. Expects pre_transformed_desc->layout to be ZDNN_3DS . Must follow general tensor requirements zdnn_ztensor *h0 Tensor containing the initial hidden state with shape (num_dirs, num_batches, num_hidden) prior to transformation with the zdnn_transform_ztensor API. Expects pre_transformed_desc->layout to be ZDNN_3DS . Must follow general tensor requirements Must follow num_hidden requirements zdnn_ztensor *c0 Tensor containing the initial cell state with shape (num_dirs, num_batches, num_hidden) prior to transformation with the zdnn_transform_ztensor API. Expects pre_transformed_desc->layout to be ZDNN_3DS . Must follow general tensor requirements Must follow num_hidden requirements zdnn_ztensor *weights Tensor containing the concatenated input connection weights in Forget, Input, Cell, Output (FICO) order. Prior to transformation, each gate needs to be transposed to shape (num_dirs, num_features, num_hidden) by the caller. Expects pre_transformed_desc->layout to be ZDNN_3DS . Expects zdnn_concat_info having the following flags turned on: RNN_TYPE_LSTM USAGE_WEIGHTS Appropriate PREV_LAYER flag: PREV_LAYER_NONE if input tensor is not from a previous RNN layer PREV_LAYER_UNI if input tensor is uni-directional output from a previous RNN layer PREV_LAYER_BIDIR if input tensor is bi-directional output from a previous RNN layer Must follow concatenated tensor requirements Must follow num_hidden requirements zdnn_ztensor *biases Tensor containing the concatenated input connection bias in Forget, Input, Cell, Output (FICO) order. Prior to transformation, expects each gate needs to be shape (num_dirs, num_hidden). Expects pre_transformed_desc->layout to be ZDNN_2DS . Expects zdnn_concat_info having the following flags turned on: RNN_TYPE_LSTM USAGE_HIDDEN_WEIGHTS Appropriate PREV_LAYER flag: PREV_LAYER_NONE if input tensor is not from a previous RNN layer PREV_LAYER_UNI if input tensor is uni-directional output from a previous RNN layer PREV_LAYER_BIDIR if input tensor is bi-directional output from a previous RNN layer Must follow concatenated tensor requirements Must follow num_hidden requirements zdnn_ztensor *hidden_weights Tensor containing the concatenated hidden connection weights in Forget, Input, Cell, Output (FICO) order. Prior to transformation, each gate needs to be transposed to shape (num_dirs, num_hidden, num_hidden) by the caller. Expects pre_transformed_desc->layout to be ZDNN_3DS . Expects zdnn_concat_info having the following flags turned on: RNN_TYPE_LSTM USAGE_BIASES Appropriate PREV_LAYER flag: PREV_LAYER_NONE if input tensor is not from a previous RNN layer PREV_LAYER_UNI if input tensor is uni-directional output from a previous RNN layer PREV_LAYER_BIDIR if input tensor is bi-directional output from a previous RNN layer Must follow concatenated tensor requirements Must follow num_hidden requirements zdnn_ztensor *hidden_biases Tensor containing the concatenated hidden connection bias in Forget, Input, Cell, Output (FICO) order. Prior to transformation, expects each gate needs to be shape (num_dirs, num_hidden). Expects pre_transformed_desc->layout to be ZDNN_2DS . Expects zdnn_concat_info having the following flags turned on: RNN_TYPE_LSTM USAGE_HIDDEN_BIASES Appropriate PREV_LAYER flag: PREV_LAYER_NONE if input tensor is not from a previous RNN layer PREV_LAYER_UNI if input tensor is uni-directional output from a previous RNN layer PREV_LAYER_BIDIR if input tensor is bi-directional output from a previous RNN layer Must follow concatenated tensor requirements Must follow num_hidden requirements lstm_gru_direction direction Direction indicator of lstm_gru_direction direction type. Valid values: FWD (forward) BWD (backward) BIDIR (bi-directional). For input and output shapes, the num_dirs dimension should be: 1 for unidirectional calls such as FWD or BWD 2 for bidirectional calls such that: dimension 0 contains FWD values. dimension 1 contains BWD values. void *work_area A preallocated memory address to use for temporary storage during internal operation processing. If set to NULL, the operation will determine, allocate and free storage automatically. Amount of required storage can be determined given the LSTM timestep, batch, and num_hidden values. The sample code below creates a ztensor descriptor that is an equivalent size of the required work_area . To use this sample code yourself, replace the num_timesteps , num_batches , and num_hidden variables with your own values. zdnn_tensor_desc desc; desc.dim4 = (4 * num_timesteps) + 6; desc.dim3 = 1; desc.dim2 = num_batches; desc.dim1 = num_hidden; uint64_t work_area_size = zdnn_getsize_ztensor(&desc); For bidirectional, twice the amount of contiguous storage is required. The start of the buffer must be 4k aligned. zdnn_ztensor *hn_output Output results of the hidden states Expects pre_transformed_desc->layout to be ZDNN_4DS . Must follow general tensor requirements Must follow num_hidden requirements Output pre-transformed shapes: all timesteps: (num_timesteps, num_dirs, num_batches, num_hidden) final timestep only: (1, num_dirs, num_batches, num_hidden) For bidirectional ( BIDIR ) output: Forward and backward results are concatenated on the innermost dimension. Can be used directly as input for subsequent RNN layers without needing untransformation. Can not be used directly as input for other non-RNN zDNN ops. Untransformation is supported. Note that for BWD and the backward component of BIDIR directions, the output order matches the order of the input, not the processing order. For example, the first input timestep is the last to be processed and its result is the first timestep of the output. zdnn_ztensor *cf_output Output results of the cell state for the last processed timestep Expects pre_transformed_desc->layout to be ZDNN_4DS . Must follow general tensor requirements Must follow num_hidden requirements Output pre-transformed shapes: (1, num_dirs, num_batches, num_hidden) For bidirectional ( BIDIR ): Forward and backward results are concatenated on the innermost dimension. Can not be used directly as input for other non-RNN zDNN ops. Untransformation is supported.","title":"Parameters"},{"location":"zDNN/#summary","text":"pre-transformed layout pre-transformed shape input ZDNN_3DS (num_timesteps, num_batches, num_features) h0 ZDNN_3DS (num_dirs, num_batches, num_hidden) c0 ZDNN_3DS (num_dirs, num_batches, num_hidden) weights ZDNN_3DS (num_dirs, num_features, num_hidden) bias ZDNN_2DS (num_dirs, num_hidden) hidden_weights ZDNN_3DS (num_dirs, num_hidden, num_hidden) hidden_biases ZDNN_2DS (num_dirs, num_hidden) hn_output ZDNN_4DS (num_timesteps, num_dirs, num_batches, num_hidden) (last timestep only when num_timesteps = 1) cf_output ZDNN_4DS (1, num_dirs, num_batches, num_hidden) create transformed descriptor via input zdnn_generate_transformed_desc h0 zdnn_generate_transformed_desc c0 zdnn_generate_transformed_desc weights zdnn_generate_transformed_desc_concatenated - RNN_TYPE_LSTM + USAGE_WEIGHTS + one of the following: PREV_LAYER_NONE / PREV_LAYER_UNI / PREV_LAYER_BIDIR bias zdnn_generate_transformed_desc_concatenated - RNN_TYPE_LSTM + USAGE_BIASES + one of the following: PREV_LAYER_NONE / PREV_LAYER_UNI / PREV_LAYER_BIDIR hidden_weights zdnn_generate_transformed_desc_concatenated - RNN_TYPE_LSTM + USAGE_HIDDEN_WEIGHTS + one of the following: PREV_LAYER_NONE / PREV_LAYER_UNI / PREV_LAYER_BIDIR hidden_biases zdnn_generate_transformed_desc_concatenated - RNN_TYPE_LSTM + USAGE_HIDDEN_BIASES + one of the following: PREV_LAYER_NONE / PREV_LAYER_UNI / PREV_LAYER_BIDIR hn_output zdnn_generate_transformed_desc cf_output zdnn_generate_transformed_desc","title":"Summary"},{"location":"zDNN/#returns-see-zdnn-statuses-for-descriptions_15","text":"ZDNN_OK ZDNN_INVALID_TYPE ZDNN_INVALID_FORMAT ZDNN_INVALID_SHAPE - (if any of the following are not true) hn_output timesteps dimension must be 1 or the same size as input timestep dimension. All tensors with a direction dimension have the same direction dimension size. input timestep dimension must be greater than or equal to 1. Other general shape violations (exceeds MDIS, etc.) ZDNN_INVALID_DIRECTION - direction parameter was not a recognized lstm_gru_direction . ZDNN_ALLOCATION_FAILURE - A preallocated work_area was not specified and internal allocation for the required memory failed. hardware statuses","title":"Returns (see zDNN Statuses for descriptions)"},{"location":"zDNN/#framework-examples_16","text":"TensorFlow LSTM ONNX LSTM","title":"Framework Examples"},{"location":"zDNN/#zdnn_gru","text":"Back to Table of Contents","title":"zdnn_gru"},{"location":"zDNN/#description_44","text":"Implements Gated Recurrent Unit (Kyunghyun Cho 2014). Supports only reset after linear. The following formula is computed for the input tensor input(t) for all time steps: (Default: f=Sigmoid, g=Tanh): - zt = f(Xt*(Wz^T) + Ht-1*(Rz^T) + Wbz + Rbz) - rt = f(Xt*(Wr^T) + Ht-1*(Rr^T) + Wbr + Rbr) - ht = g(Xt*(Wh^T) + (rt (.) (Ht-1*(Rh^T) + Rbh)) + Wbh) - Ht = (1 - zt) (.) ht + zt (.) Ht-1","title":"Description"},{"location":"zDNN/#format_44","text":"zdnn_status zdnn_gru(const zdnn_ztensor *input, const zdnn_ztensor *h0, const zdnn_ztensor *weights, const zdnn_ztensor *biases, const zdnn_ztensor *hidden_weights, const zdnn_ztensor *hidden_biases, lstm_gru_direction direction, void *work_area, zdnn_ztensor *hn_output); Also see an example in the usage example section.","title":"Format"},{"location":"zDNN/#gru-input-output-requirements","text":"num_hidden dimensions: Any num_hidden dimension must be less than or equal to 10880 elements.","title":"GRU Input / Output requirements"},{"location":"zDNN/#parameters_42","text":"zdnn_ztensor *input Input must be a tensor with the shape (num_timesteps, num_batches, num_features) prior to transformation with the zdnn_transform_ztensor API. Expects pre_transformed_desc->layout to be ZDNN_3DS . Must follow general tensor requirements zdnn_ztensor *h0 Tensor containing the initial hidden state with shape (num_dirs, num_batches, num_hidden) prior to transformation with the zdnn_transform_ztensor API. Expects pre_transformed_desc->layout to be ZDNN_3DS . Must follow general tensor requirements Must follow num_hidden requirements zdnn_ztensor *weights Tensor containing the concatenated input connection weights in (Z)update, Reset, Hidden, (ZRH) order. Prior to transformation, each gate needs to be transposed to shape (num_dirs, num_features, num_hidden) by the caller. Expects pre_transformed_desc->layout to be ZDNN_3DS . Expects zdnn_concat_info having the following flags turned on: RNN_TYPE_GRU USAGE_WEIGHTS Appropriate PREV_LAYER flag: PREV_LAYER_NONE if input tensor is not from a previous RNN layer PREV_LAYER_UNI if input tensor is uni-directional output from a previous RNN layer PREV_LAYER_BIDIR if input tensor is bi-directional output from a previous RNN layer Must follow concatenated tensor requirements Must follow num_hidden requirements zdnn_ztensor *biases Tensor containing the concatenated input connection bias in (Z)update, Reset, Hidden, (ZRH) order. Prior to transformation, expects each gate needs to be shape (num_dirs, num_hidden). Expects pre_transformed_desc->layout to be ZDNN_2DS . Expects zdnn_concat_info having the following flags turned on: RNN_TYPE_GRU USAGE_HIDDEN_WEIGHTS Appropriate PREV_LAYER flag: PREV_LAYER_NONE if input tensor is not from a previous RNN layer PREV_LAYER_UNI if input tensor is uni-directional output from a previous RNN layer PREV_LAYER_BIDIR if input tensor is bi-directional output from a previous RNN layer Must follow concatenated tensor requirements Must follow num_hidden requirements zdnn_ztensor *hidden_weights Tensor containing the concatenated hidden connection weights in (Z)update, Reset, Hidden, (ZRH) order. Prior to transformation, each gate needs to be transposed to shape (num_dirs, num_hidden, num_hidden) by the caller. Expects pre_transformed_desc->layout to be ZDNN_3DS . Expects zdnn_concat_info having the following flags turned on: RNN_TYPE_GRU USAGE_BIASES Appropriate PREV_LAYER flag: PREV_LAYER_NONE if input tensor is not from a previous RNN layer PREV_LAYER_UNI if input tensor is uni-directional output from a previous RNN layer PREV_LAYER_BIDIR if input tensor is bi-directional output from a previous RNN layer Must follow concatenated tensor requirements Must follow num_hidden requirements zdnn_ztensor *hidden_biases Tensor containing the concatenated hidden connection bias in (Z)update, Reset, Hidden, (ZRH) order. Prior to transformation, expects each gate needs to be shape (num_dirs, num_hidden). Expects pre_transformed_desc->layout to be ZDNN_2DS . Expects zdnn_concat_info having the following flags turned on: RNN_TYPE_GRU USAGE_HIDDEN_BIASES Appropriate PREV_LAYER flag: PREV_LAYER_NONE if input tensor is not from a previous RNN layer PREV_LAYER_UNI if input tensor is uni-directional output from a previous RNN layer PREV_LAYER_BIDIR if input tensor is bi-directional output from a previous RNN layer Must follow concatenated tensor requirements Must follow num_hidden requirements lstm_gru_direction direction Direction indicator of lstm_gru_direction direction type. Valid values: FWD (forward) BWD (backward) BIDIR (bi-directional). For input shapes, the num_dirs dimension should be: 1 for unidirectional calls such as FWD or BWD 2 for bidirectional calls such that: dimension 0 contains FWD values. dimension 1 contains BWD values. void *work_area A preallocated memory address to use for temporary storage during internal operation processing. If set to NULL, the operation will determine, allocate and free storage automatically. Amount of required storage can be determined given the GRU timestep, batch, and num_hidden values. The sample code below creates a ztensor descriptor that is an equivalent size of the required work_area . To use this sample code yourself, replace the num_timesteps , num_batches , and num_hidden variables with your own values. zdnn_tensor_desc desc; desc.dim4 = (3 * num_timesteps) + 5; desc.dim3 = 1; desc.dim2 = num_batches; desc.dim1 = num_hidden; uint64_t work_area_size = zdnn_getsize_ztensor(&desc); For bidirectional, twice the amount of contiguous storage is required. The start of the buffer must be 4k aligned. zdnn_ztensor *hn_output Output results of the hidden states Expects pre_transformed_desc->layout to be ZDNN_4DS . Must follow general tensor requirements Must follow num_hidden requirements Output pre-transformed shapes: all timesteps: (num_timesteps, num_dirs, num_batches, num_hidden) final timestep only: (1, num_dirs, num_batches, num_hidden) For bidirectional ( BIDIR ) output: Forward and backward results are concatenated on the innermost dimension. Can be used directly as input for subsequent RNN layers without needing untransformation. Can not be used directly as input for other non-RNN zDNN ops. Untransformation is supported. Note that for BWD and the backward component of BIDIR directions, the output order matches the order of the input, not the processing order. For example, the first input timestep is the last to be processed and its result is the first timestep of the output.","title":"Parameters"},{"location":"zDNN/#summary_1","text":"pre-transformed layout pre-transformed shape input ZDNN_3DS (num_timesteps, num_batches, num_features) h0 ZDNN_3DS (num_dirs, num_batches, num_hidden) c0 ZDNN_3DS (num_dirs, num_batches, num_hidden) weights ZDNN_3DS (num_dirs, num_features, num_hidden) bias ZDNN_2DS (num_dirs, num_hidden) hidden_weights ZDNN_3DS (num_dirs, num_hidden, num_hidden) hidden_biases ZDNN_2DS (num_dirs, num_hidden) hn_output ZDNN_4DS (num_timesteps, num_dirs, num_batches, num_hidden) (last timestep only when num_timesteps = 1) create transformed descriptor via input zdnn_generate_transformed_desc h0 zdnn_generate_transformed_desc c0 zdnn_generate_transformed_desc weights zdnn_generate_transformed_desc_concatenated - RNN_TYPE_LSTM + USAGE_WEIGHTS + one of the following: PREV_LAYER_NONE / PREV_LAYER_UNI / PREV_LAYER_BIDIR bias zdnn_generate_transformed_desc_concatenated - RNN_TYPE_LSTM + USAGE_BIASES + one of the following: PREV_LAYER_NONE / PREV_LAYER_UNI / PREV_LAYER_BIDIR hidden_weights zdnn_generate_transformed_desc_concatenated - RNN_TYPE_LSTM + USAGE_HIDDEN_WEIGHTS + one of the following: PREV_LAYER_NONE / PREV_LAYER_UNI / PREV_LAYER_BIDIR hidden_biases zdnn_generate_transformed_desc_concatenated - RNN_TYPE_LSTM + USAGE_HIDDEN_BIASES + one of the following: PREV_LAYER_NONE / PREV_LAYER_UNI / PREV_LAYER_BIDIR hn_output zdnn_generate_transformed_desc","title":"Summary"},{"location":"zDNN/#returns-see-zdnn-statuses-for-descriptions_16","text":"ZDNN_OK ZDNN_INVALID_TYPE ZDNN_INVALID_FORMAT ZDNN_INVALID_SHAPE - (if any of the following are not true) hn_output timesteps dimension must be 1 or the same size as input timestep dimension. All tensors with a direction dimension have the same direction dimension size. input timestep dimension must be greater than or equal to 1. Other general shape violations (exceeds MDIS, etc.) ZDNN_INVALID_DIRECTION - direction parameter was not a recognized lstm_gru_direction . ZDNN_ALLOCATION_FAILURE - A preallocated work_area was not specified and internal allocation for the required memory failed. hardware statuses","title":"Returns (see zDNN Statuses for descriptions)"},{"location":"zDNN/#framework-examples_17","text":"TensorFlow GRU ONNX GRU","title":"Framework Examples"},{"location":"zDNN/#zdnn_avgpool2d","text":"Back to Table of Contents","title":"zdnn_avgpool2d"},{"location":"zDNN/#description_45","text":"Given an input tensor in zDNN transformed format, padding type, kernel size and kernel stride, produces a downsampled tensor reducing the middle dimensions based on the mean values within the kernel window at each step and stores the results into the provided output zDNN tensor.","title":"Description"},{"location":"zDNN/#format_45","text":"zdnn_status zdnn_avgpool2d(const zdnn_ztensor *input, zdnn_pool_padding padding_type, uint32_t kernel_height, uint32_t kernel_width, uint32_t stride_height, uint32_t stride_width, zdnn_ztensor *output);","title":"Format"},{"location":"zDNN/#parameters_43","text":"zdnn_ztensor *input Tensor with original values to be downsampled in the output tensor. Must be a ZDNN_NHWC tensor with pre_transformed shape [batch_Num, Height, Width, Channel]. See Parameter Restrictions below for information on the expected shape of the input tensor. Must follow general tensor requirements padding_type The type of padding to use for the pooling operations. Valid values: are SAME_PADDING or VALID_PADDING . See Parameter Restrictions below for information on the expected value of padding_type. For information on \"same\" vs \"valid\" padding see: https://www.pico.net/kb/what-is-the-difference-between-same-and-valid-padding-in-tf-nn-max-pool-of-tensorflow . kernel_height Size of the kernel window that passes over the input's height dimension. See Parameter Restrictions below for information on the expected value of kerneL_height. kernel_width Size of the kernel window that passes over the input's width dimension. See Parameter Restrictions below for information on the expected value of kerneL_width. stride_height Number of positions the kernel moves over input's height dimension at each step. If stride_height is 0 then stride_width must also be 0. If strides are greater than 0 then stride_height must be less than or equal to 30. stride_width Number of positions the kernel moves over the input's width dimension at each step. If stride_height is 0 then stride_width must also be 0. If strides are greater than 0 then stride_width must be less than or equal to 30. zdnn_ztensor *output The result tensor which will hold the result of the pooling operation its buffer. Must be a ZDNN_NHWC tensor with pre_transformed shape [batch_Num, Height, Width, Channel]. See Parameter Restrictions below for information on the expected shape of the output tensor. Must follow general tensor requirements","title":"Parameters"},{"location":"zDNN/#avgpool2d-parameter-restrictions","text":"Parameter restrictions may vary based on provided strides and padding_type. Input tensor batch_Num and Channel dimensions must always match the output tensor's respective dimensions. If strides are 0: Both input tensor's Height dimension and the kernel_height must match and be less than or equal to 1024. Both input tensor's Width dimension and the kernel_width must match and be less than or equal to 1024. Output tensor's height and width dimensions must be 1. padding_type must be VALID_PADDING . If strides are greater than zero: kernel_width and kernel_height must be less than or equal to 64. input tensor's height or weight dimension must not be greater than 1024. If padding_type is SAME_PADDING : Output tensor's height dimension must equal ceil((float)input's height / stride_height) . Output tensor's width dimension must equal ceil((float)input's width / stride_width) . If padding_type is VALID_PADDING : Output tensor's height dimension must equal ceil((float)(input's height - kernel_height + 1) / stride_height) . Output tensor's width dimension must equal ceil((float)(input's width - kernel_width + 1) / stride_width) .","title":"AvgPool2D Parameter Restrictions "},{"location":"zDNN/#programming-notes_9","text":"If the magnitude of difference between elements of input is large (greater than 10), accuracy may be reduced.","title":"Programming Notes"},{"location":"zDNN/#returns-see-zdnn-statuses-for-descriptions_17","text":"ZDNN_OK ZDNN_INVALID_SHAPE Shape of input or output tensor is invalid based on given kernel and stride parameters Other general shape violations (exceeds MDIS, etc.) ZDNN_INVALID_TYPE ZDNN_INVALID_FORMAT ZDNN_INVALID_STRIDE_PADDING ZDNN_INVALID_STRIDES - One stride was non-zero, but not the other. hardware statuses ZDNN_EXCEEDS_MDIS will also occur if any of the following conditions occur: stride_height is larger than zdnn_get_nnpa_max_dim_idx_size . stride_width is larger than zdnn_get_nnpa_max_dim_idx_size . kernel_height is 0 or is larger than zdnn_get_nnpa_max_dim_idx_size . kernel_width is 0 or is larger than zdnn_get_nnpa_max_dim_idx_size . ZDNN_FUNC_RC_F000 - Invalid padding_type ZDNN_FUNC_RC_F001 - stride_height = 0 and stride_width = 0, but a kernel parameter is greater than allowed (see kernel_height or kernel_width above) ZDNN_FUNC_RC_F002 - stride_height > 0 and stride_width > 0, but a kernel parameter is greater than allowed (see kernel_height or kernel_width above) ZDNN_FUNC_RC_F003 - stride_height > 0 and stride_width > 0, but a stride parameter is greater than allowed (see stride_height or stride_width above) ZDNN_FUNC_RC_F004 - stride_height > 0 and stride_width > 0, but either input tensor's height or weight dimension is greater than 1024.","title":"Returns (see zDNN Statuses for descriptions)"},{"location":"zDNN/#framework-examples_18","text":"TensorFlow AvgPool ONNX AvgPool","title":"Framework Examples"},{"location":"zDNN/#zdnn_maxpool2d","text":"Back to Table of Contents","title":"zdnn_maxpool2d"},{"location":"zDNN/#description_46","text":"Given an input tensor in zDNN transformed format, padding type, kernel size and kernel stride, produces a downsampled tensor reducing the middle dimensions based on the maximum values within the kernel window at each step and stores the results into the provided output zDNN tensor.","title":"Description"},{"location":"zDNN/#format_46","text":"zdnn_status zdnn_maxpool2d(const zdnn_ztensor *input, zdnn_pool_padding padding_type, uint32_t kernel_height, uint32_t kernel_width, uint32_t stride_height, uint32_t stride_width, zdnn_ztensor *output);","title":"Format"},{"location":"zDNN/#parameters_44","text":"zdnn_ztensor *input Tensor with original values to be downsampled in the output tensor. Must be a ZDNN_NHWC tensor with pre_transformed shape [batch_Num, Height, Width, Channel]. See Parameter Restrictions below for information on the expected shape of the input tensor. Must follow general tensor requirements padding_type The type of padding to use for the pooling operations. Valid values: are SAME_PADDING or VALID_PADDING . See Parameter Restrictions below for information on the expected value of padding_type. For information on \"same\" vs \"valid\" padding see: https://www.pico.net/kb/what-is-the-difference-between-same-and-valid-padding-in-tf-nn-max-pool-of-tensorflow . kernel_height Size of the kernel window that passes over the input's height dimension. See Parameter Restrictions below for information on the expected value of kerneL_height. kernel_width Size of the kernel window that passes over the input's width dimension. See Parameter Restrictions below for information on the expected value of kerneL_width. stride_height Number of positions the kernel moves over input's height dimension at each step. If stride_height is 0 then stride_width must also be 0. If strides are greater than 0 then stride_height must be less than or equal to 30. stride_width Number of positions the kernel moves over the input's width dimension at each step. If stride_height is 0 then stride_width must also be 0. If strides are greater than 0 then stride_width must be less than or equal to 30. zdnn_ztensor *output The result tensor which will hold the result of the pooling operation its buffer. Must be a ZDNN_NHWC tensor with pre_transformed shape [batch_Num, Height, Width, Channel]. See Parameter Restrictions below for information on the expected shape of the output tensor. Must follow general tensor requirements","title":"Parameters"},{"location":"zDNN/#maxpool2d-parameter-restrictions","text":"Parameter restrictions may vary based on provided strides and padding_type. Input tensor batch_Num and Channel dimensions must always match the output tensor's respective dimensions. If strides are 0: Both input tensor's Height dimension and the kernel_height must match and be less than or equal to 1024. Both input tensor's Width dimension and the kernel_width must match and be less than or equal to 1024. Output tensor's height and width dimensions must be 1. padding_type must be VALID_PADDING . If strides are greater than zero: kernel_width and kernel_height must be less than or equal to 64. input tensor's height or weight dimension must not be greater than 1024. If padding_type is SAME_PADDING : Output tensor's height dimension must equal ceil((float)input's height / stride_height) . Output tensor's width dimension must equal ceil((float)input's width / stride_width) . If padding_type is VALID_PADDING : Output tensor's height dimension must equal ceil((float)(input's height - kernel_height + 1) / stride_height) . Output tensor's width dimension must equal ceil((float)(input's width - kernel_width + 1) / stride_width) .","title":"MaxPool2D Parameter Restrictions "},{"location":"zDNN/#programming-notes_10","text":"If the magnitude of difference between elements of input is large (greater than 10), accuracy may be reduced.","title":"Programming Notes"},{"location":"zDNN/#returns-see-zdnn-statuses-for-descriptions_18","text":"ZDNN_OK ZDNN_INVALID_SHAPE Shape of input or output tensor is invalid based on given kernel and stride parameters Other general shape violations (exceeds MDIS, etc.) ZDNN_INVALID_TYPE ZDNN_INVALID_FORMAT ZDNN_INVALID_STRIDE_PADDING ZDNN_INVALID_STRIDES - One stride was non-zero, but not the other. hardware statuses ZDNN_EXCEEDS_MDIS will also occur if any of the following conditions occur: stride_height is larger than zdnn_get_nnpa_max_dim_idx_size . stride_width is larger than zdnn_get_nnpa_max_dim_idx_size . kernel_height is 0 or is larger than zdnn_get_nnpa_max_dim_idx_size . kernel_width is 0 or is larger than zdnn_get_nnpa_max_dim_idx_size . ZDNN_FUNC_RC_F000 - Invalid padding_type ZDNN_FUNC_RC_F001 - stride_height = 0 and stride_width = 0, but a kernel parameter is greater than allowed (see kernel_height or kernel_width above) ZDNN_FUNC_RC_F002 - stride_height > 0 and stride_width > 0, but a kernel parameter is greater than allowed (see kernel_height or kernel_width above) ZDNN_FUNC_RC_F003 - stride_height > 0 and stride_width > 0, but a stride parameter is greater than allowed (see stride_height or stride_width above) ZDNN_FUNC_RC_F004 - stride_height > 0 and stride_width > 0, but either input tensor's height or weight dimension is greater than 1024.","title":"Returns (see zDNN Statuses for descriptions)"},{"location":"zDNN/#framework-examples_19","text":"TensorFlow MaxPool ONNX MaxPool","title":"Framework Examples"},{"location":"zDNN/#zdnn_conv2d","text":"Back to Table of Contents","title":"zdnn_conv2d"},{"location":"zDNN/#description_47","text":"Perform 2D convolution over an input tensor in zDNN transformed format. First the input tensor is convolved with the kernel tensor. Then the bias tensor is added to the results. Then if act_func is not CONV2D_ACT_NONE , the activation function is applied to the results. Then if act_func is set to CONV2D_ACT_RELU , and clipping_value is not NULL or 0 , clipping is performed against the intermediate result where z = min(intermediate_result, clipping_value). Finally the results are stored into the provided output zDNN tensor.","title":"Description"},{"location":"zDNN/#format_47","text":"zdnn_status zdnn_conv2d(const zdnn_ztensor *input, const zdnn_ztensor *kernel, const zdnn_ztensor *bias, zdnn_pool_padding padding_type, uint32_t stride_height, uint32_t stride_width, zdnn_conv2d_act act_func, const void *clipping_value, zdnn_ztensor *output);","title":"Format"},{"location":"zDNN/#parameters_45","text":"zdnn_ztensor *input Tensor with original values to be downsampled in the output tensor. Must be a ZDNN_NHWC tensor with pre_transformed shape [num_batches, height_in, width_in, channels_in]. See Convolution 2D Requirements for requirements. Must follow general tensor requirements zdnn_ztensor *kernel The kernel tensor to convolute with the input tensor. Must be a ZDNN_HWCK tensor with pre_transformed shape [kernel_height, kernel_width, channels_in, channels_out]. See Convolution 2D Requirements for requirements. Must follow general tensor requirements zdnn_ztensor *bias The bias tensor to add to the convoluted results. Must be a ZDNN_1D tensor with pre_transformed shape [channels_out]. See Convolution 2D Requirements for requirements. Must follow general tensor requirements zdnn_pool_padding padding_type The type of padding to use for the pooling operations. Valid values: are SAME_PADDING or VALID_PADDING . For information on \"same\" vs \"valid\" padding see: https://www.pico.net/kb/what-is-the-difference-between-same-and-valid-padding-in-tf-nn-max-pool-of-tensorflow . uint32_t stride_height Number of positions the kernel moves over the input's dim3 dimension at each step. See Convolution 2D Requirements for requirements. uint32_t stride_width Number of positions the kernel moves over the input's dim2 dimension at each step. See Convolution 2D Requirements for requirements. zdnn_conv2d_act act_func Activation function to apply to the results. CONV2D_ACT_NONE or CONV2D_ACT_RELU void *clipping_value A pointer to an FP32 value, used to clip input tensor's elements. If set to NULL or 0, no clipping will occur. Must not be a negative value. Value is ignored if act_func is not set to CONV2D_ACT_RELU . zdnn_ztensor *output The result tensor which will hold the results. Must be a ZDNN_NHWC tensor with pre_transformed shape [num_batches, height_out, width_out, channels_out]. See Convolution 2D Requirements for requirements. Must follow general tensor requirements","title":"Parameters"},{"location":"zDNN/#convolution-2d-requirements","text":"strides and padding input (num_batches, height_in, width_in, channels_in) kernel (kernel_height, kernel_width, channels_in, channels_out) bias (channels_out) output (num_batches, height_out, width_out, channels_out) both strides > 0 and =< 13, SAME padding both kernel_height and kernel_width must be =< 64 height_out = ceil(kernel_height/stride_height) width_out = ceil(kernel_width/stride_width) both strides > 0 and =< 13, VALID padding height_in must be > kernel_height width_in must be > kernel_width both kernel_height and kernel_width must be =< 64 height_out = ceil((height_in - kernel_height + 1)/stride_height) width_out = ceil((width_in - kernel_width + 1)/stride_width) both strides = 0, VALID padding height_in must be = kernel_height width_in must be = kernel_width both kernel_height and kernel_width must be =< 448 both height_out and width_out must be 1","title":"Convolution 2D Requirements"},{"location":"zDNN/#returns-see-zdnn-statuses-for-descriptions_19","text":"ZDNN_OK warning statuses ZDNN_INVALID_SHAPE Shape of input or output tensor is invalid based on given kernel and stride parameters Other general shape violations (exceeds MDIS, etc.) ZDNN_INVALID_TYPE ZDNN_INVALID_FORMAT ZDNN_INVALID_STRIDE_PADDING ZDNN_INVALID_STRIDES ZDNN_INVALID_CLIPPING_VALUE hardware statuses ZDNN_FUNC_RC_F000 - Invalid padding_type ZDNN_FUNC_RC_F001 - Invalid act_func ZDNN_FUNC_RC_F002 - stride_height = 0 and stride_width = 0, but either kernel_height or kernel_width > 448 ZDNN_FUNC_RC_F003 - stride_height > 0 and stride_width > 0, but either kernel_height or kernel_width > 64 ZDNN_FUNC_RC_F004 - Either stride_height or stride_width > 13","title":"Returns (see zDNN Statuses for descriptions)"},{"location":"zDNN/#framework-examples_20","text":"TensorFlow Conv2D ONNX Conv2D","title":"Framework Examples"},{"location":"zDNN/#convenience-functions","text":"Back to Table of Contents None","title":"Convenience Functions"},{"location":"zDNN/#usage-examples","text":"","title":"Usage Examples"},{"location":"zDNN/#example-flow-of-an-application-calling-the-zdnn-apis","text":"Back to Table of Contents #include <assert.h> #include <stdint.h> #include <stdio.h> #include <stdlib.h> #include <string.h> #include \"zdnn.h\" // *************************************************************************** // Sample: // // Create 2 zTensors a and b, and add them together via zdnn_add() // *************************************************************************** int main(int argc, char *argv[]) { zdnn_tensor_desc pre_tfrmd_desc, tfrmd_desc; zdnn_ztensor ztensor_a; zdnn_ztensor ztensor_b; zdnn_ztensor ztensor_out; zdnn_status status; uint32_t dim_n = 1, dim_h = 32, dim_w = 32, dim_c = 3; zdnn_data_types type = FP32; short element_size = 4; // size of each element in bytes uint64_t num_elements = dim_n * dim_h * dim_w * dim_c; // allocate tensor data storage void *data1 = malloc(num_elements * element_size); void *data2 = malloc(num_elements * element_size); void *data_out = malloc(num_elements * element_size); // read input_data // check status for AIU availability, supported ops, etc. here // status = zdnn_query(\u2026); // set input tensor data to 0 to 127 sequentially and repeat for (uint64_t i = 0; i < num_elements; i++) { ((float *)data1)[i] = (float)(i & 0x7f); ((float *)data2)[i] = (float)(i & 0x7f); } zdnn_init_pre_transformed_desc(ZDNN_NHWC, type, &pre_tfrmd_desc, dim_n, dim_h, dim_w, dim_c); // generate transformed shape information status = zdnn_generate_transformed_desc(&pre_tfrmd_desc, &tfrmd_desc); assert(status == ZDNN_OK); // initialize zTensors and allocate 4k-aligned storage via helper function status = zdnn_init_ztensor_with_malloc(&pre_tfrmd_desc, &tfrmd_desc, &ztensor_a); assert(status == ZDNN_OK); status = zdnn_init_ztensor_with_malloc(&pre_tfrmd_desc, &tfrmd_desc, &ztensor_b); assert(status == ZDNN_OK); status = zdnn_init_ztensor_with_malloc(&pre_tfrmd_desc, &tfrmd_desc, &ztensor_out); assert(status == ZDNN_OK); // transform the feature tensor status = zdnn_transform_ztensor(&ztensor_a, data1); assert(status == ZDNN_OK); status = zdnn_transform_ztensor(&ztensor_b, data2); assert(status == ZDNN_OK); // perform element-wise add between the two input tensors status = zdnn_add(&ztensor_a, &ztensor_b, &ztensor_out); assert(status == ZDNN_OK); // transform resultant zTensor back to original data format status = zdnn_transform_origtensor(&ztensor_out, data_out); assert(status == ZDNN_OK); for (uint64_t i = 0; i < num_elements; i++) { printf(\"out element %\" PRIu64 \" %f\\n\", i, ((float *)data_out)[i]); } free(data1); free(data2); free(data_out); }","title":"Example flow of an application calling the zDNN APIs"},{"location":"zDNN/#example-of-an-application-calling-the-zdnn_lstm-api-forward","text":"Back to Table of Contents // SPDX-License-Identifier: Apache-2.0 /* * Copyright IBM Corp. 2021 * * Licensed under the Apache License, Version 2.0 (the \"License\"); * you may not use this file except in compliance with the License. * You may obtain a copy of the License at * * http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an \"AS IS\" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ #include <assert.h> #include <stdio.h> #include <stdlib.h> #include <string.h> #include \"zdnn.h\" // Sample: LSTM int main(int argc, char *argv[]) { zdnn_status status; #ifdef STATIC_LIB zdnn_init(); #endif /*********************************************************************** * * LSTM (FWD/BWD): * * INPUTS -------------------------------------------------------------- * input | ZDNN_3DS | (num_timesteps, num_batches, num_features) * h0 | ZDNN_3DS | (1, num_batches, num_hidden) * c0 | ZDNN_3DS | (1, num_batches, num_hidden) * weights | ZDNN_3DS | (1, num_features, num_hidden) * biases | ZDNN_2DS | (1, num_hidden) * hidden_weights | ZDNN_3DS | (1, num_hidden, num_hidden) * hidden_biases | ZDNN_2DS | (1, num_hidden) * * OUTPUTS ------------------------------------------------------------- * hn_output | ZDNN_4DS | (num_timesteps, 1, num_batches, num_hidden) * | | or (1, 1, num_batches, num_hidden) * cf_output | ZDNN_4DS | (1, 1, num_batches, num_hidden) ***********************************************************************/ /*********************************************************************** * Create input zTensor ***********************************************************************/ zdnn_tensor_desc input_pre_tfrmd_desc, input_tfrmd_desc; zdnn_ztensor input; uint32_t num_timesteps = 5; uint32_t num_batches = 3; uint32_t num_features = 32; uint32_t num_hidden = 5; zdnn_data_types type = FP32; short element_size = 4; // size of each element in bytes lstm_gru_direction dir = FWD; uint8_t num_dirs = 1; zdnn_init_pre_transformed_desc(ZDNN_3DS, type, &input_pre_tfrmd_desc, num_timesteps, num_batches, num_features); status = zdnn_generate_transformed_desc(&input_pre_tfrmd_desc, &input_tfrmd_desc); assert(status == ZDNN_OK); status = zdnn_init_ztensor_with_malloc(&input_pre_tfrmd_desc, &input_tfrmd_desc, &input); assert(status == ZDNN_OK); uint64_t input_data_size = num_timesteps * num_batches * num_features * element_size; void *input_data = malloc(input_data_size); status = zdnn_transform_ztensor(&input, input_data); assert(status == ZDNN_OK); /*********************************************************************** * Create initial hidden and cell state zTensors ***********************************************************************/ zdnn_tensor_desc h0c0_pre_tfrmd_desc, h0c0_tfrmd_desc; zdnn_ztensor h0, c0; zdnn_init_pre_transformed_desc(ZDNN_3DS, type, &h0c0_pre_tfrmd_desc, num_dirs, num_batches, num_hidden); status = zdnn_generate_transformed_desc(&h0c0_pre_tfrmd_desc, &h0c0_tfrmd_desc); assert(status == ZDNN_OK); status = zdnn_init_ztensor_with_malloc(&h0c0_pre_tfrmd_desc, &h0c0_tfrmd_desc, &h0); assert(status == ZDNN_OK); status = zdnn_init_ztensor_with_malloc(&h0c0_pre_tfrmd_desc, &h0c0_tfrmd_desc, &c0); assert(status == ZDNN_OK); uint64_t h0c0_data_size = num_batches * num_hidden * element_size; void *hidden_state_data = malloc(h0c0_data_size); void *cell_state_data = malloc(h0c0_data_size); status = zdnn_transform_ztensor(&h0, hidden_state_data); assert(status == ZDNN_OK); status = zdnn_transform_ztensor(&c0, cell_state_data); assert(status == ZDNN_OK); /*********************************************************************** * Create input weights zTensor * Resultant zTensor is concatenated ***********************************************************************/ zdnn_tensor_desc weights_pre_tfrmd_desc, weights_tfrmd_desc; zdnn_ztensor weights; zdnn_init_pre_transformed_desc(ZDNN_3DS, type, &weights_pre_tfrmd_desc, num_dirs, num_features, num_hidden); status = zdnn_generate_transformed_desc_concatenated( &weights_pre_tfrmd_desc, RNN_TYPE_LSTM | USAGE_WEIGHTS | PREV_LAYER_NONE, &weights_tfrmd_desc); assert(status == ZDNN_OK); status = zdnn_init_ztensor_with_malloc(&weights_pre_tfrmd_desc, &weights_tfrmd_desc, &weights); assert(status == ZDNN_OK); uint64_t weights_data_size = num_features * num_hidden * element_size; void *weights_data_f = malloc(weights_data_size); void *weights_data_i = malloc(weights_data_size); void *weights_data_c = malloc(weights_data_size); void *weights_data_o = malloc(weights_data_size); status = zdnn_transform_ztensor(&weights, weights_data_f, weights_data_i, weights_data_c, weights_data_o); assert(status == ZDNN_OK); /*********************************************************************** * Create biases zTensors * Resultant zTensors are concatenated ***********************************************************************/ zdnn_tensor_desc biases_pre_tfrmd_desc, biases_tfrmd_desc; zdnn_ztensor biases; zdnn_init_pre_transformed_desc(ZDNN_2DS, type, &biases_pre_tfrmd_desc, num_dirs, num_hidden); status = zdnn_generate_transformed_desc_concatenated( &biases_pre_tfrmd_desc, RNN_TYPE_LSTM | USAGE_BIASES | PREV_LAYER_NONE, &biases_tfrmd_desc); assert(status == ZDNN_OK); status = zdnn_init_ztensor_with_malloc(&biases_pre_tfrmd_desc, &biases_tfrmd_desc, &biases); assert(status == ZDNN_OK); uint64_t biases_data_size = num_hidden * element_size; void *biases_data_f = malloc(biases_data_size); void *biases_data_i = malloc(biases_data_size); void *biases_data_c = malloc(biases_data_size); void *biases_data_o = malloc(biases_data_size); status = zdnn_transform_ztensor(&biases, biases_data_f, biases_data_i, biases_data_c, biases_data_o); assert(status == ZDNN_OK); /*********************************************************************** * Create hidden weights zTensor * Resultant zTensor is concatenated ***********************************************************************/ zdnn_tensor_desc hidden_weights_pre_tfrmd_desc, hidden_weights_tfrmd_desc; zdnn_ztensor hidden_weights; zdnn_init_pre_transformed_desc(ZDNN_3DS, type, &hidden_weights_pre_tfrmd_desc, num_dirs, num_hidden, num_hidden); status = zdnn_generate_transformed_desc_concatenated( &hidden_weights_pre_tfrmd_desc, RNN_TYPE_LSTM | USAGE_HIDDEN_WEIGHTS | PREV_LAYER_NONE, &hidden_weights_tfrmd_desc); assert(status == ZDNN_OK); status = zdnn_init_ztensor_with_malloc(&hidden_weights_pre_tfrmd_desc, &hidden_weights_tfrmd_desc, &hidden_weights); assert(status == ZDNN_OK); uint64_t hidden_weights_data_size = num_hidden * num_hidden * element_size; void *hidden_weights_data_f = malloc(hidden_weights_data_size); void *hidden_weights_data_i = malloc(hidden_weights_data_size); void *hidden_weights_data_c = malloc(hidden_weights_data_size); void *hidden_weights_data_o = malloc(hidden_weights_data_size); status = zdnn_transform_ztensor(&hidden_weights, hidden_weights_data_f, hidden_weights_data_i, hidden_weights_data_c, hidden_weights_data_o); assert(status == ZDNN_OK); /*********************************************************************** * Create hidden biases zTensors * Resultant zTensors are concatenated ***********************************************************************/ zdnn_tensor_desc hidden_biases_pre_tfrmd_desc, hidden_biases_tfrmd_desc; zdnn_ztensor hidden_biases; zdnn_init_pre_transformed_desc(ZDNN_2DS, type, &hidden_biases_pre_tfrmd_desc, num_dirs, num_hidden); status = zdnn_generate_transformed_desc_concatenated( &hidden_biases_pre_tfrmd_desc, RNN_TYPE_LSTM | USAGE_HIDDEN_BIASES | PREV_LAYER_NONE, &hidden_biases_tfrmd_desc); assert(status == ZDNN_OK); status = zdnn_init_ztensor_with_malloc( &hidden_biases_pre_tfrmd_desc, &hidden_biases_tfrmd_desc, &hidden_biases); assert(status == ZDNN_OK); uint64_t hidden_biases_data_size = num_hidden * element_size; void *hidden_biases_data_f = malloc(hidden_biases_data_size); void *hidden_biases_data_i = malloc(hidden_biases_data_size); void *hidden_biases_data_c = malloc(hidden_biases_data_size); void *hidden_biases_data_o = malloc(hidden_biases_data_size); status = zdnn_transform_ztensor(&hidden_biases, hidden_biases_data_f, hidden_biases_data_i, hidden_biases_data_c, hidden_biases_data_o); assert(status == ZDNN_OK); /*********************************************************************** * Create output zTensor ***********************************************************************/ // get only the last timestep, thus hn and cf can share descriptor zdnn_tensor_desc hncf_pre_tfrmd_desc, hncf_tfrmd_desc; zdnn_ztensor hn_output_ztensor, cf_output_ztensor; zdnn_init_pre_transformed_desc(ZDNN_4DS, type, &hncf_pre_tfrmd_desc, 1, 1, num_batches, num_hidden); status = zdnn_generate_transformed_desc(&hncf_pre_tfrmd_desc, &hncf_tfrmd_desc); assert(status == ZDNN_OK); status = zdnn_init_ztensor_with_malloc(&hncf_pre_tfrmd_desc, &hncf_tfrmd_desc, &hn_output_ztensor); assert(status == ZDNN_OK); status = zdnn_init_ztensor_with_malloc(&hncf_pre_tfrmd_desc, &hncf_tfrmd_desc, &cf_output_ztensor); assert(status == ZDNN_OK); /*********************************************************************** * Call the AIU ***********************************************************************/ void *work_area = NULL; status = zdnn_lstm(&input, &h0, &c0, &weights, &biases, &hidden_weights, &hidden_biases, dir, work_area, &hn_output_ztensor, &cf_output_ztensor); assert(status == ZDNN_OK); /*********************************************************************** * Output and Cleanup ***********************************************************************/ uint64_t hncf_data_size = num_batches * num_hidden * element_size; void *hn_output_data = malloc(hncf_data_size); void *cf_output_data = malloc(hncf_data_size); status = zdnn_transform_origtensor(&hn_output_ztensor, hn_output_data); assert(status == ZDNN_OK); status = zdnn_transform_origtensor(&cf_output_ztensor, cf_output_data); assert(status == ZDNN_OK); status = zdnn_free_ztensor_buffer(&input); assert(status == ZDNN_OK); status = zdnn_free_ztensor_buffer(&h0); assert(status == ZDNN_OK); status = zdnn_free_ztensor_buffer(&c0); assert(status == ZDNN_OK); status = zdnn_free_ztensor_buffer(&weights); assert(status == ZDNN_OK); status = zdnn_free_ztensor_buffer(&biases); assert(status == ZDNN_OK); status = zdnn_free_ztensor_buffer(&hidden_weights); assert(status == ZDNN_OK); status = zdnn_free_ztensor_buffer(&hidden_biases); assert(status == ZDNN_OK); status = zdnn_free_ztensor_buffer(&hn_output_ztensor); assert(status == ZDNN_OK); status = zdnn_free_ztensor_buffer(&cf_output_ztensor); assert(status == ZDNN_OK); free(input_data); free(hidden_state_data); free(cell_state_data); free(weights_data_f); free(weights_data_i); free(weights_data_c); free(weights_data_o); free(hidden_weights_data_f); free(hidden_weights_data_i); free(hidden_weights_data_c); free(hidden_weights_data_o); free(biases_data_f); free(biases_data_i); free(biases_data_c); free(biases_data_o); free(hidden_biases_data_f); free(hidden_biases_data_i); free(hidden_biases_data_c); free(hidden_biases_data_o); free(hn_output_data); free(cf_output_data); }","title":"Example of an application calling the zdnn_lstm API (forward)"},{"location":"zDNN/#example-of-an-application-calling-the-zdnn_lstm-api-bi-directional","text":"Back to Table of Contents // SPDX-License-Identifier: Apache-2.0 /* * Copyright IBM Corp. 2021 * * Licensed under the Apache License, Version 2.0 (the \"License\"); * you may not use this file except in compliance with the License. * You may obtain a copy of the License at * * http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an \"AS IS\" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ #include <assert.h> #include <stdio.h> #include <stdlib.h> #include <string.h> #include \"zdnn.h\" // Sample: LSTM BI-DIR int main(int argc, char *argv[]) { zdnn_status status; #ifdef STATIC_LIB zdnn_init(); #endif /*********************************************************************** * * LSTM (BI-DIR): * * INPUTS -------------------------------------------------------------- * input | ZDNN_3DS | (num_timesteps, num_batches, num_features) * h0 | ZDNN_3DS | (2, num_batches, num_hidden) * c0 | ZDNN_3DS | (2, num_batches, num_hidden) * weights | ZDNN_3DS | (2, num_features, num_hidden) * biases | ZDNN_2DS | (2, num_hidden) * hidden_weights | ZDNN_3DS | (2, num_hidden, num_hidden) * hidden_biases | ZDNN_2DS | (2, num_hidden) * * OUTPUTS ------------------------------------------------------------- * hn_output | ZDNN_4DS | (num_timesteps, 2, num_batches, num_hidden) * | | or (1, 2, num_batches, num_hidden) * cf_output | ZDNN_4DS | (1, 2, num_batches, num_hidden) ***********************************************************************/ /*********************************************************************** * Create input zTensor ***********************************************************************/ zdnn_tensor_desc input_pre_tfrmd_desc, input_tfrmd_desc; zdnn_ztensor input; uint32_t num_timesteps = 5; uint32_t num_batches = 3; uint32_t num_features = 32; uint32_t num_hidden = 5; zdnn_data_types type = FP32; short element_size = 4; // size of each element in bytes lstm_gru_direction dir = BIDIR; uint8_t num_dirs = 2; zdnn_init_pre_transformed_desc(ZDNN_3DS, type, &input_pre_tfrmd_desc, num_timesteps, num_batches, num_features); status = zdnn_generate_transformed_desc(&input_pre_tfrmd_desc, &input_tfrmd_desc); assert(status == ZDNN_OK); status = zdnn_init_ztensor_with_malloc(&input_pre_tfrmd_desc, &input_tfrmd_desc, &input); assert(status == ZDNN_OK); uint64_t input_data_size = num_timesteps * num_batches * num_features * element_size; void *input_data = malloc(input_data_size); status = zdnn_transform_ztensor(&input, input_data); assert(status == ZDNN_OK); /*********************************************************************** * Create initial hidden and cell state zTensors ***********************************************************************/ zdnn_tensor_desc h0c0_pre_tfrmd_desc, h0c0_tfrmd_desc; zdnn_ztensor h0, c0; zdnn_init_pre_transformed_desc(ZDNN_3DS, type, &h0c0_pre_tfrmd_desc, num_dirs, num_batches, num_hidden); status = zdnn_generate_transformed_desc(&h0c0_pre_tfrmd_desc, &h0c0_tfrmd_desc); assert(status == ZDNN_OK); status = zdnn_init_ztensor_with_malloc(&h0c0_pre_tfrmd_desc, &h0c0_tfrmd_desc, &h0); assert(status == ZDNN_OK); status = zdnn_init_ztensor_with_malloc(&h0c0_pre_tfrmd_desc, &h0c0_tfrmd_desc, &c0); assert(status == ZDNN_OK); uint64_t h0c0_data_size = num_batches * num_hidden * element_size; void *hidden_state_data = malloc(h0c0_data_size); void *cell_state_data = malloc(h0c0_data_size); status = zdnn_transform_ztensor(&h0, hidden_state_data); assert(status == ZDNN_OK); status = zdnn_transform_ztensor(&c0, cell_state_data); assert(status == ZDNN_OK); /*********************************************************************** * Create input weights zTensor * Resultant zTensor is concatenated ***********************************************************************/ zdnn_tensor_desc weights_pre_tfrmd_desc, weights_tfrmd_desc; zdnn_ztensor weights; zdnn_init_pre_transformed_desc(ZDNN_3DS, type, &weights_pre_tfrmd_desc, num_dirs, num_features, num_hidden); status = zdnn_generate_transformed_desc_concatenated( &weights_pre_tfrmd_desc, RNN_TYPE_LSTM | USAGE_WEIGHTS | PREV_LAYER_NONE, &weights_tfrmd_desc); assert(status == ZDNN_OK); status = zdnn_init_ztensor_with_malloc(&weights_pre_tfrmd_desc, &weights_tfrmd_desc, &weights); assert(status == ZDNN_OK); uint64_t weights_data_size = num_features * num_hidden * element_size; void *weights_data_f = malloc(weights_data_size); void *weights_data_i = malloc(weights_data_size); void *weights_data_c = malloc(weights_data_size); void *weights_data_o = malloc(weights_data_size); status = zdnn_transform_ztensor(&weights, weights_data_f, weights_data_i, weights_data_c, weights_data_o); assert(status == ZDNN_OK); /*********************************************************************** * Create biases zTensors * Resultant zTensors are concatenated ***********************************************************************/ zdnn_tensor_desc biases_pre_tfrmd_desc, biases_tfrmd_desc; zdnn_ztensor biases; zdnn_init_pre_transformed_desc(ZDNN_2DS, type, &biases_pre_tfrmd_desc, num_dirs, num_hidden); status = zdnn_generate_transformed_desc_concatenated( &biases_pre_tfrmd_desc, RNN_TYPE_LSTM | USAGE_BIASES | PREV_LAYER_NONE, &biases_tfrmd_desc); assert(status == ZDNN_OK); status = zdnn_init_ztensor_with_malloc(&biases_pre_tfrmd_desc, &biases_tfrmd_desc, &biases); assert(status == ZDNN_OK); uint64_t biases_data_size = num_hidden * element_size; void *biases_data_f = malloc(biases_data_size); void *biases_data_i = malloc(biases_data_size); void *biases_data_c = malloc(biases_data_size); void *biases_data_o = malloc(biases_data_size); status = zdnn_transform_ztensor(&biases, biases_data_f, biases_data_i, biases_data_c, biases_data_o); assert(status == ZDNN_OK); /*********************************************************************** * Create hidden weights zTensor * Resultant zTensor is concatenated ***********************************************************************/ zdnn_tensor_desc hidden_weights_pre_tfrmd_desc, hidden_weights_tfrmd_desc; zdnn_ztensor hidden_weights; zdnn_init_pre_transformed_desc(ZDNN_3DS, type, &hidden_weights_pre_tfrmd_desc, num_dirs, num_hidden, num_hidden); status = zdnn_generate_transformed_desc_concatenated( &hidden_weights_pre_tfrmd_desc, RNN_TYPE_LSTM | USAGE_HIDDEN_WEIGHTS | PREV_LAYER_NONE, &hidden_weights_tfrmd_desc); assert(status == ZDNN_OK); status = zdnn_init_ztensor_with_malloc(&hidden_weights_pre_tfrmd_desc, &hidden_weights_tfrmd_desc, &hidden_weights); assert(status == ZDNN_OK); uint64_t hidden_weights_data_size = num_hidden * num_hidden * element_size; void *hidden_weights_data_f = malloc(hidden_weights_data_size); void *hidden_weights_data_i = malloc(hidden_weights_data_size); void *hidden_weights_data_c = malloc(hidden_weights_data_size); void *hidden_weights_data_o = malloc(hidden_weights_data_size); status = zdnn_transform_ztensor(&hidden_weights, hidden_weights_data_f, hidden_weights_data_i, hidden_weights_data_c, hidden_weights_data_o); assert(status == ZDNN_OK); /*********************************************************************** * Create hidden biases zTensors * Resultant zTensors are concatenated ***********************************************************************/ zdnn_tensor_desc hidden_biases_pre_tfrmd_desc, hidden_biases_tfrmd_desc; zdnn_ztensor hidden_biases; zdnn_init_pre_transformed_desc(ZDNN_2DS, type, &hidden_biases_pre_tfrmd_desc, num_dirs, num_hidden); status = zdnn_generate_transformed_desc_concatenated( &hidden_biases_pre_tfrmd_desc, RNN_TYPE_LSTM | USAGE_HIDDEN_BIASES | PREV_LAYER_NONE, &hidden_biases_tfrmd_desc); assert(status == ZDNN_OK); status = zdnn_init_ztensor_with_malloc( &hidden_biases_pre_tfrmd_desc, &hidden_biases_tfrmd_desc, &hidden_biases); assert(status == ZDNN_OK); uint64_t hidden_biases_data_size = num_hidden * element_size; void *hidden_biases_data_f = malloc(hidden_biases_data_size); void *hidden_biases_data_i = malloc(hidden_biases_data_size); void *hidden_biases_data_c = malloc(hidden_biases_data_size); void *hidden_biases_data_o = malloc(hidden_biases_data_size); status = zdnn_transform_ztensor(&hidden_biases, hidden_biases_data_f, hidden_biases_data_i, hidden_biases_data_c, hidden_biases_data_o); assert(status == ZDNN_OK); /*********************************************************************** * Create output zTensor ***********************************************************************/ zdnn_tensor_desc hn_pre_tfrmd_desc, hn_tfrmd_desc, cf_pre_tfrmd_desc, cf_tfrmd_desc; zdnn_ztensor hn_output_ztensor, cf_output_ztensor; zdnn_init_pre_transformed_desc(ZDNN_4DS, type, &hn_pre_tfrmd_desc, num_timesteps, 2, num_batches, num_hidden); status = zdnn_generate_transformed_desc(&hn_pre_tfrmd_desc, &hn_tfrmd_desc); assert(status == ZDNN_OK); zdnn_init_pre_transformed_desc(ZDNN_3DS, type, &cf_pre_tfrmd_desc, 1, 2, num_batches, num_hidden); status = zdnn_generate_transformed_desc(&cf_pre_tfrmd_desc, &cf_tfrmd_desc); assert(status == ZDNN_OK); status = zdnn_init_ztensor_with_malloc(&hn_pre_tfrmd_desc, &hn_tfrmd_desc, &hn_output_ztensor); assert(status == ZDNN_OK); status = zdnn_init_ztensor_with_malloc(&cf_pre_tfrmd_desc, &cf_tfrmd_desc, &cf_output_ztensor); assert(status == ZDNN_OK); /*********************************************************************** * Call the AIU ***********************************************************************/ void *work_area = NULL; status = zdnn_lstm(&input, &h0, &c0, &weights, &biases, &hidden_weights, &hidden_biases, dir, work_area, &hn_output_ztensor, &cf_output_ztensor); assert(status == ZDNN_OK); /*********************************************************************** * Output and Cleanup ***********************************************************************/ uint64_t hn_data_size = num_timesteps * 2 * num_batches * num_hidden * element_size; uint64_t cf_data_size = 2 * num_batches * num_hidden * element_size; void *hn_output_data = malloc(hn_data_size); void *cf_output_data = malloc(cf_data_size); status = zdnn_transform_origtensor(&hn_output_ztensor, hn_output_data); assert(status == ZDNN_OK); status = zdnn_transform_origtensor(&cf_output_ztensor, cf_output_data); assert(status == ZDNN_OK); status = zdnn_free_ztensor_buffer(&input); assert(status == ZDNN_OK); status = zdnn_free_ztensor_buffer(&h0); assert(status == ZDNN_OK); status = zdnn_free_ztensor_buffer(&c0); assert(status == ZDNN_OK); status = zdnn_free_ztensor_buffer(&weights); assert(status == ZDNN_OK); status = zdnn_free_ztensor_buffer(&biases); assert(status == ZDNN_OK); status = zdnn_free_ztensor_buffer(&hidden_weights); assert(status == ZDNN_OK); status = zdnn_free_ztensor_buffer(&hidden_biases); assert(status == ZDNN_OK); status = zdnn_free_ztensor_buffer(&hn_output_ztensor); assert(status == ZDNN_OK); status = zdnn_free_ztensor_buffer(&cf_output_ztensor); assert(status == ZDNN_OK); free(input_data); free(hidden_state_data); free(cell_state_data); free(weights_data_f); free(weights_data_i); free(weights_data_c); free(weights_data_o); free(hidden_weights_data_f); free(hidden_weights_data_i); free(hidden_weights_data_c); free(hidden_weights_data_o); free(biases_data_f); free(biases_data_i); free(biases_data_c); free(biases_data_o); free(hidden_biases_data_f); free(hidden_biases_data_i); free(hidden_biases_data_c); free(hidden_biases_data_o); free(hn_output_data); free(cf_output_data); }","title":"Example of an application calling the zdnn_lstm API (bi-directional)"},{"location":"zDNN/#example-of-an-application-calling-the-zdnn_lstm-api-multi-layer-bi-directional","text":"Back to Table of Contents // SPDX-License-Identifier: Apache-2.0 /* * Copyright IBM Corp. 2021 * * Licensed under the Apache License, Version 2.0 (the \"License\"); * you may not use this file except in compliance with the License. * You may obtain a copy of the License at * * http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an \"AS IS\" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ #include <assert.h> #include <stdio.h> #include <stdlib.h> #include <string.h> #include \"zdnn.h\" void do_bidir_layer(zdnn_ztensor *input, uint32_t num_hidden, zdnn_ztensor *hn_output, bool is_prev_layer_bidir) { zdnn_status status; uint32_t num_batches = input->pre_transformed_desc->dim2; // if input is bidir output from previous layer then number of features for // this layer is 2x of hidden-state size (dim1) of the previous layer uint32_t num_features = input->pre_transformed_desc->dim1 * (is_prev_layer_bidir ? 2 : 1); zdnn_data_types type = FP32; short element_size = 4; // size of each element in bytes lstm_gru_direction dir = BIDIR; uint8_t num_dirs = 2; /*********************************************************************** * Create initial hidden and cell state zTensors ***********************************************************************/ zdnn_tensor_desc h0c0_pre_tfrmd_desc, h0c0_tfrmd_desc; zdnn_ztensor h0, c0; zdnn_init_pre_transformed_desc(ZDNN_3DS, type, &h0c0_pre_tfrmd_desc, num_dirs, num_batches, num_hidden); status = zdnn_generate_transformed_desc(&h0c0_pre_tfrmd_desc, &h0c0_tfrmd_desc); assert(status == ZDNN_OK); status = zdnn_init_ztensor_with_malloc(&h0c0_pre_tfrmd_desc, &h0c0_tfrmd_desc, &h0); assert(status == ZDNN_OK); status = zdnn_init_ztensor_with_malloc(&h0c0_pre_tfrmd_desc, &h0c0_tfrmd_desc, &c0); assert(status == ZDNN_OK); uint64_t h0c0_data_size = num_batches * num_hidden * element_size; void *hidden_state_data = malloc(h0c0_data_size); void *cell_state_data = malloc(h0c0_data_size); status = zdnn_transform_ztensor(&h0, hidden_state_data); assert(status == ZDNN_OK); status = zdnn_transform_ztensor(&c0, cell_state_data); assert(status == ZDNN_OK); /*********************************************************************** * Create input weights zTensor * Resultant zTensor is concatenated ***********************************************************************/ zdnn_tensor_desc weights_pre_tfrmd_desc, weights_tfrmd_desc; zdnn_ztensor weights; // if using previous layer bidir output as input then number of features of // this layer is zdnn_init_pre_transformed_desc(ZDNN_3DS, type, &weights_pre_tfrmd_desc, num_dirs, num_features, num_hidden); status = zdnn_generate_transformed_desc_concatenated( &weights_pre_tfrmd_desc, RNN_TYPE_LSTM | USAGE_WEIGHTS | (is_prev_layer_bidir ? PREV_LAYER_BIDIR : PREV_LAYER_UNI), &weights_tfrmd_desc); assert(status == ZDNN_OK); status = zdnn_init_ztensor_with_malloc(&weights_pre_tfrmd_desc, &weights_tfrmd_desc, &weights); assert(status == ZDNN_OK); uint64_t weights_data_size = num_features * num_hidden * element_size; void *weights_data_f = malloc(weights_data_size); void *weights_data_i = malloc(weights_data_size); void *weights_data_c = malloc(weights_data_size); void *weights_data_o = malloc(weights_data_size); status = zdnn_transform_ztensor(&weights, weights_data_f, weights_data_i, weights_data_c, weights_data_o); assert(status == ZDNN_OK); /*********************************************************************** * Create biases zTensors * Resultant zTensors are concatenated ***********************************************************************/ zdnn_tensor_desc biases_pre_tfrmd_desc, biases_tfrmd_desc; zdnn_ztensor biases; zdnn_init_pre_transformed_desc(ZDNN_2DS, type, &biases_pre_tfrmd_desc, num_dirs, num_hidden); status = zdnn_generate_transformed_desc_concatenated( &biases_pre_tfrmd_desc, RNN_TYPE_LSTM | USAGE_BIASES | (is_prev_layer_bidir ? PREV_LAYER_BIDIR : PREV_LAYER_UNI), &biases_tfrmd_desc); assert(status == ZDNN_OK); status = zdnn_init_ztensor_with_malloc(&biases_pre_tfrmd_desc, &biases_tfrmd_desc, &biases); assert(status == ZDNN_OK); uint64_t biases_data_size = num_hidden * element_size; void *biases_data_f = malloc(biases_data_size); void *biases_data_i = malloc(biases_data_size); void *biases_data_c = malloc(biases_data_size); void *biases_data_o = malloc(biases_data_size); status = zdnn_transform_ztensor(&biases, biases_data_f, biases_data_i, biases_data_c, biases_data_o); assert(status == ZDNN_OK); /*********************************************************************** * Create hidden weights zTensor * Resultant zTensor is concatenated ***********************************************************************/ zdnn_tensor_desc hidden_weights_pre_tfrmd_desc, hidden_weights_tfrmd_desc; zdnn_ztensor hidden_weights; zdnn_init_pre_transformed_desc(ZDNN_3DS, type, &hidden_weights_pre_tfrmd_desc, num_dirs, num_hidden, num_hidden); status = zdnn_generate_transformed_desc_concatenated( &hidden_weights_pre_tfrmd_desc, RNN_TYPE_LSTM | USAGE_HIDDEN_WEIGHTS | (is_prev_layer_bidir ? PREV_LAYER_BIDIR : PREV_LAYER_UNI), &hidden_weights_tfrmd_desc); assert(status == ZDNN_OK); status = zdnn_init_ztensor_with_malloc(&hidden_weights_pre_tfrmd_desc, &hidden_weights_tfrmd_desc, &hidden_weights); assert(status == ZDNN_OK); uint64_t hidden_weights_data_size = num_hidden * num_hidden * element_size; void *hidden_weights_data_f = malloc(hidden_weights_data_size); void *hidden_weights_data_i = malloc(hidden_weights_data_size); void *hidden_weights_data_c = malloc(hidden_weights_data_size); void *hidden_weights_data_o = malloc(hidden_weights_data_size); status = zdnn_transform_ztensor(&hidden_weights, hidden_weights_data_f, hidden_weights_data_i, hidden_weights_data_c, hidden_weights_data_o); assert(status == ZDNN_OK); /*********************************************************************** * Create hidden biases zTensors * Resultant zTensors are concatenated ***********************************************************************/ zdnn_tensor_desc hidden_biases_pre_tfrmd_desc, hidden_biases_tfrmd_desc; zdnn_ztensor hidden_biases; zdnn_init_pre_transformed_desc(ZDNN_2DS, type, &hidden_biases_pre_tfrmd_desc, num_dirs, num_hidden); status = zdnn_generate_transformed_desc_concatenated( &hidden_biases_pre_tfrmd_desc, RNN_TYPE_LSTM | USAGE_HIDDEN_BIASES | (is_prev_layer_bidir ? PREV_LAYER_BIDIR : PREV_LAYER_UNI), &hidden_biases_tfrmd_desc); assert(status == ZDNN_OK); status = zdnn_init_ztensor_with_malloc( &hidden_biases_pre_tfrmd_desc, &hidden_biases_tfrmd_desc, &hidden_biases); assert(status == ZDNN_OK); uint64_t hidden_biases_data_size = num_hidden * element_size; void *hidden_biases_data_f = malloc(hidden_biases_data_size); void *hidden_biases_data_i = malloc(hidden_biases_data_size); void *hidden_biases_data_c = malloc(hidden_biases_data_size); void *hidden_biases_data_o = malloc(hidden_biases_data_size); status = zdnn_transform_ztensor(&hidden_biases, hidden_biases_data_f, hidden_biases_data_i, hidden_biases_data_c, hidden_biases_data_o); assert(status == ZDNN_OK); /*********************************************************************** * Create cf output zTensor ***********************************************************************/ zdnn_tensor_desc cf_pre_tfrmd_desc, cf_tfrmd_desc; zdnn_ztensor cf_output_ztensor; zdnn_init_pre_transformed_desc(ZDNN_4DS, type, &cf_pre_tfrmd_desc, 1, 2, num_batches, num_hidden); status = zdnn_generate_transformed_desc(&cf_pre_tfrmd_desc, &cf_tfrmd_desc); assert(status == ZDNN_OK); status = zdnn_init_ztensor_with_malloc(&cf_pre_tfrmd_desc, &cf_tfrmd_desc, &cf_output_ztensor); assert(status == ZDNN_OK); /*********************************************************************** * Call the AIU ***********************************************************************/ void *work_area = NULL; status = zdnn_lstm(input, &h0, &c0, &weights, &biases, &hidden_weights, &hidden_biases, dir, work_area, hn_output, &cf_output_ztensor); assert(status == ZDNN_OK); /*********************************************************************** * Cleanup and Return ***********************************************************************/ status = zdnn_free_ztensor_buffer(&h0); assert(status == ZDNN_OK); status = zdnn_free_ztensor_buffer(&c0); assert(status == ZDNN_OK); status = zdnn_free_ztensor_buffer(&weights); assert(status == ZDNN_OK); status = zdnn_free_ztensor_buffer(&biases); assert(status == ZDNN_OK); status = zdnn_free_ztensor_buffer(&hidden_weights); assert(status == ZDNN_OK); status = zdnn_free_ztensor_buffer(&hidden_biases); assert(status == ZDNN_OK); status = zdnn_free_ztensor_buffer(&cf_output_ztensor); assert(status == ZDNN_OK); free(hidden_state_data); free(cell_state_data); free(weights_data_f); free(weights_data_i); free(weights_data_c); free(weights_data_o); free(hidden_weights_data_f); free(hidden_weights_data_i); free(hidden_weights_data_c); free(hidden_weights_data_o); free(biases_data_f); free(biases_data_i); free(biases_data_c); free(biases_data_o); free(hidden_biases_data_f); free(hidden_biases_data_i); free(hidden_biases_data_c); free(hidden_biases_data_o); } // Sample: LSTM multi-layer BIDIR int main(int argc, char *argv[]) { zdnn_status status; #ifdef STATIC_LIB zdnn_init(); #endif uint32_t num_hidden[2] = {5, 4}; /*********************************************************************** * Create input zTensor ***********************************************************************/ zdnn_tensor_desc input_pre_tfrmd_desc, input_tfrmd_desc; zdnn_ztensor input; uint32_t num_timesteps = 5; uint32_t num_batches = 3; uint32_t num_features = 32; zdnn_data_types type = FP32; short element_size = 4; // size of each element in bytes zdnn_init_pre_transformed_desc(ZDNN_3DS, type, &input_pre_tfrmd_desc, num_timesteps, num_batches, num_features); status = zdnn_generate_transformed_desc(&input_pre_tfrmd_desc, &input_tfrmd_desc); assert(status == ZDNN_OK); status = zdnn_init_ztensor_with_malloc(&input_pre_tfrmd_desc, &input_tfrmd_desc, &input); assert(status == ZDNN_OK); uint64_t input_data_size = num_timesteps * num_batches * num_features * element_size; void *input_data = malloc(input_data_size); status = zdnn_transform_ztensor(&input, input_data); assert(status == ZDNN_OK); /*********************************************************************** * Create 2 hn output zTensors ***********************************************************************/ zdnn_tensor_desc hn_pre_tfrmd_desc[2], hn_tfrmd_desc[2]; zdnn_ztensor hn_output[2]; for (int i = 0; i < 2; i++) { zdnn_init_pre_transformed_desc(ZDNN_4DS, type, &hn_pre_tfrmd_desc[i], num_timesteps, 2, num_batches, num_hidden[i]); status = zdnn_generate_transformed_desc(&hn_pre_tfrmd_desc[i], &hn_tfrmd_desc[i]); assert(status == ZDNN_OK); status = zdnn_init_ztensor_with_malloc(&hn_pre_tfrmd_desc[i], &hn_tfrmd_desc[i], &hn_output[i]); assert(status == ZDNN_OK); } /*********************************************************************** * Do the layers ***********************************************************************/ // call the first layer with input, previous layer bidir = false, output goes // to hn_output[0] do_bidir_layer(&input, num_hidden[0], &hn_output[0], false); // call the second layer with hn_output[0] from layer 1, previous layer bidir // = true, output goes to hn_output[1] do_bidir_layer(&hn_output[0], num_hidden[1], &hn_output[1], true); /*********************************************************************** * Output and Cleanup ***********************************************************************/ void *hn_output_data[2]; for (int i = 0; i < 2; i++) { uint64_t hn_output_data_size = (uint64_t)num_timesteps * num_batches * num_hidden[i] * 2 * element_size; hn_output_data[i] = malloc(hn_output_data_size); status = zdnn_transform_origtensor(&hn_output[i], hn_output_data[i]); assert(status == ZDNN_OK); } status = zdnn_free_ztensor_buffer(&input); assert(status == ZDNN_OK); status = zdnn_free_ztensor_buffer(&hn_output[0]); assert(status == ZDNN_OK); status = zdnn_free_ztensor_buffer(&hn_output[1]); assert(status == ZDNN_OK); free(input_data); free(hn_output_data[0]); free(hn_output_data[1]); }","title":"Example of an application calling the zdnn_lstm API (multi-layer bi-directional)"},{"location":"zDNN/#example-of-an-application-calling-the-zdnn_gru-api-forward","text":"Back to Table of Contents // SPDX-License-Identifier: Apache-2.0 /* * Copyright IBM Corp. 2021 * * Licensed under the Apache License, Version 2.0 (the \"License\"); * you may not use this file except in compliance with the License. * You may obtain a copy of the License at * * http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an \"AS IS\" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ #include <assert.h> #include <stdio.h> #include <stdlib.h> #include <string.h> #include \"zdnn.h\" // Sample: GRU int main(int argc, char *argv[]) { zdnn_status status; #ifdef STATIC_LIB zdnn_init(); #endif /*********************************************************************** * * GRU (FWD/BWD): * * INPUTS -------------------------------------------------------------- * input | ZDNN_3DS | (num_timesteps, num_batches, num_features) * h0 | ZDNN_3DS | (1, num_batches, num_hidden) * weights | ZDNN_3DS | (1, num_features, num_hidden) * input_biases | ZDNN_2DS | (1, num_hidden) * hidden_weights | ZDNN_3DS | (1, num_hidden, num_hidden) * hidden_biases | ZDNN_2DS | (1, num_hidden) * * OUTPUTS ------------------------------------------------------------- * hn_output | ZDNN_4DS | (num_timesteps, 1, num_batches, num_hidden) * | | or (1, 1, num_batches, num_hidden) ***********************************************************************/ /*********************************************************************** * Create input zTensor ***********************************************************************/ zdnn_tensor_desc input_pre_tfrmd_desc, input_tfrmd_desc; zdnn_ztensor input; uint32_t num_timesteps = 5; uint32_t num_batches = 3; uint32_t num_features = 32; uint32_t num_hidden = 5; zdnn_data_types type = FP32; short element_size = 4; // size of each element in bytes lstm_gru_direction dir = FWD; uint8_t num_dirs = 1; zdnn_init_pre_transformed_desc(ZDNN_3DS, type, &input_pre_tfrmd_desc, num_timesteps, num_batches, num_features); status = zdnn_generate_transformed_desc(&input_pre_tfrmd_desc, &input_tfrmd_desc); assert(status == ZDNN_OK); status = zdnn_init_ztensor_with_malloc(&input_pre_tfrmd_desc, &input_tfrmd_desc, &input); assert(status == ZDNN_OK); uint64_t input_data_size = num_timesteps * num_batches * num_features * element_size; void *input_data = malloc(input_data_size); status = zdnn_transform_ztensor(&input, input_data); assert(status == ZDNN_OK); /*********************************************************************** * Create initial hidden zTensor ***********************************************************************/ zdnn_tensor_desc h0_pre_tfrmd_desc, h0_tfrmd_desc; zdnn_ztensor h0; zdnn_init_pre_transformed_desc(ZDNN_3DS, type, &h0_pre_tfrmd_desc, num_dirs, num_batches, num_hidden); status = zdnn_generate_transformed_desc(&h0_pre_tfrmd_desc, &h0_tfrmd_desc); assert(status == ZDNN_OK); status = zdnn_init_ztensor_with_malloc(&h0_pre_tfrmd_desc, &h0_tfrmd_desc, &h0); assert(status == ZDNN_OK); uint64_t h0_data_size = num_batches * num_hidden * element_size; void *hidden_state_data = malloc(h0_data_size); status = zdnn_transform_ztensor(&h0, hidden_state_data); assert(status == ZDNN_OK); /*********************************************************************** * Create input weights zTensor * Resultant zTensor is concatenated ***********************************************************************/ zdnn_tensor_desc weights_pre_tfrmd_desc, weights_tfrmd_desc; zdnn_ztensor weights; zdnn_init_pre_transformed_desc(ZDNN_3DS, type, &weights_pre_tfrmd_desc, num_dirs, num_features, num_hidden); status = zdnn_generate_transformed_desc_concatenated( &weights_pre_tfrmd_desc, RNN_TYPE_GRU | USAGE_WEIGHTS | PREV_LAYER_NONE, &weights_tfrmd_desc); assert(status == ZDNN_OK); status = zdnn_init_ztensor_with_malloc(&weights_pre_tfrmd_desc, &weights_tfrmd_desc, &weights); assert(status == ZDNN_OK); uint64_t weights_data_size = num_features * num_hidden * element_size; void *weights_data_z = malloc(weights_data_size); void *weights_data_r = malloc(weights_data_size); void *weights_data_h = malloc(weights_data_size); status = zdnn_transform_ztensor(&weights, weights_data_z, weights_data_r, weights_data_h); assert(status == ZDNN_OK); /*********************************************************************** * Create biases zTensors * Resultant zTensors are concatenated ***********************************************************************/ zdnn_tensor_desc biases_pre_tfrmd_desc, biases_tfrmd_desc; zdnn_ztensor biases; zdnn_init_pre_transformed_desc(ZDNN_2DS, type, &biases_pre_tfrmd_desc, num_dirs, num_hidden); status = zdnn_generate_transformed_desc_concatenated( &biases_pre_tfrmd_desc, RNN_TYPE_GRU | USAGE_BIASES | PREV_LAYER_NONE, &biases_tfrmd_desc); assert(status == ZDNN_OK); status = zdnn_init_ztensor_with_malloc(&biases_pre_tfrmd_desc, &biases_tfrmd_desc, &biases); assert(status == ZDNN_OK); uint64_t biases_data_size = num_hidden * element_size; void *biases_data_z = malloc(biases_data_size); void *biases_data_r = malloc(biases_data_size); void *biases_data_h = malloc(biases_data_size); status = zdnn_transform_ztensor(&biases, biases_data_z, biases_data_r, biases_data_h); assert(status == ZDNN_OK); /*********************************************************************** * Create hidden weights zTensor * Resultant zTensor is concatenated ***********************************************************************/ zdnn_tensor_desc hidden_weights_pre_tfrmd_desc, hidden_weights_tfrmd_desc; zdnn_ztensor hidden_weights; zdnn_init_pre_transformed_desc(ZDNN_3DS, type, &hidden_weights_pre_tfrmd_desc, num_dirs, num_hidden, num_hidden); status = zdnn_generate_transformed_desc_concatenated( &hidden_weights_pre_tfrmd_desc, RNN_TYPE_GRU | USAGE_HIDDEN_WEIGHTS | PREV_LAYER_NONE, &hidden_weights_tfrmd_desc); assert(status == ZDNN_OK); status = zdnn_init_ztensor_with_malloc(&hidden_weights_pre_tfrmd_desc, &hidden_weights_tfrmd_desc, &hidden_weights); assert(status == ZDNN_OK); uint64_t hidden_weights_data_size = num_hidden * num_hidden * element_size; void *hidden_weights_data_z = malloc(hidden_weights_data_size); void *hidden_weights_data_r = malloc(hidden_weights_data_size); void *hidden_weights_data_h = malloc(hidden_weights_data_size); status = zdnn_transform_ztensor(&hidden_weights, hidden_weights_data_z, hidden_weights_data_r, hidden_weights_data_h); assert(status == ZDNN_OK); /*********************************************************************** * Create hidden biases zTensors * Resultant zTensors are concatenated ***********************************************************************/ zdnn_tensor_desc hidden_biases_pre_tfrmd_desc, hidden_biases_tfrmd_desc; zdnn_ztensor hidden_biases; zdnn_init_pre_transformed_desc(ZDNN_2DS, type, &hidden_biases_pre_tfrmd_desc, num_dirs, num_hidden); status = zdnn_generate_transformed_desc_concatenated( &hidden_biases_pre_tfrmd_desc, RNN_TYPE_GRU | USAGE_HIDDEN_BIASES | PREV_LAYER_NONE, &hidden_biases_tfrmd_desc); assert(status == ZDNN_OK); status = zdnn_init_ztensor_with_malloc( &hidden_biases_pre_tfrmd_desc, &hidden_biases_tfrmd_desc, &hidden_biases); assert(status == ZDNN_OK); uint64_t hidden_biases_data_size = num_hidden * element_size; void *hidden_biases_data_z = malloc(hidden_biases_data_size); void *hidden_biases_data_r = malloc(hidden_biases_data_size); void *hidden_biases_data_h = malloc(hidden_biases_data_size); status = zdnn_transform_ztensor(&hidden_biases, hidden_biases_data_z, hidden_biases_data_r, hidden_biases_data_h); assert(status == ZDNN_OK); /*********************************************************************** * Create output zTensor ***********************************************************************/ // get only the last timestep zdnn_tensor_desc hn_pre_tfrmd_desc, hn_tfrmd_desc; zdnn_ztensor hn_output_ztensor; zdnn_init_pre_transformed_desc(ZDNN_4DS, type, &hn_pre_tfrmd_desc, 1, 1, num_batches, num_hidden); status = zdnn_generate_transformed_desc(&hn_pre_tfrmd_desc, &hn_tfrmd_desc); assert(status == ZDNN_OK); status = zdnn_init_ztensor_with_malloc(&hn_pre_tfrmd_desc, &hn_tfrmd_desc, &hn_output_ztensor); assert(status == ZDNN_OK); /*********************************************************************** * Call the AIU ***********************************************************************/ void *work_area = NULL; status = zdnn_gru(&input, &h0, &weights, &biases, &hidden_weights, &hidden_biases, dir, work_area, &hn_output_ztensor); assert(status == ZDNN_OK); /*********************************************************************** * Output and Cleanup ***********************************************************************/ uint64_t hn_data_size = num_batches * num_hidden * element_size; void *hn_output_data = malloc(hn_data_size); status = zdnn_transform_origtensor(&hn_output_ztensor, hn_output_data); assert(status == ZDNN_OK); status = zdnn_free_ztensor_buffer(&input); assert(status == ZDNN_OK); status = zdnn_free_ztensor_buffer(&h0); assert(status == ZDNN_OK); status = zdnn_free_ztensor_buffer(&weights); assert(status == ZDNN_OK); status = zdnn_free_ztensor_buffer(&biases); assert(status == ZDNN_OK); status = zdnn_free_ztensor_buffer(&hidden_weights); assert(status == ZDNN_OK); status = zdnn_free_ztensor_buffer(&hidden_biases); assert(status == ZDNN_OK); status = zdnn_free_ztensor_buffer(&hn_output_ztensor); assert(status == ZDNN_OK); free(input_data); free(hidden_state_data); free(weights_data_z); free(weights_data_r); free(weights_data_h); free(hidden_weights_data_z); free(hidden_weights_data_r); free(hidden_weights_data_h); free(biases_data_z); free(biases_data_r); free(biases_data_h); free(hidden_biases_data_z); free(hidden_biases_data_r); free(hidden_biases_data_h); free(hn_output_data); }","title":"Example of an application calling the zdnn_gru API (forward)"},{"location":"zDNN/CONTRIBUTING/","text":"Contributing to zDNN \u00b6 License \u00b6 All contributions have to be submitted under the Apache 2.0 license. See also the LICENSE file. Developer's Certificate of Origin and Signed-off-by \u00b6 The sign-off is a simple line at the end of the explanation for the patch, which certifies that you wrote it or otherwise have the right to pass it on as an open-source patch. With the Signed-off-by line you certify the below: Developer's Certificate of Origin 1.1 By making a contribution to this project, I certify that: (a) The contribution was created in whole or in part by me and I have the right to submit it under the open source license indicated in the file; or (b) The contribution is based upon previous work that, to the best of my knowledge, is covered under an appropriate open source license and I have the right under that license to submit that work with modifications, whether created in whole or in part by me, under the same open source license (unless I am permitted to submit under a different license), as indicated in the file; or (c) The contribution was provided directly to me by some other person who certified (a), (b) or (c) and I have not modified it. (d) I understand and agree that this project and the contribution are public and that a record of the contribution (including all personal information I submit with it, including my sign-off) is maintained indefinitely and may be redistributed consistent with this project or the open source license(s) involved. If you can certify the above, just add a line stating the following at the bottom of each of your commit messages: Signed-off-by: Random Developer <random@developer.example.org> Please use your real name and a valid e-mail address (no pseudonyms or anonymous contributions). Submitting code \u00b6 The preferred way is to create GitHub pull requests for your code contributions. Please create separate pull requests for each logical enhancement, new feature, or fix. GitHub workflow for contributions \u00b6 In the examples below we use this fictive identity: Name: Random Developer E-mail: random@developer.example.org GitHub ID: random-developer Setup GitHub and local git \u00b6 Create a fork of this repository by clicking the Fork button on the top right of the zDNN main page Clone your forked repository to your local development system $ git clone https://github.com/random-developer/zDNN.git Configure a remote called \"upstream\" pointing to the official zDNN repository on GitHub $ cd zDNN ~/zDNN $ git remote add upstream https://github.com/IBM/zDNN.git Verify your remotes ~/zDNN $ git remote -v origin https://github.com/random-developer/zDNN.git (fetch) origin https://github.com/random-developer/zDNN.git (push) upstream https://github.com/IBM/zDNN.git (fetch) upstream https://github.com/IBM/zDNN.git (push) You now have two remotes: The \"origin\" remote points to your fork and the \"upstream\" remote to the official zDNN repository. Configure your git user name and e-mail ~/zDNN $ git config user.name \"Random Developer\" ~/zDNN $ git config user.email \"random@developer.example.com\" Create a pull request \u00b6 Create and checkout a new branch for your contribution ~/zDNN $ git checkout -b contrib-doc-pr Make your changes to the code ~/zDNN $ vim CONTRIBUTING.md Build and test your contribution, recommended on NNPA enabled machine. ~/zDNN $ make clean all Commit your changes ~/zDNN $ git add CONTRIBUTING.md ~/zDNN $ git commit -s Provide a meaningful commit message including your \"Signed-off-by\" line to each commit: CONTRIBUTING: Outline steps to submit code Explain in more detail how to submit zDNN contributions as GitHub pull requests. Signed-off-by: Random Developer <random@developer.example.com> Push the changes to your fork of the repository ~/zDNN $ git push origin contrib-doc-pr Go to the GitHub website of your zDNN fork and create a pull request for your branch \"contrib-doc-pr\" Update a pull request during review \u00b6 If there are changes requested during the review process, you have to update your code in the pull request. To retain the existing review comments, add commits on top of your pull request branch. Depending on the size and number of changes, a rebase of the pull request might be required. This will be communicated during the review. Update your code with new commits ~/zDNN $ vi CONTRIBUTING.md ~/zDNN $ git add CONTRIBUTING.md ~/zDNN $ git commit -s -m \"CONTRIBUTING: Add update PR info\" Update your pull request by pushing changes ~/zDNN $ git push origin contrib-doc-pr Finalize a pull request \u00b6 After the review process is finished or if you are explicitly asked for it, you have to create a clean commit series. Save branch to \"contrib-doc-pr.v1\" $ cd zDNN ~/zDNN $ git branch contrib-doc-pr.v1 Use interactive git rebase to merge commits, adjust commit messages, and rebase onto your local main branch ~/zDNN $ git rebase -i main An editor is started and shows the following: pick 2c73b9fc CONTRIBUTING: Outline steps to submit code pick fcfb0412 CONTRIBUTING: Add update PR info To merge the update into the original commit, replace \"pick fcfb0412\" with \"squash fcfb0412\". pick 2c73b9fc CONTRIBUTING: Outline steps to submit code squash fcfb0412 CONTRIBUTING: Add update PR info Save the document and exit the editor to finish the merge. Another editor window is presented to modify the commit message. You now could change the commit message as follows: CONTRIBUTING: Outline steps to submit code Explain in more detail how to submit zDNN contributions as GitHub pull requests and how to update already submitted pull requests. Signed-off-by: Random Developer <random@developer.example.com> With interactive rebasing you can also change the order of commits and modify commit messages with \"reword\". Use git push with the force option to replace the existing pull request with your locally modified commits ~/zDNN $ git push --force origin contrib-doc-pr Rebase a pull request \u00b6 If changes are made to the main branch in the official zDNN repository you may be asked to rebase your branch with your contribution onto it. This can be required to prevent any merge conflicts that might arise when integrating your contribution. Fetch all upstream changes from the official zDNN repository, rebase your local main branch and update the main branch on your fork ~/zDNN $ git fetch upstream ~/zDNN $ git checkout main ~/zDNN $ git rebase upstream/main ~/zDNN $ git push origin main Rebase your branch with your contribution onto the main branch of the official zDNN repository ~/zDNN $ git checkout contrib-doc-pr ~/zDNN $ git rebase main Use git push with the force option to replace the existing pull request with your locally modified commits ~/zDNN $ git push --force origin contrib-doc-pr","title":"CONTRIBUTING"},{"location":"zDNN/CONTRIBUTING/#contributing-to-zdnn","text":"","title":"Contributing to zDNN"},{"location":"zDNN/CONTRIBUTING/#license","text":"All contributions have to be submitted under the Apache 2.0 license. See also the LICENSE file.","title":"License"},{"location":"zDNN/CONTRIBUTING/#developers-certificate-of-origin-and-signed-off-by","text":"The sign-off is a simple line at the end of the explanation for the patch, which certifies that you wrote it or otherwise have the right to pass it on as an open-source patch. With the Signed-off-by line you certify the below: Developer's Certificate of Origin 1.1 By making a contribution to this project, I certify that: (a) The contribution was created in whole or in part by me and I have the right to submit it under the open source license indicated in the file; or (b) The contribution is based upon previous work that, to the best of my knowledge, is covered under an appropriate open source license and I have the right under that license to submit that work with modifications, whether created in whole or in part by me, under the same open source license (unless I am permitted to submit under a different license), as indicated in the file; or (c) The contribution was provided directly to me by some other person who certified (a), (b) or (c) and I have not modified it. (d) I understand and agree that this project and the contribution are public and that a record of the contribution (including all personal information I submit with it, including my sign-off) is maintained indefinitely and may be redistributed consistent with this project or the open source license(s) involved. If you can certify the above, just add a line stating the following at the bottom of each of your commit messages: Signed-off-by: Random Developer <random@developer.example.org> Please use your real name and a valid e-mail address (no pseudonyms or anonymous contributions).","title":"Developer's Certificate of Origin and Signed-off-by"},{"location":"zDNN/CONTRIBUTING/#submitting-code","text":"The preferred way is to create GitHub pull requests for your code contributions. Please create separate pull requests for each logical enhancement, new feature, or fix.","title":"Submitting code"},{"location":"zDNN/CONTRIBUTING/#github-workflow-for-contributions","text":"In the examples below we use this fictive identity: Name: Random Developer E-mail: random@developer.example.org GitHub ID: random-developer","title":"GitHub workflow for contributions"},{"location":"zDNN/CONTRIBUTING/#setup-github-and-local-git","text":"Create a fork of this repository by clicking the Fork button on the top right of the zDNN main page Clone your forked repository to your local development system $ git clone https://github.com/random-developer/zDNN.git Configure a remote called \"upstream\" pointing to the official zDNN repository on GitHub $ cd zDNN ~/zDNN $ git remote add upstream https://github.com/IBM/zDNN.git Verify your remotes ~/zDNN $ git remote -v origin https://github.com/random-developer/zDNN.git (fetch) origin https://github.com/random-developer/zDNN.git (push) upstream https://github.com/IBM/zDNN.git (fetch) upstream https://github.com/IBM/zDNN.git (push) You now have two remotes: The \"origin\" remote points to your fork and the \"upstream\" remote to the official zDNN repository. Configure your git user name and e-mail ~/zDNN $ git config user.name \"Random Developer\" ~/zDNN $ git config user.email \"random@developer.example.com\"","title":"Setup GitHub and local git"},{"location":"zDNN/CONTRIBUTING/#create-a-pull-request","text":"Create and checkout a new branch for your contribution ~/zDNN $ git checkout -b contrib-doc-pr Make your changes to the code ~/zDNN $ vim CONTRIBUTING.md Build and test your contribution, recommended on NNPA enabled machine. ~/zDNN $ make clean all Commit your changes ~/zDNN $ git add CONTRIBUTING.md ~/zDNN $ git commit -s Provide a meaningful commit message including your \"Signed-off-by\" line to each commit: CONTRIBUTING: Outline steps to submit code Explain in more detail how to submit zDNN contributions as GitHub pull requests. Signed-off-by: Random Developer <random@developer.example.com> Push the changes to your fork of the repository ~/zDNN $ git push origin contrib-doc-pr Go to the GitHub website of your zDNN fork and create a pull request for your branch \"contrib-doc-pr\"","title":"Create a pull request"},{"location":"zDNN/CONTRIBUTING/#update-a-pull-request-during-review","text":"If there are changes requested during the review process, you have to update your code in the pull request. To retain the existing review comments, add commits on top of your pull request branch. Depending on the size and number of changes, a rebase of the pull request might be required. This will be communicated during the review. Update your code with new commits ~/zDNN $ vi CONTRIBUTING.md ~/zDNN $ git add CONTRIBUTING.md ~/zDNN $ git commit -s -m \"CONTRIBUTING: Add update PR info\" Update your pull request by pushing changes ~/zDNN $ git push origin contrib-doc-pr","title":"Update a pull request during review"},{"location":"zDNN/CONTRIBUTING/#finalize-a-pull-request","text":"After the review process is finished or if you are explicitly asked for it, you have to create a clean commit series. Save branch to \"contrib-doc-pr.v1\" $ cd zDNN ~/zDNN $ git branch contrib-doc-pr.v1 Use interactive git rebase to merge commits, adjust commit messages, and rebase onto your local main branch ~/zDNN $ git rebase -i main An editor is started and shows the following: pick 2c73b9fc CONTRIBUTING: Outline steps to submit code pick fcfb0412 CONTRIBUTING: Add update PR info To merge the update into the original commit, replace \"pick fcfb0412\" with \"squash fcfb0412\". pick 2c73b9fc CONTRIBUTING: Outline steps to submit code squash fcfb0412 CONTRIBUTING: Add update PR info Save the document and exit the editor to finish the merge. Another editor window is presented to modify the commit message. You now could change the commit message as follows: CONTRIBUTING: Outline steps to submit code Explain in more detail how to submit zDNN contributions as GitHub pull requests and how to update already submitted pull requests. Signed-off-by: Random Developer <random@developer.example.com> With interactive rebasing you can also change the order of commits and modify commit messages with \"reword\". Use git push with the force option to replace the existing pull request with your locally modified commits ~/zDNN $ git push --force origin contrib-doc-pr","title":"Finalize a pull request"},{"location":"zDNN/CONTRIBUTING/#rebase-a-pull-request","text":"If changes are made to the main branch in the official zDNN repository you may be asked to rebase your branch with your contribution onto it. This can be required to prevent any merge conflicts that might arise when integrating your contribution. Fetch all upstream changes from the official zDNN repository, rebase your local main branch and update the main branch on your fork ~/zDNN $ git fetch upstream ~/zDNN $ git checkout main ~/zDNN $ git rebase upstream/main ~/zDNN $ git push origin main Rebase your branch with your contribution onto the main branch of the official zDNN repository ~/zDNN $ git checkout contrib-doc-pr ~/zDNN $ git rebase main Use git push with the force option to replace the existing pull request with your locally modified commits ~/zDNN $ git push --force origin contrib-doc-pr","title":"Rebase a pull request"},{"location":"zDNN/samples/","text":"Samples \u00b6 Compile \u00b6 Assume current directroy is /samples z/OS: xlc -g3 -qlanglvl=extc99 -Wc,LP64 -I ../zdnn -o simple_add simple_add.c ../zdnn/lib/libzdnn.x Linux's: gcc -g3 -Wall -fmessage-length=0 -std=c99 -I ../zdnn -o simple_add simple_add.c ../zdnn/lib/libzdnn.so NOTE: Add -D STATIC_LIB to gcc invocation if you're compiling using statically-linked library \u00b6","title":"Samples"},{"location":"zDNN/samples/#samples","text":"","title":"Samples"},{"location":"zDNN/samples/#compile","text":"Assume current directroy is /samples z/OS: xlc -g3 -qlanglvl=extc99 -Wc,LP64 -I ../zdnn -o simple_add simple_add.c ../zdnn/lib/libzdnn.x Linux's: gcc -g3 -Wall -fmessage-length=0 -std=c99 -I ../zdnn -o simple_add simple_add.c ../zdnn/lib/libzdnn.so","title":"Compile"},{"location":"zDNN/samples/#note-add-d-static_lib-to-gcc-invocation-if-youre-compiling-using-statically-linked-library","text":"","title":"NOTE: Add -D STATIC_LIB to gcc invocation if you're compiling using statically-linked library"}]}